<!doctype html><html lang="en"><head><meta name="msvalidate.01" content="D404690CEFCB54C7762AC84935B99171"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?6618da70c90c8744eead2e9371fb5077";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script type="text/javascript">!function(t,e,n,c,s,a,r){t[n]=t[n]||function(){(t[n].q=t[n].q||[]).push(arguments)},(a=e.createElement(c)).async=1,a.src="https://www.clarity.ms/tag/s5f3f0tojf",(r=e.getElementsByTagName(c)[0]).parentNode.insertBefore(a,r)}(window,document,"clarity","script")</script><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta http-equiv="X-UA-Compatible" content="ie=edge"><link rel="stylesheet" href="/styles/base.css"><link rel="stylesheet" href="/styles/theme.css"><link rel="shortcut icon" href="/favicon.png"><title>用 Spark SQL 进行结构化数据处理 - 归墟星火集 又一个 LinuxCN 站点</title><meta name="generator" content="Hexo 7.3.0"></head><body><div class="header-title"><span class="header-light"></span> <span class="header-light"></span> <span class="header-light"></span> <span>归墟星火集 又一个 LinuxCN 站点 linuxcn.undefined.today<span></span></span></div><div class="container"><ul class="nav"><li><a href="/">首页</a></li><li><a target="_blank" rel="noopener" href="https://undefined.today/">Blog</a></li></ul><div class="content"><div class="post-container"><div class="post-header"><span class="ui-tips">标题：</span><h1 class="ui-keyword post-title">用 Spark SQL 进行结构化数据处理</h1><span class="post-date">2022-05-24</span></div><div class="post-header"><span class="ui-tips">分类：</span> <a href="/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">软件开发</a></div><div class="post-header"><span class="ui-tips">标签：</span> <a href="/tags/SQL/">SQL</a> <a href="/tags/Spark/">Spark</a></div><div class="post-content"><blockquote><p>Spark SQL 是 Spark 生态系统中处理结构化格式数据的模块。它在内部使用 Spark Core API 进行处理，但对用户的使用进行了抽象。这篇文章深入浅出地告诉你 Spark SQL 3.x 的新内容。</p></blockquote><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/202205/24/093036xaf6kaz1auaf4a7s.jpg"></p><p>有了 Spark SQL，用户可以编写 SQL 风格的查询。这对于精通结构化查询语言或 SQL 的广大用户群体来说，基本上是很有帮助的。用户也将能够在结构化数据上编写交互式和临时性的查询。Spark SQL 弥补了<ruby>弹性分布式数据集 <rt>resilient distributed data sets</rt></ruby>（RDD）和关系表之间的差距。RDD 是 Spark 的基本数据结构。它将数据作为分布式对象存储在适合并行处理的节点集群中。RDD 很适合底层处理，但在运行时很难调试，程序员不能自动推断<ruby>模式 <rt>schema</rt></ruby>。另外，RDD 没有内置的优化功能。Spark SQL 提供了<ruby>数据帧 <rt>DataFrame</rt></ruby>和数据集来解决这些问题。</p><p>Spark SQL 可以使用现有的 Hive 元存储、SerDes 和 UDF。它可以使用 JDBC&#x2F;ODBC 连接到现有的 BI 工具。</p><h3 id="数据源"><a href="#数据源" class="headerlink" title="数据源"></a>数据源</h3><p>大数据处理通常需要处理不同的文件类型和数据源（关系型和非关系型）的能力。Spark SQL 支持一个统一的数据帧接口来处理不同类型的源，如下所示。</p><ul><li>文件：<ul><li>CSV</li><li>Text</li><li>JSON</li><li>XML</li></ul></li><li>JDBC&#x2F;ODBC：<ul><li>MySQL</li><li>Oracle</li><li>Postgres</li></ul></li><li>带模式的文件：<ul><li>AVRO</li><li>Parquet</li></ul></li><li>Hive 表：<ul><li>Spark SQL 也支持读写存储在 Apache Hive 中的数据。</li></ul></li></ul><p>通过数据帧，用户可以无缝地读取这些多样化的数据源，并对其进行转换&#x2F;连接。</p><h3 id="Spark-SQL-3-x-的新内容"><a href="#Spark-SQL-3-x-的新内容" class="headerlink" title="Spark SQL 3.x 的新内容"></a>Spark SQL 3.x 的新内容</h3><p>在以前的版本中（Spark 2.x），查询计划是基于启发式规则和成本估算的。从解析到逻辑和物理查询计划，最后到优化的过程是连续的。这些版本对转换和行动的运行时特性几乎没有可见性。因此，由于以下原因，查询计划是次优的：</p><ul><li>缺失和过时的统计数据</li><li>次优的启发式方法</li><li>错误的成本估计</li></ul><p>Spark 3.x 通过使用运行时数据来迭代改进查询计划和优化，增强了这个过程。前一阶段的运行时统计数据被用来优化后续阶段的查询计划。这里有一个反馈回路，有助于重新规划和重新优化执行计划。</p><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/202205/24/093039bgv1g1kw54xbk211.jpg" alt="Figure 1: Query planning"></p><h4 id="自适应查询执行（AQE）"><a href="#自适应查询执行（AQE）" class="headerlink" title="自适应查询执行（AQE）"></a>自适应查询执行（AQE）</h4><p>查询被改变为逻辑计划，最后变成物理计划。这里的概念是“重新优化”。它利用前一阶段的可用数据，为后续阶段重新优化。正因为如此，整个查询的执行要快得多。</p><p>AQE 可以通过设置 SQL 配置来启用，如下所示（Spark 3.0 中默认为 false）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.conf.set(“spark.sql.adaptive.enabled”,true)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="动态合并“洗牌”分区"><a href="#动态合并“洗牌”分区" class="headerlink" title="动态合并“洗牌”分区"></a>动态合并“洗牌”分区</h4><p>Spark 在“<ruby>洗牌 <rt>shuffle</rt></ruby>”操作后确定最佳的分区数量。在 AQE 中，Spark 使用默认的分区数，即 200 个。这可以通过配置来启用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.conf.set(“spark.sql.adaptive.coalescePartitions.enabled”,true)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="动态切换连接策略"><a href="#动态切换连接策略" class="headerlink" title="动态切换连接策略"></a>动态切换连接策略</h4><p>广播哈希是最好的连接操作。如果其中一个数据集很小，Spark 可以动态地切换到广播连接，而不是在网络上“洗牌”大量的数据。</p><h4 id="动态优化倾斜连接"><a href="#动态优化倾斜连接" class="headerlink" title="动态优化倾斜连接"></a>动态优化倾斜连接</h4><p>如果数据分布不均匀，数据会出现倾斜，会有一些大的分区。这些分区占用了大量的时间。Spark 3.x 通过将大分区分割成多个小分区来进行优化。这可以通过设置来启用：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.conf.set(“spark.sql.adaptive.skewJoin.enabled”,true)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/202205/24/093039mz91rb31jiyt3qjc.jpg" alt="Figure 2: Performance improvement in Spark 3.x (Source: Databricks)"></p><h3 id="其他改进措施"><a href="#其他改进措施" class="headerlink" title="其他改进措施"></a>其他改进措施</h3><p>此外，Spark SQL 3.x还支持以下内容。</p><h4 id="动态分区修剪"><a href="#动态分区修剪" class="headerlink" title="动态分区修剪"></a>动态分区修剪</h4><p>3.x 将只读取基于其中一个表的值的相关分区。这消除了解析大表的需要。</p><h4 id="连接提示"><a href="#连接提示" class="headerlink" title="连接提示"></a>连接提示</h4><p>如果用户对数据有了解，这允许用户指定要使用的连接策略。这增强了查询的执行过程。</p><h4 id="兼容-ANSI-SQL"><a href="#兼容-ANSI-SQL" class="headerlink" title="兼容 ANSI SQL"></a>兼容 ANSI SQL</h4><p>在兼容 Hive 的早期版本的 Spark 中，我们可以在查询中使用某些关键词，这样做是完全可行的。然而，这在 Spark SQL 3 中是不允许的，因为它有完整的 ANSI SQL 支持。例如，“将字符串转换为整数”会在运行时产生异常。它还支持保留关键字。</p><h4 id="较新的-Hadoop、Java-和-Scala-版本"><a href="#较新的-Hadoop、Java-和-Scala-版本" class="headerlink" title="较新的 Hadoop、Java 和 Scala 版本"></a>较新的 Hadoop、Java 和 Scala 版本</h4><p>从 Spark 3.0 开始，支持 Java 11 和 Scala 2.12。 Java 11 具有更好的原生协调和垃圾校正，从而带来更好的性能。 Scala 2.12 利用了 Java 8 的新特性，优于 2.11。</p><p>Spark 3.x 提供了这些现成的有用功能，而无需开发人员操心。这将显着提高 Spark 的整体性能。</p><hr><p>via: <a target="_blank" rel="noopener" href="https://www.opensourceforu.com/2022/05/structured-data-processing-with-spark-sql/">https://www.opensourceforu.com/2022/05/structured-data-processing-with-spark-sql/</a></p><p>作者：<a target="_blank" rel="noopener" href="https://www.opensourceforu.com/author/phani-kiran/">Phani Kiran</a> 选题：<a target="_blank" rel="noopener" href="https://github.com/lkxed">lkxed</a> 译者：<a target="_blank" rel="noopener" href="https://github.com/geekpi">geekpi</a> 校对：<a target="_blank" rel="noopener" href="https://github.com/wxy">wxy</a></p><p>本文由 <a target="_blank" rel="noopener" href="https://github.com/LCTT/TranslateProject">LCTT</a> 原创编译，<a target="_blank" rel="noopener" href="https://linux.cn/">Linux中国</a> 荣誉推出</p></div></div></div><div class="footer"><p class="footer-copyright"><span>Powered by <a target="_blank" href="https://hexo.io">Hexo</a></span> <span>Theme <a target="_blank" href="https://github.com/tinkink-co/hexo-theme-terminal">Terminal</a></span><script type="text/javascript" src="https://cdn.staticfile.net/jquery/3.4.1/jquery.min.js"></script><script>getCDNinfo=function(){$.ajax({url:"/cdn-cgi/trace",success:function(a,n){let i="Antananarivo, Madagascar - (TNR);Cape Town, South Africa - (CPT);Casablanca, Morocco - (CMN);Dar Es Salaam, Tanzania - (DAR);Djibouti City, Djibouti - (JIB);Durban, South Africa - (DUR);Johannesburg, South Africa - (JNB);Kigali, Rwanda - (KGL);Lagos, Nigeria - (LOS);Luanda, Angola - (LAD);Maputo, MZ - (MPM);Mombasa, Kenya - (MBA);Port Louis, Mauritius - (MRU);Réunion, France - (RUN);Bangalore, India - (BLR);Bangkok, Thailand - (BKK);Bandar Seri Begawan, Brunei - (BWN);Cebu, Philippines - (CEB);Chengdu, China - (CTU);Chennai, India - (MAA);Chittagong, Bangladesh - (CGP);Chongqing, China - (CKG);Colombo, Sri Lanka - (CMB);Dhaka, Bangladesh - (DAC);Dongguan, China - (SZX);Foshan, China - (FUO);Fuzhou, China - (FOC);Guangzhou, China - (CAN);Hangzhou, China - (HGH);Hanoi, Vietnam - (HAN);Hengyang, China - (HNY);Ho Chi Minh City, Vietnam - (SGN);Hong Kong - (HKG);Hyderabad, India - (HYD);Islamabad, Pakistan - (ISB);Jakarta, Indonesia - (CGK);Jinan, China - (TNA);Karachi, Pakistan - (KHI);Kathmandu, Nepal - (KTM);Kolkata, India - (CCU);Kuala Lumpur, Malaysia - (KUL);Lahore, Pakistan - (LHE);Langfang, China - (NAY);Luoyang, China - (LYA);Macau - (MFM);Malé, Maldives - (MLE);Manila, Philippines - (MNL);Mumbai, India - (BOM);Nagpur, India - (NAG);Nanning, China - (NNG);New Delhi, India - (DEL);Osaka, Japan - (KIX);Phnom Penh, Cambodia - (PNH);Qingdao, China - (TAO);Seoul, South Korea - (ICN);Shanghai, China - (SHA);Shenyang, China - (SHE);Shijiazhuang, China - (SJW);Singapore, Singapore - (SIN);Suzhou, China - (SZV);Taipei - (TPE);Thimphu, Bhutan - (PBH);Tianjin, China - (TSN);Tokyo, Japan - (NRT);Ulaanbaatar, Mongolia - (ULN);Vientiane, Laos - (VTE);Wuhan, China - (WUH);Wuxi, China - (WUX);Xi'an, China - (XIY);Yerevan, Armenia - (EVN);Zhengzhou, China - (CGO);Zuzhou, China - (CSX);Amsterdam, Netherlands - (AMS);Athens, Greece - (ATH);Barcelona, Spain - (BCN);Belgrade, Serbia - (BEG);Berlin, Germany - (TXL);Brussels, Belgium - (BRU);Bucharest, Romania - (OTP);Budapest, Hungary - (BUD);Chișinău, Moldova - (KIV);Copenhagen, Denmark - (CPH);Cork, Ireland -  (ORK);Dublin, Ireland - (DUB);Düsseldorf, Germany - (DUS);Edinburgh, United Kingdom - (EDI);Frankfurt, Germany - (FRA);Geneva, Switzerland - (GVA);Gothenburg, Sweden - (GOT);Hamburg, Germany - (HAM);Helsinki, Finland - (HEL);Istanbul, Turkey - (IST);Kyiv, Ukraine - (KBP);Lisbon, Portugal - (LIS);London, United Kingdom - (LHR);Luxembourg City, Luxembourg - (LUX);Madrid, Spain - (MAD);Manchester, United Kingdom - (MAN);Marseille, France - (MRS);Milan, Italy - (MXP);Moscow, Russia - (DME);Munich, Germany - (MUC);Nicosia, Cyprus - (LCA);Oslo, Norway - (OSL);Paris, France - (CDG);Prague, Czech Republic - (PRG);Reykjavík, Iceland - (KEF);Riga, Latvia - (RIX);Rome, Italy - (FCO);Saint Petersburg, Russia - (LED);Sofia, Bulgaria - (SOF);Stockholm, Sweden - (ARN);Tallinn, Estonia - (TLL);Thessaloniki, Greece - (SKG);Vienna, Austria - (VIE);Vilnius, Lithuania - (VNO);Warsaw, Poland - (WAW);Zagreb, Croatia - (ZAG);Zürich, Switzerland - (ZRH);Arica, Chile - (ARI);Asunción, Paraguay - (ASU);Bogotá, Colombia - (BOG);Buenos Aires, Argentina - (EZE);Curitiba, Brazil - (CWB);Fortaleza, Brazil - (FOR);Guatemala City, Guatemala - (GUA);Lima, Peru - (LIM);Medellín, Colombia - (MDE);Panama City, Panama - (PTY);Porto Alegre, Brazil - (POA);Quito, Ecuador - (UIO);Rio de Janeiro, Brazil - (GIG);São Paulo, Brazil - (GRU);Santiago, Chile - (SCL);Willemstad, Curaçao - (CUR);St. George's, Grenada - (GND);Amman, Jordan - (AMM);Baghdad, Iraq - (BGW);Baku, Azerbaijan - (GYD);Beirut, Lebanon - (BEY);Doha, Qatar - (DOH);Dubai, United Arab Emirates - (DXB);Kuwait City, Kuwait - (KWI);Manama, Bahrain - (BAH);Muscat, Oman - (MCT);Ramallah - (ZDM);Riyadh, Saudi Arabia - (RUH);Tel Aviv, Israel - (TLV);Ashburn, VA, United States - (IAD);Atlanta, GA, United States - (ATL);Boston, MA, United States - (BOS);Buffalo, NY, United States - (BUF);Calgary, AB, Canada - (YYC);Charlotte, NC, United States - (CLT);Chicago, IL, United States - (ORD);Columbus, OH, United States - (CMH);Dallas, TX, United States - (DFW);Denver, CO, United States - (DEN);Detroit, MI, United States - (DTW);Honolulu, HI, United States - (HNL);Houston, TX, United States - (IAH);Indianapolis, IN, United States - (IND);Jacksonville, FL, United States - (JAX);Kansas City, MO, United States - (MCI);Las Vegas, NV, United States - (LAS);Los Angeles, CA, United States - (LAX);McAllen, TX, United States - (MFE);Memphis, TN, United States - (MEM);Mexico City, Mexico - (MEX);Miami, FL, United States - (MIA);Minneapolis, MN, United States - (MSP);Montgomery, AL, United States - (MGM);Montréal, QC, Canada - (YUL);Nashville, TN, United States - (BNA);Newark, NJ, United States - (EWR);Norfolk, VA, United States - (ORF);Omaha, NE, United States - (OMA);Philadelphia, United States - (PHL);Phoenix, AZ, United States - (PHX);Pittsburgh, PA, United States - (PIT);Port-Au-Prince, Haiti - (PAP);Portland, OR, United States - (PDX);Queretaro, MX, Mexico - (QRO);Richmond, Virginia - (RIC);Sacramento, CA, United States - (SMF);Salt Lake City, UT, United States - (SLC);San Diego, CA, United States - (SAN);San Jose, CA, United States - (SJC);Saskatoon, SK, Canada - (YXE);Seattle, WA, United States - (SEA);St. Louis, MO, United States - (STL);Tampa, FL, United States - (TPA);Toronto, ON, Canada - (YYZ);Vancouver, BC, Canada - (YVR);Tallahassee, FL, United States - (TLH);Winnipeg, MB, Canada - (YWG);Adelaide, SA, Australia - (ADL);Auckland, New Zealand - (AKL);Brisbane, QLD, Australia - (BNE);Melbourne, VIC, Australia - (MEL);Noumea, New caledonia - (NOU);Perth, WA, Australia - (PER);Sydney, NSW, Australia - (SYD)".split(";"),e=a.split("colo=")[1].split("\n")[0],t=(a.split("colo=")[1].split("\n")[0],a.split("tls=")[1].split("\n")[0]),o=a.split("http=")[1].split("\n")[0],s=a.split("sni=")[1].split("\n")[0],r=a.split("ip=")[1].split("\n")[0],l=a.split("uag=")[1].split("\n")[0];for(var d=0;d<i.length;d++)if(-1!=i[d].indexOf(e)){document.getElementById("cdn").innerHTML=i[d];break}document.getElementById("tls").innerHTML=t,document.getElementById("http").innerHTML=o,document.getElementById("sni").innerHTML=s,document.getElementById("ip").innerHTML=r,document.getElementById("useragent").innerHTML=l}})},$(document).ready((function(){getCDNinfo()}))</script></p><p style="text-align:center">感谢陪伴与布道，开源之火不灭。​</p><p style="text-align:center"><script>document.write("本次加载耗时: "+(performance.getEntriesByType("navigation").reduce((e,r)=>e+r.responseEnd-r.startTime,0)+performance.getEntriesByType("resource").reduce((e,r)=>e+r.responseEnd-r.startTime,0)).toFixed(0)+"ms")</script></p><p style="text-align:center">当前 SNI 状态： <span id="sni">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 TLS 版本： <span id="tls">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 HTTP 版本： <span id="http">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前您的客户端 IP 是： <span id="ip">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前分配的 CDN 节点是: <span id="cdn">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">您的 UserAgent 信息是: <span id="useragent">正在统计！或可能被浏览器防追踪拦截！</span></p><p></p></div></div></body></html>