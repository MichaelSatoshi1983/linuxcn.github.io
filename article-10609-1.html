<!doctype html><html lang="en"><head><meta name="msvalidate.01" content="D404690CEFCB54C7762AC84935B99171"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?6618da70c90c8744eead2e9371fb5077";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script type="text/javascript">!function(t,e,n,c,s,a,r){t[n]=t[n]||function(){(t[n].q=t[n].q||[]).push(arguments)},(a=e.createElement(c)).async=1,a.src="https://www.clarity.ms/tag/s5f3f0tojf",(r=e.getElementsByTagName(c)[0]).parentNode.insertBefore(a,r)}(window,document,"clarity","script")</script><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta http-equiv="X-UA-Compatible" content="ie=edge"><link rel="stylesheet" href="/styles/base.css"><link rel="stylesheet" href="/styles/theme.css"><link rel="shortcut icon" href="/favicon.png"><title>使用 shell 构建多进程的 CommandlineFu 爬虫 - 归墟星火集</title><meta name="generator" content="Hexo 7.3.0"></head><body><div class="header-title"><span class="header-light"></span> <span class="header-light"></span> <span class="header-light"></span> <span>归墟星火集 linuxcn.undefined.today<span></span></span></div><div class="container"><ul class="nav"><li><a href="/">首页</a></li><li><a href="/about/">关于</a></li><li><a target="_blank" rel="noopener" href="https://undefined.today/">Blog</a></li></ul><div class="content"><div class="post-container"><div class="post-header"><span class="ui-tips">标题：</span><h1 class="ui-keyword post-title">使用 shell 构建多进程的 CommandlineFu 爬虫</h1><span class="post-date">2019-03-11</span></div><div class="post-header"><span class="ui-tips">分类：</span> <a href="/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">软件开发</a></div><div class="post-header"><span class="ui-tips">标签：</span> <a href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a> <a href="/tags/CommandlineFu/">CommandlineFu</a></div><div class="post-content"><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201903/11/224237ba1adl8jd18mlady.jpg"></p><p><a target="_blank" rel="noopener" href="https://www.commandlinefu.com/">CommandlineFu</a> 是一个记录脚本片段的网站，每个片段都有对应的功能说明和对应的标签。我想要做的就是尝试用 shell 写一个多进程的爬虫把这些代码片段记录在一个 org 文件中。</p><h3 id="参数定义"><a href="#参数定义" class="headerlink" title="参数定义"></a>参数定义</h3><p>这个脚本需要能够通过 <code>-n</code> 参数指定并发的爬虫数（默认为 CPU 核的数量），还要能通过 <code>-f</code> 指定保存的 org 文件路径（默认输出到 stdout）。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env bash</span><br><span class="line"></span><br><span class="line">proc_num=$(nproc)</span><br><span class="line">store_file=/dev/stdout</span><br><span class="line">while getopts :n:f: OPT; do</span><br><span class="line">    case $OPT in</span><br><span class="line">        n|+n)</span><br><span class="line">            proc_num=&quot;$OPTARG&quot;</span><br><span class="line">            ;;</span><br><span class="line">        f|+f)</span><br><span class="line">            store_file=&quot;$OPTARG&quot;</span><br><span class="line">            ;;</span><br><span class="line">        *)</span><br><span class="line">            echo &quot;usage: $&#123;0##*/&#125; [+-n proc_num] [+-f org_file&#125; [--]&quot;</span><br><span class="line">            exit 2</span><br><span class="line">    esac</span><br><span class="line">done</span><br><span class="line">shift $(( OPTIND - 1 ))</span><br><span class="line">OPTIND=1</span><br></pre></td></tr></table></figure><h3 id="解析命令浏览页面"><a href="#解析命令浏览页面" class="headerlink" title="解析命令浏览页面"></a>解析命令浏览页面</h3><p>我们需要一个进程从 CommandlineFu 的浏览列表中抽取各个脚本片段的 URL，这个进程将抽取出来的 URL 存放到一个队列中，再由各个爬虫进程从进程中读取 URL 并从中抽取出对应的代码片段、描述说明和标签信息写入 org 文件中。</p><p>这里就会遇到三个问题:</p><ol><li>进程之间通讯的队列如何实现</li><li>如何从页面中抽取出 URL、代码片段、描述说明、标签等信息</li><li>多进程对同一文件进行读写时的乱序问题</li></ol><h4 id="实现进程之间的通讯队列"><a href="#实现进程之间的通讯队列" class="headerlink" title="实现进程之间的通讯队列"></a>实现进程之间的通讯队列</h4><p>这个问题比较好解决，我们可以通过一个命名管道来实现：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">queue=$(mktemp --dry-run)</span><br><span class="line">mkfifo $&#123;queue&#125;</span><br><span class="line">exec 99&lt;&gt;$&#123;queue&#125;</span><br><span class="line">trap &quot;rm $&#123;queue&#125; 2&gt;/dev/null&quot; EXIT</span><br></pre></td></tr></table></figure><h4 id="从页面中抽取想要的信息"><a href="#从页面中抽取想要的信息" class="headerlink" title="从页面中抽取想要的信息"></a>从页面中抽取想要的信息</h4><p>从页面中提取元素内容主要有两种方法：</p><ol><li>对于简单的 HTML 页面，我们可以通过 <code>sed</code>、<code>grep</code>、<code>awk</code> 等工具通过正则表达式匹配的方式来从 HTML 中抽取信息。</li><li>通过 <a target="_blank" rel="noopener" href="https://www.w3.org/Tools/HTML-XML-utils/">html-xml-utils</a> 工具集中的 <a target="_blank" rel="noopener" href="https://www.w3.org/Tools/HTML-XML-utils/man1/hxselect.html">hxselect</a> 来根据 CSS 选择器提取相关元素。</li></ol><p>这里我们使用 html-xml-utils 工具来提取：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">function extract_views_from_browse_page()</span><br><span class="line">&#123;</span><br><span class="line">    if [[ $# -eq 0 ]];then</span><br><span class="line">        local html=$(cat -)</span><br><span class="line">    else</span><br><span class="line">        local html=&quot;$*&quot;</span><br><span class="line">    fi</span><br><span class="line">    echo $&#123;html&#125; |hxclean |hxselect -c -s &quot;\n&quot; &quot;li.list-group-item &gt; div:nth-child(1) &gt; div:nth-child(1) &gt; a:nth-child(1)::attr(href)&quot;|sed &#x27;s@^@https://www.commandlinefu.com/@&#x27;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function extract_nextpage_from_browse_page()</span><br><span class="line">&#123;</span><br><span class="line">    if [[ $# -eq 0 ]];then</span><br><span class="line">        local html=$(cat -)</span><br><span class="line">    else</span><br><span class="line">        local html=&quot;$*&quot;</span><br><span class="line">    fi</span><br><span class="line">    echo $&#123;html&#125; |hxclean |hxselect -s &quot;\n&quot; &quot;li.list-group-item:nth-child(26) &gt; a&quot;|grep &#x27;&gt;&#x27;|hxselect -c &quot;::attr(href)&quot;|sed &#x27;s@^@https://www.commandlinefu.com/@&#x27;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里需要注意的是：<code>hxselect</code> 对 HTML 解析时要求遵循严格的 XML 规范，因此在用 <code>hxselect</code> 解析之前需要先经过 <code>hxclean</code> 矫正。另外，为了防止 HTML 过大，超过参数列表长度，这里允许通过管道的形式将 HTML 内容传入。</p><h4 id="循环读取下一页的浏览页面，不断抽取代码片段-URL-写入队列"><a href="#循环读取下一页的浏览页面，不断抽取代码片段-URL-写入队列" class="headerlink" title="循环读取下一页的浏览页面，不断抽取代码片段 URL 写入队列"></a>循环读取下一页的浏览页面，不断抽取代码片段 URL 写入队列</h4><p>这里要解决的是上面提到的第三个问题: 多进程对管道进行读写时如何保障不出现乱序? 为此，我们需要在写入文件时对文件加锁，然后在写完文件后对文件解锁，在 shell 中我们可以使用 flock 来对文件进行枷锁。 关于 <code>flock</code> 的使用方法和注意事项，请参见另一篇博文 <a target="_blank" rel="noopener" href="https://github.com/lujun9972/lujun9972.github.com/blob/source/linux%E5%92%8C%E5%AE%83%E7%9A%84%E5%B0%8F%E4%BC%99%E4%BC%B4/linux%20shell%20flock%E6%96%87%E4%BB%B6%E9%94%81%E7%9A%84%E7%94%A8%E6%B3%95%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9.org">Linux shell flock 文件锁的用法及注意事项</a>。</p><p>由于需要在 <code>flock</code> 子进程中使用函数 <code>extract_views_from_browse_page</code>，因此需要先导出该函数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export -f extract_views_from_browse_page</span><br></pre></td></tr></table></figure><p>由于网络问题，使用 <code>curl</code> 获取内容可能失败，需要重复获取：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">function fetch()</span><br><span class="line">&#123;</span><br><span class="line">    local url=&quot;$1&quot;</span><br><span class="line">    while ! curl -L $&#123;url&#125; 2&gt;/dev/null;do</span><br><span class="line">        :</span><br><span class="line">    done</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>collector</code> 用来从种子 URL 中抓取待爬的 URL，写入管道文件中，写操作期间管道文件同时作为锁文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">function collector()</span><br><span class="line">&#123;</span><br><span class="line">    url=&quot;$*&quot;</span><br><span class="line">    while [[ -n $&#123;url&#125; ]];do</span><br><span class="line">        echo &quot;从$url中抽取&quot;</span><br><span class="line">        html=$(fetch &quot;$&#123;url&#125;&quot;)</span><br><span class="line">        echo &quot;$&#123;html&#125;&quot;|flock $&#123;queue&#125; -c &quot;extract_views_from_browse_page &gt;$&#123;queue&#125;&quot;</span><br><span class="line">        url=$(echo &quot;$&#123;html&#125;&quot;|extract_nextpage_from_browse_page)</span><br><span class="line">    done</span><br><span class="line">    # 让后面解析代码片段的爬虫进程能够正常退出，而不至于被阻塞.</span><br><span class="line">    for ((i=0;i&lt;$&#123;proc_num&#125;;i++))</span><br><span class="line">    do</span><br><span class="line">        echo &gt;$&#123;queue&#125;</span><br><span class="line">    done</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里要注意的是， 在找不到下一页 URL 后，我们用一个 for 循环往队列里写入了 <code>=proc_num=</code> 个空行，这一步的目的是让后面解析代码片段的爬虫进程能够正常退出，而不至于被阻塞。</p><h3 id="解析脚本片段页面"><a href="#解析脚本片段页面" class="headerlink" title="解析脚本片段页面"></a>解析脚本片段页面</h3><p>我们需要从脚本片段的页面中抽取标题、代码片段、描述说明以及标签信息，同时将这些内容按 org 模式的格式写入存储文件中。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">  function view_page_handler()</span><br><span class="line">  &#123;</span><br><span class="line">      local url=&quot;$1&quot;</span><br><span class="line">      local html=&quot;$(fetch &quot;$&#123;url&#125;&quot;)&quot;</span><br><span class="line">      # headline</span><br><span class="line">      local headline=&quot;$(echo $&#123;html&#125; |hxclean |hxselect -c -s &quot;\n&quot; &quot;.col-md-8 &gt; h1:nth-child(1)&quot;)&quot;</span><br><span class="line">      # command</span><br><span class="line">      local command=&quot;$(echo $&#123;html&#125; |hxclean |hxselect -c -s &quot;\n&quot; &quot;.col-md-8 &gt; div:nth-child(2) &gt; span:nth-child(2)&quot;|pandoc -f html -t org)&quot;</span><br><span class="line">      # description</span><br><span class="line">      local description=&quot;$(echo $&#123;html&#125; |hxclean |hxselect -c -s &quot;\n&quot; &quot;.col-md-8 &gt; div.description&quot;|pandoc -f html -t org)&quot;</span><br><span class="line">      # tags</span><br><span class="line">      local tags=&quot;$(echo $&#123;html&#125; |hxclean |hxselect -c -s &quot;:&quot; &quot;.functions &gt; a&quot;)&quot;</span><br><span class="line">      if [[ -n &quot;$&#123;tags&#125;&quot; ]];then</span><br><span class="line">          tags=&quot;:$&#123;tags&#125;&quot;</span><br><span class="line">      fi</span><br><span class="line">      # build org content</span><br><span class="line">      cat &lt;&lt;EOF |flock -x $&#123;store_file&#125; tee -a $&#123;store_file&#125;</span><br><span class="line">* $&#123;headline&#125;      $&#123;tags&#125;</span><br><span class="line"></span><br><span class="line">:PROPERTIES:</span><br><span class="line">:URL:       $&#123;url&#125;</span><br><span class="line">:END:</span><br><span class="line"></span><br><span class="line">$&#123;description&#125;</span><br><span class="line">#+begin_src shell</span><br><span class="line">$&#123;command&#125;</span><br><span class="line">#+end_src</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>这里抽取信息的方法跟上面的类似，不过代码片段和描述说明中可能有一些 HTML 代码，因此通过 <code>pandoc</code> 将之转换为 org 格式的内容。</p><p>注意最后输出 org 模式的格式并写入存储文件中的代码不要写成下面这样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">    flock -x $&#123;store_file&#125; cat &lt;&lt;EOF &gt;$&#123;store_file&#125;</span><br><span class="line">    * $&#123;headline&#125;\t\t $&#123;tags&#125;</span><br><span class="line">    $&#123;description&#125;</span><br><span class="line">    #+begin_src shell</span><br><span class="line">    $&#123;command&#125;</span><br><span class="line">    #+end_src</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>它的意思是使用 <code>flock</code> 对 <code>cat</code> 命令进行加锁，再把 <code>flock</code> 整个命令的结果通过重定向输出到存储文件中，而重定向输出的这个过程是没有加锁的。</p><p><code>spider</code> 从管道文件中读取待抓取的 URL，然后实施真正的抓取动作。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">function spider()</span><br><span class="line">&#123;</span><br><span class="line">    while :</span><br><span class="line">    do</span><br><span class="line">        if ! url=$(flock $&#123;queue&#125; -c &#x27;read -t 1 -u 99 url &amp;&amp; echo $url&#x27;)</span><br><span class="line">        then</span><br><span class="line">            sleep 1</span><br><span class="line">            continue</span><br><span class="line">        fi</span><br><span class="line"></span><br><span class="line">        if [[ -z &quot;$url&quot; ]];then</span><br><span class="line">            break</span><br><span class="line">        fi</span><br><span class="line">        view_page_handler $&#123;url&#125;</span><br><span class="line">    done</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里要注意的是，为了防止发生死锁，从管道中读取 URL 时设置了超时，当出现超时就意味着生产进程赶不上消费进程的消费速度,因此消费进程休眠一秒后再次检查队列中的 URL。</p><h3 id="组合起来"><a href="#组合起来" class="headerlink" title="组合起来"></a>组合起来</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">collector &quot;https://www.commandlinefu.com/commands/browse&quot; &amp;</span><br><span class="line"></span><br><span class="line">for ((i=0;i&lt;$&#123;proc_num&#125;;i++))</span><br><span class="line">do</span><br><span class="line">    spider &amp;</span><br><span class="line">done</span><br><span class="line">wait</span><br></pre></td></tr></table></figure><h3 id="抓取其他网站"><a href="#抓取其他网站" class="headerlink" title="抓取其他网站"></a>抓取其他网站</h3><p>通过重新定义 <code>extract_views_from_browse_page</code>、 <code>extract_nextpage_from-browse_page</code>、 <code>view_page_handler</code> 这几个函数， 以及提供一个新的种子 URL，我们可以很容易将其改造成抓取其他网站的多进程爬虫。</p><p>例如通过下面这段代码，就可以用来爬取 <a target="_blank" rel="noopener" href="https://xkcd.com/">xkcd</a> 上的漫画：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">function extract_views_from_browse_page()</span><br><span class="line">&#123;</span><br><span class="line">    if [[ $# -eq 0 ]];then</span><br><span class="line">        local html=$(cat -)</span><br><span class="line">    else</span><br><span class="line">        local html=&quot;$*&quot;</span><br><span class="line">    fi</span><br><span class="line">    max=$(echo &quot;$&#123;html&#125;&quot;|hxclean |hxselect -c -s &quot;\n&quot; &quot;#middleContainer&quot;|grep &quot;Permanent link to this comic&quot; |awk -F &quot;/&quot; &#x27;&#123;print $4&#125;&#x27;)</span><br><span class="line">    seq 1 $&#123;max&#125;|sed &#x27;s@^@https://xkcd.com/@&#x27;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function extract_nextpage_from_browse_page()</span><br><span class="line">&#123;</span><br><span class="line">    echo &quot;&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function view_page_handler()</span><br><span class="line">&#123;</span><br><span class="line">    local url=&quot;$1&quot;</span><br><span class="line">    local html=&quot;$(fetch &quot;$&#123;url&#125;/&quot;)&quot;</span><br><span class="line">    local image=&quot;https:$(echo $&#123;html&#125; |hxclean |hxselect -c -s &quot;\n&quot; &quot;#comic &gt; img:nth-child(1)::attr(src)&quot;)&quot;</span><br><span class="line">    echo $&#123;image&#125;</span><br><span class="line">    wget $&#123;image&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">collector &quot;https://xkcd.com/&quot; &amp;</span><br></pre></td></tr></table></figure></div></div></div><div class="footer"><p class="footer-copyright"><span>Powered by <a target="_blank" href="https://hexo.io">Hexo</a></span> <span>Theme <a target="_blank" href="https://github.com/tinkink-co/hexo-theme-terminal">Terminal</a></span><script type="text/javascript" src="https://cdn.staticfile.net/jquery/3.4.1/jquery.min.js"></script><script>getCDNinfo=function(){$.ajax({url:"/cdn-cgi/trace",success:function(a,n){let i="Antananarivo, Madagascar - (TNR);Cape Town, South Africa - (CPT);Casablanca, Morocco - (CMN);Dar Es Salaam, Tanzania - (DAR);Djibouti City, Djibouti - (JIB);Durban, South Africa - (DUR);Johannesburg, South Africa - (JNB);Kigali, Rwanda - (KGL);Lagos, Nigeria - (LOS);Luanda, Angola - (LAD);Maputo, MZ - (MPM);Mombasa, Kenya - (MBA);Port Louis, Mauritius - (MRU);Réunion, France - (RUN);Bangalore, India - (BLR);Bangkok, Thailand - (BKK);Bandar Seri Begawan, Brunei - (BWN);Cebu, Philippines - (CEB);Chengdu, China - (CTU);Chennai, India - (MAA);Chittagong, Bangladesh - (CGP);Chongqing, China - (CKG);Colombo, Sri Lanka - (CMB);Dhaka, Bangladesh - (DAC);Dongguan, China - (SZX);Foshan, China - (FUO);Fuzhou, China - (FOC);Guangzhou, China - (CAN);Hangzhou, China - (HGH);Hanoi, Vietnam - (HAN);Hengyang, China - (HNY);Ho Chi Minh City, Vietnam - (SGN);Hong Kong - (HKG);Hyderabad, India - (HYD);Islamabad, Pakistan - (ISB);Jakarta, Indonesia - (CGK);Jinan, China - (TNA);Karachi, Pakistan - (KHI);Kathmandu, Nepal - (KTM);Kolkata, India - (CCU);Kuala Lumpur, Malaysia - (KUL);Lahore, Pakistan - (LHE);Langfang, China - (NAY);Luoyang, China - (LYA);Macau - (MFM);Malé, Maldives - (MLE);Manila, Philippines - (MNL);Mumbai, India - (BOM);Nagpur, India - (NAG);Nanning, China - (NNG);New Delhi, India - (DEL);Osaka, Japan - (KIX);Phnom Penh, Cambodia - (PNH);Qingdao, China - (TAO);Seoul, South Korea - (ICN);Shanghai, China - (SHA);Shenyang, China - (SHE);Shijiazhuang, China - (SJW);Singapore, Singapore - (SIN);Suzhou, China - (SZV);Taipei - (TPE);Thimphu, Bhutan - (PBH);Tianjin, China - (TSN);Tokyo, Japan - (NRT);Ulaanbaatar, Mongolia - (ULN);Vientiane, Laos - (VTE);Wuhan, China - (WUH);Wuxi, China - (WUX);Xi'an, China - (XIY);Yerevan, Armenia - (EVN);Zhengzhou, China - (CGO);Zuzhou, China - (CSX);Amsterdam, Netherlands - (AMS);Athens, Greece - (ATH);Barcelona, Spain - (BCN);Belgrade, Serbia - (BEG);Berlin, Germany - (TXL);Brussels, Belgium - (BRU);Bucharest, Romania - (OTP);Budapest, Hungary - (BUD);Chișinău, Moldova - (KIV);Copenhagen, Denmark - (CPH);Cork, Ireland -  (ORK);Dublin, Ireland - (DUB);Düsseldorf, Germany - (DUS);Edinburgh, United Kingdom - (EDI);Frankfurt, Germany - (FRA);Geneva, Switzerland - (GVA);Gothenburg, Sweden - (GOT);Hamburg, Germany - (HAM);Helsinki, Finland - (HEL);Istanbul, Turkey - (IST);Kyiv, Ukraine - (KBP);Lisbon, Portugal - (LIS);London, United Kingdom - (LHR);Luxembourg City, Luxembourg - (LUX);Madrid, Spain - (MAD);Manchester, United Kingdom - (MAN);Marseille, France - (MRS);Milan, Italy - (MXP);Moscow, Russia - (DME);Munich, Germany - (MUC);Nicosia, Cyprus - (LCA);Oslo, Norway - (OSL);Paris, France - (CDG);Prague, Czech Republic - (PRG);Reykjavík, Iceland - (KEF);Riga, Latvia - (RIX);Rome, Italy - (FCO);Saint Petersburg, Russia - (LED);Sofia, Bulgaria - (SOF);Stockholm, Sweden - (ARN);Tallinn, Estonia - (TLL);Thessaloniki, Greece - (SKG);Vienna, Austria - (VIE);Vilnius, Lithuania - (VNO);Warsaw, Poland - (WAW);Zagreb, Croatia - (ZAG);Zürich, Switzerland - (ZRH);Arica, Chile - (ARI);Asunción, Paraguay - (ASU);Bogotá, Colombia - (BOG);Buenos Aires, Argentina - (EZE);Curitiba, Brazil - (CWB);Fortaleza, Brazil - (FOR);Guatemala City, Guatemala - (GUA);Lima, Peru - (LIM);Medellín, Colombia - (MDE);Panama City, Panama - (PTY);Porto Alegre, Brazil - (POA);Quito, Ecuador - (UIO);Rio de Janeiro, Brazil - (GIG);São Paulo, Brazil - (GRU);Santiago, Chile - (SCL);Willemstad, Curaçao - (CUR);St. George's, Grenada - (GND);Amman, Jordan - (AMM);Baghdad, Iraq - (BGW);Baku, Azerbaijan - (GYD);Beirut, Lebanon - (BEY);Doha, Qatar - (DOH);Dubai, United Arab Emirates - (DXB);Kuwait City, Kuwait - (KWI);Manama, Bahrain - (BAH);Muscat, Oman - (MCT);Ramallah - (ZDM);Riyadh, Saudi Arabia - (RUH);Tel Aviv, Israel - (TLV);Ashburn, VA, United States - (IAD);Atlanta, GA, United States - (ATL);Boston, MA, United States - (BOS);Buffalo, NY, United States - (BUF);Calgary, AB, Canada - (YYC);Charlotte, NC, United States - (CLT);Chicago, IL, United States - (ORD);Columbus, OH, United States - (CMH);Dallas, TX, United States - (DFW);Denver, CO, United States - (DEN);Detroit, MI, United States - (DTW);Honolulu, HI, United States - (HNL);Houston, TX, United States - (IAH);Indianapolis, IN, United States - (IND);Jacksonville, FL, United States - (JAX);Kansas City, MO, United States - (MCI);Las Vegas, NV, United States - (LAS);Los Angeles, CA, United States - (LAX);McAllen, TX, United States - (MFE);Memphis, TN, United States - (MEM);Mexico City, Mexico - (MEX);Miami, FL, United States - (MIA);Minneapolis, MN, United States - (MSP);Montgomery, AL, United States - (MGM);Montréal, QC, Canada - (YUL);Nashville, TN, United States - (BNA);Newark, NJ, United States - (EWR);Norfolk, VA, United States - (ORF);Omaha, NE, United States - (OMA);Philadelphia, United States - (PHL);Phoenix, AZ, United States - (PHX);Pittsburgh, PA, United States - (PIT);Port-Au-Prince, Haiti - (PAP);Portland, OR, United States - (PDX);Queretaro, MX, Mexico - (QRO);Richmond, Virginia - (RIC);Sacramento, CA, United States - (SMF);Salt Lake City, UT, United States - (SLC);San Diego, CA, United States - (SAN);San Jose, CA, United States - (SJC);Saskatoon, SK, Canada - (YXE);Seattle, WA, United States - (SEA);St. Louis, MO, United States - (STL);Tampa, FL, United States - (TPA);Toronto, ON, Canada - (YYZ);Vancouver, BC, Canada - (YVR);Tallahassee, FL, United States - (TLH);Winnipeg, MB, Canada - (YWG);Adelaide, SA, Australia - (ADL);Auckland, New Zealand - (AKL);Brisbane, QLD, Australia - (BNE);Melbourne, VIC, Australia - (MEL);Noumea, New caledonia - (NOU);Perth, WA, Australia - (PER);Sydney, NSW, Australia - (SYD)".split(";"),e=a.split("colo=")[1].split("\n")[0],t=(a.split("colo=")[1].split("\n")[0],a.split("tls=")[1].split("\n")[0]),o=a.split("http=")[1].split("\n")[0],s=a.split("sni=")[1].split("\n")[0],r=a.split("ip=")[1].split("\n")[0],l=a.split("uag=")[1].split("\n")[0];for(var d=0;d<i.length;d++)if(-1!=i[d].indexOf(e)){document.getElementById("cdn").innerHTML=i[d];break}document.getElementById("tls").innerHTML=t,document.getElementById("http").innerHTML=o,document.getElementById("sni").innerHTML=s,document.getElementById("ip").innerHTML=r,document.getElementById("useragent").innerHTML=l}})},$(document).ready((function(){getCDNinfo()}))</script></p><p style="text-align:center">感谢陪伴与布道，开源之火不灭。​</p><p style="text-align:center"><script>document.write("本次加载耗时: "+(performance.getEntriesByType("navigation").reduce((e,r)=>e+r.responseEnd-r.startTime,0)+performance.getEntriesByType("resource").reduce((e,r)=>e+r.responseEnd-r.startTime,0)).toFixed(0)+"ms")</script></p><p style="text-align:center">当前 SNI 状态： <span id="sni">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 TLS 版本： <span id="tls">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 HTTP 版本： <span id="http">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前您的客户端 IP 是： <span id="ip">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前分配的 CDN 节点是: <span id="cdn">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">您的 UserAgent 信息是: <span id="useragent">正在统计！或可能被浏览器防追踪拦截！</span></p><p></p></div></div></body></html>