<!doctype html><html lang="en"><head><meta name="msvalidate.01" content="D404690CEFCB54C7762AC84935B99171"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?6618da70c90c8744eead2e9371fb5077";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script type="text/javascript">!function(t,e,n,c,s,a,r){t[n]=t[n]||function(){(t[n].q=t[n].q||[]).push(arguments)},(a=e.createElement(c)).async=1,a.src="https://www.clarity.ms/tag/s5f3f0tojf",(r=e.getElementsByTagName(c)[0]).parentNode.insertBefore(a,r)}(window,document,"clarity","script")</script><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta http-equiv="X-UA-Compatible" content="ie=edge"><link rel="stylesheet" href="/styles/base.css"><link rel="stylesheet" href="/styles/theme.css"><link rel="shortcut icon" href="/favicon.png"><title>Python 学习：urllib 简介 - 归墟星火集</title><meta name="generator" content="Hexo 7.3.0"></head><body><div class="header-title"><span class="header-light"></span> <span class="header-light"></span> <span class="header-light"></span> <span>归墟星火集 linuxcn.undefined.today<span></span></span></div><div class="container"><ul class="nav"><li><a href="/">首页</a></li><li><a href="/about/">关于</a></li><li><a target="_blank" rel="noopener" href="https://undefined.today/">Blog</a></li></ul><div class="content"><div class="post-container"><div class="post-header"><span class="ui-tips">标题：</span><h1 class="ui-keyword post-title">Python 学习：urllib 简介</h1><span class="post-date">2016-08-09</span></div><div class="post-header"><span class="ui-tips">分类：</span> <a href="/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">软件开发</a></div><div class="post-header"><span class="ui-tips">标签：</span> <a href="/tags/python/">python</a> <a href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a> <a href="/tags/urllib/">urllib</a></div><div class="post-content"><p>Python 3 的 urllib 模块是一堆可以处理 URL 的组件集合。如果你有 Python 2 的知识，那么你就会注意到 Python 2 中有 urllib 和 urllib2 两个版本的模块。这些现在都是 Python 3 的 urllib 包的一部分。当前版本的 urllib 包括下面几部分：</p><ul><li>urllib.request</li><li>urllib.error</li><li>urllib.parse</li><li>urllib.rebotparser</li></ul><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201608/09/082037ijkkjwctadvpk6uc.jpg"></p><p>接下来我们会分开讨论除了 urllib.error 以外的几部分。官方文档实际推荐你尝试第三方库， requests，一个高级的 HTTP 客户端接口。然而我依然认为知道如何不依赖第三方库打开 URL 并与之进行交互是很有用的，而且这也可以帮助你理解为什么 requests 包是如此的流行。</p><h3 id="urllib-request"><a href="#urllib-request" class="headerlink" title="urllib.request"></a>urllib.request</h3><p>urllib.request 模块期初是用来打开和获取 URL 的。让我们看看你可以用函数 urlopen 可以做的事：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import urllib.request</span><br><span class="line">&gt;&gt;&gt; url = urllib.request.urlopen(&#x27;https://www.google.com/&#x27;)</span><br><span class="line">&gt;&gt;&gt; url.geturl()</span><br><span class="line">&#x27;https://www.google.com/&#x27;</span><br><span class="line">&gt;&gt;&gt; url.info()</span><br><span class="line">&lt;http.client.HTTPMessage object at 0x7fddc2de04e0&gt;</span><br><span class="line">&gt;&gt;&gt; header = url.info()</span><br><span class="line">&gt;&gt;&gt; header.as_string()</span><br><span class="line">(&#x27;Date: Fri, 24 Jun 2016 18:21:19 GMT\n&#x27;</span><br><span class="line"> &#x27;Expires: -1\n&#x27;</span><br><span class="line"> &#x27;Cache-Control: private, max-age=0\n&#x27;</span><br><span class="line"> &#x27;Content-Type: text/html; charset=ISO-8859-1\n&#x27;</span><br><span class="line"> &#x27;P3P: CP=&quot;This is not a P3P policy! See &#x27;</span><br><span class="line"> &#x27;https://www.google.com/support/accounts/answer/151657?hl=en for more info.&quot;\n&#x27;</span><br><span class="line"> &#x27;Server: gws\n&#x27;</span><br><span class="line"> &#x27;X-XSS-Protection: 1; mode=block\n&#x27;</span><br><span class="line"> &#x27;X-Frame-Options: SAMEORIGIN\n&#x27;</span><br><span class="line"> &#x27;Set-Cookie: &#x27;</span><br><span class="line"> &#x27;NID=80=tYjmy0JY6flsSVj7DPSSZNOuqdvqKfKHDcHsPIGu3xFv41LvH_Jg6LrUsDgkPrtM2hmZ3j9V76pS4K_cBg7pdwueMQfr0DFzw33SwpGex5qzLkXUvUVPfe9g699Qz4cx9ipcbU3HKwrRYA; &#x27;</span><br><span class="line"> &#x27;expires=Sat, 24-Dec-2016 18:21:19 GMT; path=/; domain=.google.com; HttpOnly\n&#x27;</span><br><span class="line"> &#x27;Alternate-Protocol: 443:quic\n&#x27;</span><br><span class="line"> &#x27;Alt-Svc: quic=&quot;:443&quot;; ma=2592000; v=&quot;34,33,32,31,30,29,28,27,26,25&quot;\n&#x27;</span><br><span class="line"> &#x27;Accept-Ranges: none\n&#x27;</span><br><span class="line"> &#x27;Vary: Accept-Encoding\n&#x27;</span><br><span class="line"> &#x27;Connection: close\n&#x27;</span><br><span class="line"> &#x27;\n&#x27;)</span><br><span class="line">&gt;&gt;&gt; url.getcode()</span><br><span class="line">200</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在这里我们包含了需要的模块，然后告诉它打开 Google 的 URL。现在我们就有了一个可以交互的 HTTPResponse 对象。我们要做的第一件事是调用方法 geturl ，它会返回根据 URL 获取的资源。这可以让我们发现 URL 是否进行了重定向。</p><p>接下来调用 info ，它会返回网页的元数据，比如请求头信息。因此，我们可以将结果赋给我们的 headers 变量，然后调用它的方法 as_string 。就可以打印出我们从 Google 收到的头信息。你也可以通过 getcode 得到网页的 HTTP 响应码，当前情况下就是 200，意思是正常工作。</p><p>如果你想看看网页的 HTML 代码，你可以调用变量 url 的方法 read。我不准备再现这个过程，因为输出结果太长了。</p><p>请注意 request 对象默认发起 GET 请求，除非你指定了它的 data 参数。如果你给它传递了 data 参数，这样 request 对象将会变成 POST 请求。</p><hr><h3 id="下载文件"><a href="#下载文件" class="headerlink" title="下载文件"></a>下载文件</h3><p>urllib 一个典型的应用场景是下载文件。让我们看看几种可以完成这个任务的方法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import urllib.request</span><br><span class="line">&gt;&gt;&gt; url = &#x27;http://www.blog.pythonlibrary.org/wp-content/uploads/2012/06/wxDbViewer.zip&#x27;</span><br><span class="line">&gt;&gt;&gt; response = urllib.request.urlopen(url)</span><br><span class="line">&gt;&gt;&gt; data = response.read()</span><br><span class="line">&gt;&gt;&gt; with open(&#x27;/home/mike/Desktop/test.zip&#x27;, &#x27;wb&#x27;) as fobj:</span><br><span class="line">...     fobj.write(data)</span><br><span class="line">...</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这个例子中我们打开一个保存在我的博客上的 zip 压缩文件的 URL。然后我们读出数据并将数据写到磁盘。一个替代此操作的方案是使用 urlretrieve ：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import urllib.request</span><br><span class="line">&gt;&gt;&gt; url = &#x27;http://www.blog.pythonlibrary.org/wp-content/uploads/2012/06/wxDbViewer.zip&#x27;</span><br><span class="line">&gt;&gt;&gt; tmp_file, header = urllib.request.urlretrieve(url)</span><br><span class="line">&gt;&gt;&gt; with open(&#x27;/home/mike/Desktop/test.zip&#x27;, &#x27;wb&#x27;) as fobj:</span><br><span class="line">...     with open(tmp_file, &#x27;rb&#x27;) as tmp:</span><br><span class="line">...         fobj.write(tmp.read())</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>方法 urlretrieve 会把网络对象拷贝到本地文件。除非你在使用 urlretrieve 的第二个参数指定你要保存文件的路径，否则这个文件将被拷贝到临时文件夹的随机命名的一个文件中。这个可以为你节省一步操作，并且使代码看起来更简单：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import urllib.request</span><br><span class="line">&gt;&gt;&gt; url = &#x27;http://www.blog.pythonlibrary.org/wp-content/uploads/2012/06/wxDbViewer.zip&#x27;</span><br><span class="line">&gt;&gt;&gt; urllib.request.urlretrieve(url, &#x27;/home/mike/Desktop/blog.zip&#x27;)</span><br><span class="line">(&#x27;/home/mike/Desktop/blog.zip&#x27;,</span><br><span class="line"> &lt;http.client.HTTPMessage object at 0x7fddc21c2470&gt;)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如你所见，它返回了文件保存的路径，以及从请求得来的头信息。</p><h3 id="设置你的用户代理"><a href="#设置你的用户代理" class="headerlink" title="设置你的用户代理"></a>设置你的用户代理</h3><p>当你使用浏览器访问网页时，浏览器会告诉网站它是谁。这就是所谓的 user-agent （用户代理）字段。Python 的 urllib 会表示它自己为 Python-urllib&#x2F;x.y ， 其中 x 和 y 是你使用的 Python 的主、次版本号。有一些网站不认识这个用户代理字段，然后网站可能会有奇怪的表现或者根本不能正常工作。辛运的是你可以很轻松的设置你自己的 user-agent 字段。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import urllib.request</span><br><span class="line">&gt;&gt;&gt; user_agent = &#x27; Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0&#x27;</span><br><span class="line">&gt;&gt;&gt; url = &#x27;http://www.whatsmyua.com/&#x27;</span><br><span class="line">&gt;&gt;&gt; headers = &#123;&#x27;User-Agent&#x27;: user_agent&#125;</span><br><span class="line">&gt;&gt;&gt; request = urllib.request.Request(url, headers=headers)</span><br><span class="line">&gt;&gt;&gt; with urllib.request.urlopen(request) as response:</span><br><span class="line">...     with open(&#x27;/home/mdriscoll/Desktop/user_agent.html&#x27;, &#x27;wb&#x27;) as out:</span><br><span class="line">...         out.write(response.read())</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里设置我们的用户代理为 Mozilla FireFox ，然后我们访问 <a target="_blank" rel="noopener" href="http://www.whatsmyua.com/">http://www.whatsmyua.com/</a> ， 它会告诉我们它识别出的我们的 user-agent 字段。之后我们将 url 和我们的头信息传给 urlopen 创建一个 Request 实例。最后我们保存这个结果。如果你打开这个结果，你会看到我们成功的修改了自己的 user-agent 字段。使用这段代码尽情的尝试不同的值来看看它是如何改变的。</p><hr><h3 id="urllib-parse"><a href="#urllib-parse" class="headerlink" title="urllib.parse"></a>urllib.parse</h3><p>urllib.parse 库是用来拆分和组合 URL 字符串的标准接口。比如，你可以使用它来转换一个相对的 URL 为绝对的 URL。让我们试试用它来转换一个包含查询的 URL ：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from urllib.parse import urlparse</span><br><span class="line">&gt;&gt;&gt; result = urlparse(&#x27;https://duckduckgo.com/?q=python+stubbing&amp;t=canonical&amp;ia=qa&#x27;)</span><br><span class="line">&gt;&gt;&gt; result</span><br><span class="line">ParseResult(scheme=&#x27;https&#x27;, netloc=&#x27;duckduckgo.com&#x27;, path=&#x27;/&#x27;, params=&#x27;&#x27;, query=&#x27;q=python+stubbing&amp;t=canonical&amp;ia=qa&#x27;, fragment=&#x27;&#x27;)</span><br><span class="line">&gt;&gt;&gt; result.netloc</span><br><span class="line">&#x27;duckduckgo.com&#x27;</span><br><span class="line">&gt;&gt;&gt; result.geturl()</span><br><span class="line">&#x27;https://duckduckgo.com/?q=python+stubbing&amp;t=canonical&amp;ia=qa&#x27;</span><br><span class="line">&gt;&gt;&gt; result.port</span><br><span class="line">None</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里我们导入了函数 urlparse ， 并且把一个包含搜索查询字串的 duckduckgo 的 URL 作为参数传给它。我的查询字串是搜索关于 “python stubbing” 的文章。如你所见，它返回了一个 ParseResult 对象，你可以用这个对象了解更多关于 URL 的信息。举个例子，你可以获取到端口信息（本例中没有端口信息）、网络位置、路径和很多其它东西。</p><h3 id="提交一个-Web-表单"><a href="#提交一个-Web-表单" class="headerlink" title="提交一个 Web 表单"></a>提交一个 Web 表单</h3><p>这个模块还有一个方法 urlencode 可以向 URL 传输数据。 urllib.parse 的一个典型使用场景是提交 Web 表单。让我们通过搜索引擎 duckduckgo 搜索 Python 来看看这个功能是怎么工作的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import urllib.request</span><br><span class="line">&gt;&gt;&gt; import urllib.parse</span><br><span class="line">&gt;&gt;&gt; data = urllib.parse.urlencode(&#123;&#x27;q&#x27;: &#x27;Python&#x27;&#125;)</span><br><span class="line">&gt;&gt;&gt; data</span><br><span class="line">&#x27;q=Python&#x27;</span><br><span class="line">&gt;&gt;&gt; url = &#x27;http://duckduckgo.com/html/&#x27;</span><br><span class="line">&gt;&gt;&gt; full_url = url + &#x27;?&#x27; + data</span><br><span class="line">&gt;&gt;&gt; response = urllib.request.urlopen(full_url)</span><br><span class="line">&gt;&gt;&gt; with open(&#x27;/home/mike/Desktop/results.html&#x27;, &#x27;wb&#x27;) as f:</span><br><span class="line">...     f.write(response.read())</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这个例子很直接。基本上我们是使用 Python 而不是浏览器向 duckduckgo 提交了一个查询。要完成这个我们需要使用 urlencode 构建我们的查询字符串。然后我们把这个字符串和网址拼接成一个完整的正确 URL ，然后使用 urllib.request 提交这个表单。最后我们就获取到了结果然后保存到磁盘上。</p><h3 id="urllib-robotparser"><a href="#urllib-robotparser" class="headerlink" title="urllib.robotparser"></a>urllib.robotparser</h3><p>robotparser 模块是由一个单独的类 RobotFileParser 构成的。这个类会回答诸如一个特定的用户代理是否获取已经设置了 robot.txt 的网站的 URL。 robot.txt 文件会告诉网络爬虫或者机器人当前网站的那些部分是不允许被访问的。让我们看一个简单的例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import urllib.robotparser</span><br><span class="line">&gt;&gt;&gt; robot = urllib.robotparser.RobotFileParser()</span><br><span class="line">&gt;&gt;&gt; robot.set_url(&#x27;http://arstechnica.com/robots.txt&#x27;)</span><br><span class="line">None</span><br><span class="line">&gt;&gt;&gt; robot.read()</span><br><span class="line">None</span><br><span class="line">&gt;&gt;&gt; robot.can_fetch(&#x27;*&#x27;, &#x27;http://arstechnica.com/&#x27;)</span><br><span class="line">True</span><br><span class="line">&gt;&gt;&gt; robot.can_fetch(&#x27;*&#x27;, &#x27;http://arstechnica.com/cgi-bin/&#x27;)</span><br><span class="line">False</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里我们导入了 robot 分析器类，然后创建一个实例。然后我们给它传递一个表明网站 robots.txt 位置的 URL 。接下来我们告诉分析器来读取这个文件。完成后，我们给它了一组不同的 URL 让它找出那些我们可以爬取而那些不能爬取。我们很快就看到我们可以访问主站但是不能访问 cgi-bin 路径。</p><h3 id="总结一下"><a href="#总结一下" class="headerlink" title="总结一下"></a>总结一下</h3><p>现在你就有能力使用 Python 的 urllib 包了。在这一节里，我们学习了如何下载文件、提交 Web 表单、修改自己的用户代理以及访问 robots.txt。 urllib 还有一大堆附加功能没有在这里提及，比如网站身份认证。你可能会考虑在使用 urllib 进行身份认证之前切换到 requests 库，因为 requests 已经以更易用和易调试的方式实现了这些功能。我同时也希望提醒你 Python 已经通过 http.cookies 模块支持 Cookies 了，虽然在 request 包里也很好的封装了这个功能。你应该可能考虑同时试试两个来决定那个最适合你。</p><hr><p>via: <a target="_blank" rel="noopener" href="http://www.blog.pythonlibrary.org/2016/06/28/python-101-an-intro-to-urllib/">http://www.blog.pythonlibrary.org/2016/06/28/python-101-an-intro-to-urllib/</a></p><p>作者：<a target="_blank" rel="noopener" href="http://www.blog.pythonlibrary.org/author/mld/">Mike</a> 译者：<a target="_blank" rel="noopener" href="https://github.com/oska874">Ezio</a> 校对：<a target="_blank" rel="noopener" href="https://github.com/wxy">wxy</a></p><p>本文由 <a target="_blank" rel="noopener" href="https://github.com/LCTT/TranslateProject">LCTT</a> 原创翻译，<a target="_blank" rel="noopener" href="https://linux.cn/">Linux中国</a> 荣誉推出</p></div></div></div><div class="footer"><p class="footer-copyright"><span>Powered by <a target="_blank" href="https://hexo.io">Hexo</a></span> <span>Theme <a target="_blank" href="https://github.com/tinkink-co/hexo-theme-terminal">Terminal</a></span><script type="text/javascript" src="https://cdn.staticfile.net/jquery/3.4.1/jquery.min.js"></script><script>getCDNinfo=function(){$.ajax({url:"/cdn-cgi/trace",success:function(a,n){let i="Antananarivo, Madagascar - (TNR);Cape Town, South Africa - (CPT);Casablanca, Morocco - (CMN);Dar Es Salaam, Tanzania - (DAR);Djibouti City, Djibouti - (JIB);Durban, South Africa - (DUR);Johannesburg, South Africa - (JNB);Kigali, Rwanda - (KGL);Lagos, Nigeria - (LOS);Luanda, Angola - (LAD);Maputo, MZ - (MPM);Mombasa, Kenya - (MBA);Port Louis, Mauritius - (MRU);Réunion, France - (RUN);Bangalore, India - (BLR);Bangkok, Thailand - (BKK);Bandar Seri Begawan, Brunei - (BWN);Cebu, Philippines - (CEB);Chengdu, China - (CTU);Chennai, India - (MAA);Chittagong, Bangladesh - (CGP);Chongqing, China - (CKG);Colombo, Sri Lanka - (CMB);Dhaka, Bangladesh - (DAC);Dongguan, China - (SZX);Foshan, China - (FUO);Fuzhou, China - (FOC);Guangzhou, China - (CAN);Hangzhou, China - (HGH);Hanoi, Vietnam - (HAN);Hengyang, China - (HNY);Ho Chi Minh City, Vietnam - (SGN);Hong Kong - (HKG);Hyderabad, India - (HYD);Islamabad, Pakistan - (ISB);Jakarta, Indonesia - (CGK);Jinan, China - (TNA);Karachi, Pakistan - (KHI);Kathmandu, Nepal - (KTM);Kolkata, India - (CCU);Kuala Lumpur, Malaysia - (KUL);Lahore, Pakistan - (LHE);Langfang, China - (NAY);Luoyang, China - (LYA);Macau - (MFM);Malé, Maldives - (MLE);Manila, Philippines - (MNL);Mumbai, India - (BOM);Nagpur, India - (NAG);Nanning, China - (NNG);New Delhi, India - (DEL);Osaka, Japan - (KIX);Phnom Penh, Cambodia - (PNH);Qingdao, China - (TAO);Seoul, South Korea - (ICN);Shanghai, China - (SHA);Shenyang, China - (SHE);Shijiazhuang, China - (SJW);Singapore, Singapore - (SIN);Suzhou, China - (SZV);Taipei - (TPE);Thimphu, Bhutan - (PBH);Tianjin, China - (TSN);Tokyo, Japan - (NRT);Ulaanbaatar, Mongolia - (ULN);Vientiane, Laos - (VTE);Wuhan, China - (WUH);Wuxi, China - (WUX);Xi'an, China - (XIY);Yerevan, Armenia - (EVN);Zhengzhou, China - (CGO);Zuzhou, China - (CSX);Amsterdam, Netherlands - (AMS);Athens, Greece - (ATH);Barcelona, Spain - (BCN);Belgrade, Serbia - (BEG);Berlin, Germany - (TXL);Brussels, Belgium - (BRU);Bucharest, Romania - (OTP);Budapest, Hungary - (BUD);Chișinău, Moldova - (KIV);Copenhagen, Denmark - (CPH);Cork, Ireland -  (ORK);Dublin, Ireland - (DUB);Düsseldorf, Germany - (DUS);Edinburgh, United Kingdom - (EDI);Frankfurt, Germany - (FRA);Geneva, Switzerland - (GVA);Gothenburg, Sweden - (GOT);Hamburg, Germany - (HAM);Helsinki, Finland - (HEL);Istanbul, Turkey - (IST);Kyiv, Ukraine - (KBP);Lisbon, Portugal - (LIS);London, United Kingdom - (LHR);Luxembourg City, Luxembourg - (LUX);Madrid, Spain - (MAD);Manchester, United Kingdom - (MAN);Marseille, France - (MRS);Milan, Italy - (MXP);Moscow, Russia - (DME);Munich, Germany - (MUC);Nicosia, Cyprus - (LCA);Oslo, Norway - (OSL);Paris, France - (CDG);Prague, Czech Republic - (PRG);Reykjavík, Iceland - (KEF);Riga, Latvia - (RIX);Rome, Italy - (FCO);Saint Petersburg, Russia - (LED);Sofia, Bulgaria - (SOF);Stockholm, Sweden - (ARN);Tallinn, Estonia - (TLL);Thessaloniki, Greece - (SKG);Vienna, Austria - (VIE);Vilnius, Lithuania - (VNO);Warsaw, Poland - (WAW);Zagreb, Croatia - (ZAG);Zürich, Switzerland - (ZRH);Arica, Chile - (ARI);Asunción, Paraguay - (ASU);Bogotá, Colombia - (BOG);Buenos Aires, Argentina - (EZE);Curitiba, Brazil - (CWB);Fortaleza, Brazil - (FOR);Guatemala City, Guatemala - (GUA);Lima, Peru - (LIM);Medellín, Colombia - (MDE);Panama City, Panama - (PTY);Porto Alegre, Brazil - (POA);Quito, Ecuador - (UIO);Rio de Janeiro, Brazil - (GIG);São Paulo, Brazil - (GRU);Santiago, Chile - (SCL);Willemstad, Curaçao - (CUR);St. George's, Grenada - (GND);Amman, Jordan - (AMM);Baghdad, Iraq - (BGW);Baku, Azerbaijan - (GYD);Beirut, Lebanon - (BEY);Doha, Qatar - (DOH);Dubai, United Arab Emirates - (DXB);Kuwait City, Kuwait - (KWI);Manama, Bahrain - (BAH);Muscat, Oman - (MCT);Ramallah - (ZDM);Riyadh, Saudi Arabia - (RUH);Tel Aviv, Israel - (TLV);Ashburn, VA, United States - (IAD);Atlanta, GA, United States - (ATL);Boston, MA, United States - (BOS);Buffalo, NY, United States - (BUF);Calgary, AB, Canada - (YYC);Charlotte, NC, United States - (CLT);Chicago, IL, United States - (ORD);Columbus, OH, United States - (CMH);Dallas, TX, United States - (DFW);Denver, CO, United States - (DEN);Detroit, MI, United States - (DTW);Honolulu, HI, United States - (HNL);Houston, TX, United States - (IAH);Indianapolis, IN, United States - (IND);Jacksonville, FL, United States - (JAX);Kansas City, MO, United States - (MCI);Las Vegas, NV, United States - (LAS);Los Angeles, CA, United States - (LAX);McAllen, TX, United States - (MFE);Memphis, TN, United States - (MEM);Mexico City, Mexico - (MEX);Miami, FL, United States - (MIA);Minneapolis, MN, United States - (MSP);Montgomery, AL, United States - (MGM);Montréal, QC, Canada - (YUL);Nashville, TN, United States - (BNA);Newark, NJ, United States - (EWR);Norfolk, VA, United States - (ORF);Omaha, NE, United States - (OMA);Philadelphia, United States - (PHL);Phoenix, AZ, United States - (PHX);Pittsburgh, PA, United States - (PIT);Port-Au-Prince, Haiti - (PAP);Portland, OR, United States - (PDX);Queretaro, MX, Mexico - (QRO);Richmond, Virginia - (RIC);Sacramento, CA, United States - (SMF);Salt Lake City, UT, United States - (SLC);San Diego, CA, United States - (SAN);San Jose, CA, United States - (SJC);Saskatoon, SK, Canada - (YXE);Seattle, WA, United States - (SEA);St. Louis, MO, United States - (STL);Tampa, FL, United States - (TPA);Toronto, ON, Canada - (YYZ);Vancouver, BC, Canada - (YVR);Tallahassee, FL, United States - (TLH);Winnipeg, MB, Canada - (YWG);Adelaide, SA, Australia - (ADL);Auckland, New Zealand - (AKL);Brisbane, QLD, Australia - (BNE);Melbourne, VIC, Australia - (MEL);Noumea, New caledonia - (NOU);Perth, WA, Australia - (PER);Sydney, NSW, Australia - (SYD)".split(";"),e=a.split("colo=")[1].split("\n")[0],t=(a.split("colo=")[1].split("\n")[0],a.split("tls=")[1].split("\n")[0]),o=a.split("http=")[1].split("\n")[0],s=a.split("sni=")[1].split("\n")[0],r=a.split("ip=")[1].split("\n")[0],l=a.split("uag=")[1].split("\n")[0];for(var d=0;d<i.length;d++)if(-1!=i[d].indexOf(e)){document.getElementById("cdn").innerHTML=i[d];break}document.getElementById("tls").innerHTML=t,document.getElementById("http").innerHTML=o,document.getElementById("sni").innerHTML=s,document.getElementById("ip").innerHTML=r,document.getElementById("useragent").innerHTML=l}})},$(document).ready((function(){getCDNinfo()}))</script></p><p style="text-align:center">感谢陪伴与布道，开源之火不灭。​</p><p style="text-align:center"><script>document.write("本次加载耗时: "+(performance.getEntriesByType("navigation").reduce((e,r)=>e+r.responseEnd-r.startTime,0)+performance.getEntriesByType("resource").reduce((e,r)=>e+r.responseEnd-r.startTime,0)).toFixed(0)+"ms")</script></p><p style="text-align:center">当前 SNI 状态： <span id="sni">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 TLS 版本： <span id="tls">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 HTTP 版本： <span id="http">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前您的客户端 IP 是： <span id="ip">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前分配的 CDN 节点是: <span id="cdn">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">您的 UserAgent 信息是: <span id="useragent">正在统计！或可能被浏览器防追踪拦截！</span></p><p></p></div></div></body></html>