<!doctype html><html lang="en"><head><meta name="msvalidate.01" content="D404690CEFCB54C7762AC84935B99171"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?6618da70c90c8744eead2e9371fb5077";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script type="text/javascript">!function(t,e,n,c,s,a,r){t[n]=t[n]||function(){(t[n].q=t[n].q||[]).push(arguments)},(a=e.createElement(c)).async=1,a.src="https://www.clarity.ms/tag/s5f3f0tojf",(r=e.getElementsByTagName(c)[0]).parentNode.insertBefore(a,r)}(window,document,"clarity","script")</script><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta http-equiv="X-UA-Compatible" content="ie=edge"><link rel="stylesheet" href="/styles/base.css"><link rel="stylesheet" href="/styles/theme.css"><link rel="shortcut icon" href="/favicon.png"><title>如何在 Apache Kafka 中通过 KSQL 分析 Twitter 数据 - 归墟星火集 又一个 LinuxCN 站点</title><meta name="generator" content="Hexo 7.3.0"></head><body><div class="header-title"><span class="header-light"></span> <span class="header-light"></span> <span class="header-light"></span> <span>归墟星火集 又一个 LinuxCN 站点 linuxcn.undefined.today<span></span></span></div><div class="container"><ul class="nav"><li><a href="/">首页</a></li><li><a target="_blank" rel="noopener" href="https://undefined.today/">Blog</a></li></ul><div class="content"><div class="post-container"><div class="post-header"><span class="ui-tips">标题：</span><h1 class="ui-keyword post-title">如何在 Apache Kafka 中通过 KSQL 分析 Twitter 数据</h1><span class="post-date">2017-11-03</span></div><div class="post-header"><span class="ui-tips">分类：</span> <a href="/categories/%E6%8A%80%E6%9C%AF/">技术</a></div><div class="post-header"><span class="ui-tips">标签：</span> <a href="/tags/Kafka/">Kafka</a> <a href="/tags/Twitter/">Twitter</a> <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></div><div class="post-content"><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201711/03/230240ei0izdx0ldzlviyl.jpg"></p><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p><a target="_blank" rel="noopener" href="https://github.com/confluentinc/ksql/">KSQL</a> 是 Apache Kafka 中的开源的流式 SQL 引擎。它可以让你在 Kafka <ruby>主题 <rt>topic</rt></ruby>上，使用一个简单的并且是交互式的 SQL 接口，很容易地做一些复杂的流处理。在这个短文中，我们将看到如何轻松地配置并运行在一个沙箱中去探索它，并使用大家都喜欢的演示数据库源： Twitter。我们将从推文的原始流中获取，通过使用 KSQL 中的条件去过滤它，来构建一个聚合，如统计每个用户每小时的推文数量。</p><h3 id="Confluent"><a href="#Confluent" class="headerlink" title="Confluent"></a>Confluent</h3><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201711/03/230309xi4qjpw5qqgej6i4.png"></p><p>首先， <a target="_blank" rel="noopener" href="https://www.confluent.io/download/">获取一个 Confluent 平台的副本</a>。我使用的是 RPM 包，但是，如果你需要的话，你也可以使用 <a target="_blank" rel="noopener" href="https://docs.confluent.io/current/installation.html">tar、 zip 等等</a> 。启动 Confluent 系统：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ confluent start</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（如果你感兴趣，这里有一个 <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=ZKqBptBHZTg">Confluent 命令行的快速教程</a>）</p><p>我们将使用 Kafka Connect 从 Twitter 上拉取数据。 这个 Twitter 连接器可以在 <a target="_blank" rel="noopener" href="https://github.com/jcustenborder/kafka-connect-twitter">GitHub</a> 上找到。要安装它，像下面这样操作：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Clone the git repo</span><br><span class="line">cd /home/rmoff</span><br><span class="line">git clone https://github.com/jcustenborder/kafka-connect-twitter.git</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Compile the code</span><br><span class="line">cd kafka-connect-twitter</span><br><span class="line">mvn clean package</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>要让 Kafka Connect 去使用我们构建的<a target="_blank" rel="noopener" href="https://docs.confluent.io/current/connect/userguide.html#connect-installing-plugins">连接器</a>， 你要去修改配置文件。因为我们使用 Confluent 命令行，真实的配置文件是在 <code>etc/schema-registry/connect-avro-distributed.properties</code>，因此去修改它并增加如下内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plugin.path=/home/rmoff/kafka-connect-twitter/target/kafka-connect-twitter-0.2-SNAPSHOT.tar.gz</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>重启动 Kafka Connect：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">confluent stop connect</span><br><span class="line">confluent start connect</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>一旦你安装好插件，你可以很容易地去配置它。你可以直接使用 Kafka Connect 的 REST API ，或者创建你的配置文件，这就是我要在这里做的。如果你需要全部的方法，请首先访问 Twitter 来获取你的 <a target="_blank" rel="noopener" href="https://apps.twitter.com/">API 密钥</a>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> &quot;name&quot;: &quot;twitter_source_json_01&quot;,</span><br><span class="line"> &quot;config&quot;: &#123;</span><br><span class="line">   &quot;connector.class&quot;: &quot;com.github.jcustenborder.kafka.connect.twitter.TwitterSourceConnector&quot;,</span><br><span class="line">   &quot;twitter.oauth.accessToken&quot;: &quot;xxxx&quot;,</span><br><span class="line">   &quot;twitter.oauth.consumerSecret&quot;: &quot;xxxxx&quot;,</span><br><span class="line">   &quot;twitter.oauth.consumerKey&quot;: &quot;xxxx&quot;,</span><br><span class="line">   &quot;twitter.oauth.accessTokenSecret&quot;: &quot;xxxxx&quot;,</span><br><span class="line">   &quot;kafka.delete.topic&quot;: &quot;twitter_deletes_json_01&quot;,</span><br><span class="line">   &quot;value.converter&quot;: &quot;org.apache.kafka.connect.json.JsonConverter&quot;,</span><br><span class="line">   &quot;key.converter&quot;: &quot;org.apache.kafka.connect.json.JsonConverter&quot;,</span><br><span class="line">   &quot;value.converter.schemas.enable&quot;: false,</span><br><span class="line">   &quot;key.converter.schemas.enable&quot;: false,</span><br><span class="line">   &quot;kafka.status.topic&quot;: &quot;twitter_json_01&quot;,</span><br><span class="line">   &quot;process.deletes&quot;: true,</span><br><span class="line">   &quot;filter.keywords&quot;: &quot;rickastley,kafka,ksql,rmoff&quot;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>假设你写这些到 <code>/home/rmoff/twitter-source.json</code>，你可以现在运行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ confluent load twitter_source -d /home/rmoff/twitter-source.json</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>然后推文就从大家都喜欢的网络明星 [rick] 滚滚而来……</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kafka-console-consumer --bootstrap-server localhost:9092 --from-beginning --topic twitter_json_01|jq &#x27;.Text&#x27;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;string&quot;: &quot;RT @rickastley: 30 years ago today I said I was Never Gonna Give You Up. I am a man of my word - Rick x https://t.co/VmbMQA6tQB&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;string&quot;: &quot;RT @mariteg10: @rickastley @Carfestevent Wonderful Rick!!\nDo not forget Chile!!\nWe hope you get back someday!!\nHappy weekend for you!!\n❤…&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="KSQL"><a href="#KSQL" class="headerlink" title="KSQL"></a>KSQL</h3><p>现在我们从 KSQL 开始 ! 马上去下载并构建它：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /home/rmoff</span><br><span class="line">git clone https://github.com/confluentinc/ksql.git</span><br><span class="line">cd /home/rmoff/ksql</span><br><span class="line">mvn clean compile install -DskipTests</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>构建完成后，让我们来运行它：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./bin/ksql-cli local --bootstrap-server localhost:9092</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">                       ======================================</span><br><span class="line">                       =      _  __ _____  ____  _          =</span><br><span class="line">                       =     | |/ // ____|/ __ \| |         =</span><br><span class="line">                       =     | &#x27; /| (___ | |  | | |         =</span><br><span class="line">                       =     |  &lt;  \___ \| |  | | |         =</span><br><span class="line">                       =     | . \ ____) | |__| | |____     =</span><br><span class="line">                       =     |_|\_\_____/ \___\_\______|    =</span><br><span class="line">                       =                                    =</span><br><span class="line">                       =   Streaming SQL Engine for Kafka   =</span><br><span class="line">Copyright 2017 Confluent Inc.</span><br><span class="line"></span><br><span class="line">CLI v0.1, Server v0.1 located at http://localhost:9098</span><br><span class="line"></span><br><span class="line">Having trouble? Type &#x27;help&#x27; (case-insensitive) for a rundown of how things work!</span><br><span class="line"></span><br><span class="line">ksql&gt; </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>使用 KSQL， 我们可以让我们的数据保留在 Kafka 主题上并可以查询它。首先，我们需要去告诉 KSQL 主题上的<ruby>数据模式 <rt>schema</rt></ruby>是什么，一个 twitter 消息实际上是一个非常巨大的 JSON 对象， 但是，为了简洁，我们只选出其中几行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ksql&gt; CREATE STREAM twitter_raw (CreatedAt BIGINT, Id BIGINT, Text VARCHAR) WITH (KAFKA_TOPIC=&#x27;twitter_json_01&#x27;, VALUE_FORMAT=&#x27;JSON&#x27;);</span><br><span class="line"></span><br><span class="line">Message  </span><br><span class="line">----------------</span><br><span class="line">Stream created</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在定义的模式中，我们可以查询这些流。要让 KSQL 从该主题的开始展示数据（而不是默认的当前时间点），运行如下命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ksql&gt; SET &#x27;auto.offset.reset&#x27; = &#x27;earliest&#x27;;  </span><br><span class="line">Successfully changed local property &#x27;auto.offset.reset&#x27; from &#x27;null&#x27; to &#x27;earliest&#x27;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>现在，让我们看看这些数据，我们将使用 LIMIT 从句仅检索一行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ksql&gt; SELECT text FROM twitter_raw LIMIT 1;  </span><br><span class="line">RT @rickastley: 30 years ago today I said I was Never Gonna Give You Up. I am a man of my word - Rick x https://t.co/VmbMQA6tQB</span><br><span class="line">LIMIT reached for the partition.  </span><br><span class="line">Query terminated</span><br><span class="line">ksql&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>现在，让我们使用刚刚定义和可用的推文内容的全部数据重新定义该流：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ksql&gt; DROP stream twitter_raw;</span><br><span class="line">Message</span><br><span class="line">--------------------------------</span><br><span class="line">Source TWITTER_RAW was dropped</span><br><span class="line"></span><br><span class="line">ksql&gt; CREATE STREAM twitter_raw (CreatedAt bigint,Id bigint, Text VARCHAR, SOURCE VARCHAR, Truncated VARCHAR, InReplyToStatusId VARCHAR, InReplyToUserId VARCHAR, InReplyToScreenName VARCHAR, GeoLocation VARCHAR, Place VARCHAR, Favorited VARCHAR, Retweeted VARCHAR, FavoriteCount VARCHAR, User VARCHAR, Retweet VARCHAR, Contributors VARCHAR, RetweetCount VARCHAR, RetweetedByMe VARCHAR, CurrentUserRetweetId VARCHAR, PossiblySensitive VARCHAR, Lang VARCHAR, WithheldInCountries VARCHAR, HashtagEntities VARCHAR, UserMentionEntities VARCHAR, MediaEntities VARCHAR, SymbolEntities VARCHAR, URLEntities VARCHAR) WITH (KAFKA_TOPIC=&#x27;twitter_json_01&#x27;,VALUE_FORMAT=&#x27;JSON&#x27;);</span><br><span class="line">Message</span><br><span class="line">----------------</span><br><span class="line">Stream created</span><br><span class="line"></span><br><span class="line">ksql&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>现在，我们可以操作和检查更多的最近的数据，使用一般的 SQL 查询：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ksql&gt; SELECT TIMESTAMPTOSTRING(CreatedAt, &#x27;yyyy-MM-dd HH:mm:ss.SSS&#x27;) AS CreatedAt,\</span><br><span class="line">EXTRACTJSONFIELD(user,&#x27;$.ScreenName&#x27;) as ScreenName,Text \</span><br><span class="line">FROM twitter_raw \</span><br><span class="line">WHERE LCASE(hashtagentities) LIKE &#x27;%oow%&#x27; OR \</span><br><span class="line">LCASE(hashtagentities) LIKE &#x27;%ksql%&#x27;;  </span><br><span class="line"></span><br><span class="line">2017-09-29 13:59:58.000 | rmoff | Looking forward to talking all about @apachekafka &amp; @confluentinc’s #KSQL at #OOW17 on Sunday 13:45 https://t.co/XbM4eIuzeG</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>注意这里没有 LIMIT 从句，因此，你将在屏幕上看到 “continuous query” 的结果。不像关系型数据表中返回一个确定数量结果的查询，一个持续查询会运行在无限的流式数据上， 因此，它总是可能返回更多的记录。点击 Ctrl-C 去中断然后返回到 KSQL 提示符。在以上的查询中我们做了一些事情：</p><ul><li><strong>TIMESTAMPTOSTRING</strong> 将时间戳从 epoch 格式转换到人类可读格式。（LCTT 译注： epoch 指的是一个特定的时间 1970-01-01 00:00:00 UTC）</li><li><strong>EXTRACTJSONFIELD</strong> 来展示数据源中嵌套的用户域中的一个字段，它看起来像：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">&quot;CreatedAt&quot;: 1506570308000,</span><br><span class="line">&quot;Text&quot;: &quot;RT @gwenshap: This is the best thing since partitioned bread :) https://t.co/1wbv3KwRM6&quot;,</span><br><span class="line">[...]</span><br><span class="line">&quot;User&quot;: &#123;</span><br><span class="line">    &quot;Id&quot;: 82564066,</span><br><span class="line">    &quot;Name&quot;: &quot;Robin Moffatt \uD83C\uDF7B\uD83C\uDFC3\uD83E\uDD53&quot;,</span><br><span class="line">    &quot;ScreenName&quot;: &quot;rmoff&quot;,</span><br><span class="line">    [...]</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>应用断言去展示内容，对 #（hashtag）使用模式匹配， 使用 LCASE 去强制小写字母。（LCTT 译注：hashtag 是twitter 中用来标注线索主题的标签）</li></ul><p>关于支持的函数列表，请查看 <a target="_blank" rel="noopener" href="https://github.com/confluentinc/ksql/blob/0.1.x/docs/syntax-reference.md">KSQL 文档</a>。</p><p>我们可以创建一个从这个数据中得到的流：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">ksql&gt; CREATE STREAM twitter AS \</span><br><span class="line">SELECT TIMESTAMPTOSTRING(CreatedAt, &#x27;yyyy-MM-dd HH:mm:ss.SSS&#x27;) AS CreatedAt,\</span><br><span class="line">EXTRACTJSONFIELD(user,&#x27;$.Name&#x27;) AS user_Name,\</span><br><span class="line">EXTRACTJSONFIELD(user,&#x27;$.ScreenName&#x27;) AS user_ScreenName,\</span><br><span class="line">EXTRACTJSONFIELD(user,&#x27;$.Location&#x27;) AS user_Location,\</span><br><span class="line">EXTRACTJSONFIELD(user,&#x27;$.Description&#x27;) AS  user_Description,\</span><br><span class="line">Text,hashtagentities,lang \</span><br><span class="line">FROM twitter_raw ;</span><br><span class="line"></span><br><span class="line">Message  </span><br><span class="line">----------------------------  </span><br><span class="line">Stream created and running  </span><br><span class="line"></span><br><span class="line">ksql&gt; DESCRIBE twitter;</span><br><span class="line">Field            | Type  </span><br><span class="line">------------------------------------  </span><br><span class="line">ROWTIME          | BIGINT  </span><br><span class="line">ROWKEY           | VARCHAR(STRING)  </span><br><span class="line">CREATEDAT        | VARCHAR(STRING)  </span><br><span class="line">USER_NAME        | VARCHAR(STRING)  </span><br><span class="line">USER_SCREENNAME  | VARCHAR(STRING)  </span><br><span class="line">USER_LOCATION    | VARCHAR(STRING)  </span><br><span class="line">USER_DESCRIPTION | VARCHAR(STRING)  </span><br><span class="line">TEXT             | VARCHAR(STRING)  </span><br><span class="line">HASHTAGENTITIES  | VARCHAR(STRING)  </span><br><span class="line">LANG             | VARCHAR(STRING)  </span><br><span class="line">ksql&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>并且查询这个得到的流：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ksql&gt; SELECT CREATEDAT, USER_NAME, TEXT \</span><br><span class="line">FROM TWITTER \</span><br><span class="line">WHERE TEXT LIKE &#x27;%KSQL%&#x27;;  </span><br><span class="line"></span><br><span class="line">2017-10-03 23:39:37.000 | Nicola Ferraro | RT @flashdba: Again, I&#x27;m really taken with the possibilities opened up by @confluentinc&#x27;s KSQL engine #Kafka https://t.co/aljnScgvvs</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="聚合"><a href="#聚合" class="headerlink" title="聚合"></a>聚合</h3><p>在我们结束之前，让我们去看一下怎么去做一些聚合。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ksql&gt; SELECT user_screenname, COUNT(*) \</span><br><span class="line">FROM twitter WINDOW TUMBLING (SIZE 1 HOUR) \</span><br><span class="line">GROUP BY user_screenname HAVING COUNT(*) &gt; 1;  </span><br><span class="line"></span><br><span class="line">oracleace | 2  </span><br><span class="line">rojulman | 2</span><br><span class="line">smokeinpublic | 2  </span><br><span class="line">ArtFlowMe | 2  </span><br><span class="line">[...]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>你将可能得到满屏幕的结果；这是因为 KSQL 在每次给定的时间窗口更新时实际发出聚合值。因为我们设置 KSQL 去读取在主题上的全部消息（<code>SET &#39;auto.offset.reset&#39; = &#39;earliest&#39;;</code>），它是一次性读取这些所有的消息并计算聚合更新。这里有一个微妙之处值得去深入研究。我们的入站推文流正好就是一个流。但是，现有它不能创建聚合，我们实际上是创建了一个表。一个表是在给定时间点的给定键的值的一个快照。 KSQL 聚合数据基于消息的事件时间，并且如果它更新了，通过简单的相关窗口重申去操作后面到达的数据。困惑了吗？ 我希望没有，但是，让我们看一下，如果我们可以用这个例子去说明。 我们将申明我们的聚合作为一个真实的表：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ksql&gt; CREATE TABLE user_tweet_count AS \</span><br><span class="line">SELECT user_screenname, count(*) AS  tweet_count \</span><br><span class="line">FROM twitter WINDOW TUMBLING (SIZE 1 HOUR) \</span><br><span class="line">GROUP BY user_screenname ;</span><br><span class="line"></span><br><span class="line">Message  </span><br><span class="line">---------------------------  </span><br><span class="line">Table created and running</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>看表中的列，这里除了我们要求的外，还有两个隐含列：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ksql&gt; DESCRIBE user_tweet_count;</span><br><span class="line"></span><br><span class="line">Field           | Type  </span><br><span class="line">-----------------------------------  </span><br><span class="line">ROWTIME         | BIGINT  </span><br><span class="line">ROWKEY          | VARCHAR(STRING)  </span><br><span class="line">USER_SCREENNAME | VARCHAR(STRING)  </span><br><span class="line">TWEET_COUNT     | BIGINT  </span><br><span class="line">ksql&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>我们看一下这些是什么：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ksql&gt; SELECT TIMESTAMPTOSTRING(ROWTIME, &#x27;yyyy-MM-dd HH:mm:ss.SSS&#x27;) , \</span><br><span class="line">ROWKEY, USER_SCREENNAME, TWEET_COUNT \</span><br><span class="line">FROM user_tweet_count \</span><br><span class="line">WHERE USER_SCREENNAME= &#x27;rmoff&#x27;;  </span><br><span class="line"></span><br><span class="line">2017-09-29 11:00:00.000 | rmoff : Window&#123;start=1506708000000 end=-&#125; | rmoff | 2  </span><br><span class="line">2017-09-29 12:00:00.000 | rmoff : Window&#123;start=1506711600000 end=-&#125; | rmoff | 4  </span><br><span class="line">2017-09-28 22:00:00.000 | rmoff : Window&#123;start=1506661200000 end=-&#125; | rmoff | 2  </span><br><span class="line">2017-09-29 09:00:00.000 | rmoff : Window&#123;start=1506700800000 end=-&#125; | rmoff | 4  </span><br><span class="line">2017-09-29 15:00:00.000 | rmoff : Window&#123;start=1506722400000 end=-&#125; | rmoff | 2  </span><br><span class="line">2017-09-29 13:00:00.000 | rmoff : Window&#123;start=1506715200000 end=-&#125; | rmoff | 6</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>ROWTIME</code> 是窗口开始时间， <code>ROWKEY</code> 是 <code>GROUP BY</code>（<code>USER_SCREENNAME</code>）加上窗口的组合。因此，我们可以通过创建另外一个衍生的表来整理一下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ksql&gt; CREATE TABLE USER_TWEET_COUNT_DISPLAY AS \</span><br><span class="line">SELECT TIMESTAMPTOSTRING(ROWTIME, &#x27;yyyy-MM-dd HH:mm:ss.SSS&#x27;) AS WINDOW_START ,\</span><br><span class="line">USER_SCREENNAME, TWEET_COUNT \</span><br><span class="line">FROM user_tweet_count;</span><br><span class="line"></span><br><span class="line">Message  </span><br><span class="line">---------------------------  </span><br><span class="line">Table created and running</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>现在它更易于查询和查看我们感兴趣的数据：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">ksql&gt; SELECT WINDOW_START ,  USER_SCREENNAME, TWEET_COUNT \</span><br><span class="line">FROM USER_TWEET_COUNT_DISPLAY WHERE TWEET_COUNT&gt; 20;  </span><br><span class="line"></span><br><span class="line">2017-09-29 12:00:00.000 | VikasAatOracle | 22  </span><br><span class="line">2017-09-28 14:00:00.000 | Throne_ie | 50  </span><br><span class="line">2017-09-28 14:00:00.000 | pikipiki_net | 22  </span><br><span class="line">2017-09-29 09:00:00.000 | johanlouwers | 22  </span><br><span class="line">2017-09-28 09:00:00.000 | yvrk1973 | 24  </span><br><span class="line">2017-09-28 13:00:00.000 | cmosoares | 22  </span><br><span class="line">2017-09-29 11:00:00.000 | ypoirier | 24  </span><br><span class="line">2017-09-28 14:00:00.000 | pikisec | 22  </span><br><span class="line">2017-09-29 07:00:00.000 | Throne_ie | 22  </span><br><span class="line">2017-09-29 09:00:00.000 | ChrisVoyance | 24  </span><br><span class="line">2017-09-28 11:00:00.000 | ChrisVoyance | 28</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>所以我们有了它！ 我们可以从 Kafka 中取得数据， 并且很容易使用 KSQL 去探索它。 而不仅是去浏览和转换数据，我们可以很容易地使用 KSQL 从流和表中建立流处理。</p><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201711/03/230317ly8bg2k2es9suyy6.png"></p><p>如果你对 KSQL 能够做什么感兴趣，去查看：</p><ul><li><a target="_blank" rel="noopener" href="https://www.confluent.io/blog/ksql-open-source-streaming-sql-for-apache-kafka/">KSQL 公告</a></li><li><a target="_blank" rel="noopener" href="https://www.confluent.io/online-talk/ksql-streaming-sql-for-apache-kafka/">我们最近的 KSQL 在线研讨会</a> 和 <a target="_blank" rel="noopener" href="https://www.confluent.io/kafka-summit-sf17/Databases-and-Stream-Processing-1">Kafka 峰会讲演</a></li><li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=A45uRzJiv7I">clickstream 演示</a>，它是 <a target="_blank" rel="noopener" href="https://github.com/confluentinc/ksql">KSQL 的 GitHub 仓库</a> 的一部分</li><li><a target="_blank" rel="noopener" href="https://speakerdeck.com/rmoff/look-ma-no-code-building-streaming-data-pipelines-with-apache-kafka">我最近做的演讲</a> 展示了 KSQL 如何去支持基于流的 ETL 平台</li></ul><p>记住，KSQL 现在正处于开发者预览阶段。 欢迎在 KSQL 的 GitHub 仓库上提出任何问题， 或者去我们的 <a target="_blank" rel="noopener" href="https://slackpass.io/confluentcommunity">community Slack group</a> 的 #KSQL 频道。</p><hr><p>via: <a target="_blank" rel="noopener" href="https://www.confluent.io/blog/using-ksql-to-analyse-query-and-transform-data-in-kafka">https://www.confluent.io/blog/using-ksql-to-analyse-query-and-transform-data-in-kafka</a></p><p>作者：<a target="_blank" rel="noopener" href="https://www.confluent.io/blog/author/robin/">Robin Moffatt</a> 译者：<a target="_blank" rel="noopener" href="https://github.com/qhwdw">qhwdw</a> 校对：<a target="_blank" rel="noopener" href="https://github.com/wxy">wxy</a></p><p>本文由 <a target="_blank" rel="noopener" href="https://github.com/LCTT/TranslateProject">LCTT</a> 原创编译，<a target="_blank" rel="noopener" href="https://linux.cn/">Linux中国</a> 荣誉推出</p></div></div></div><div class="footer"><p class="footer-copyright"><span>Powered by <a target="_blank" href="https://hexo.io">Hexo</a></span> <span>Theme <a target="_blank" href="https://github.com/tinkink-co/hexo-theme-terminal">Terminal</a></span><script type="text/javascript" src="https://cdn.staticfile.net/jquery/3.4.1/jquery.min.js"></script><script>getCDNinfo=function(){$.ajax({url:"/cdn-cgi/trace",success:function(a,n){let i="Antananarivo, Madagascar - (TNR);Cape Town, South Africa - (CPT);Casablanca, Morocco - (CMN);Dar Es Salaam, Tanzania - (DAR);Djibouti City, Djibouti - (JIB);Durban, South Africa - (DUR);Johannesburg, South Africa - (JNB);Kigali, Rwanda - (KGL);Lagos, Nigeria - (LOS);Luanda, Angola - (LAD);Maputo, MZ - (MPM);Mombasa, Kenya - (MBA);Port Louis, Mauritius - (MRU);Réunion, France - (RUN);Bangalore, India - (BLR);Bangkok, Thailand - (BKK);Bandar Seri Begawan, Brunei - (BWN);Cebu, Philippines - (CEB);Chengdu, China - (CTU);Chennai, India - (MAA);Chittagong, Bangladesh - (CGP);Chongqing, China - (CKG);Colombo, Sri Lanka - (CMB);Dhaka, Bangladesh - (DAC);Dongguan, China - (SZX);Foshan, China - (FUO);Fuzhou, China - (FOC);Guangzhou, China - (CAN);Hangzhou, China - (HGH);Hanoi, Vietnam - (HAN);Hengyang, China - (HNY);Ho Chi Minh City, Vietnam - (SGN);Hong Kong - (HKG);Hyderabad, India - (HYD);Islamabad, Pakistan - (ISB);Jakarta, Indonesia - (CGK);Jinan, China - (TNA);Karachi, Pakistan - (KHI);Kathmandu, Nepal - (KTM);Kolkata, India - (CCU);Kuala Lumpur, Malaysia - (KUL);Lahore, Pakistan - (LHE);Langfang, China - (NAY);Luoyang, China - (LYA);Macau - (MFM);Malé, Maldives - (MLE);Manila, Philippines - (MNL);Mumbai, India - (BOM);Nagpur, India - (NAG);Nanning, China - (NNG);New Delhi, India - (DEL);Osaka, Japan - (KIX);Phnom Penh, Cambodia - (PNH);Qingdao, China - (TAO);Seoul, South Korea - (ICN);Shanghai, China - (SHA);Shenyang, China - (SHE);Shijiazhuang, China - (SJW);Singapore, Singapore - (SIN);Suzhou, China - (SZV);Taipei - (TPE);Thimphu, Bhutan - (PBH);Tianjin, China - (TSN);Tokyo, Japan - (NRT);Ulaanbaatar, Mongolia - (ULN);Vientiane, Laos - (VTE);Wuhan, China - (WUH);Wuxi, China - (WUX);Xi'an, China - (XIY);Yerevan, Armenia - (EVN);Zhengzhou, China - (CGO);Zuzhou, China - (CSX);Amsterdam, Netherlands - (AMS);Athens, Greece - (ATH);Barcelona, Spain - (BCN);Belgrade, Serbia - (BEG);Berlin, Germany - (TXL);Brussels, Belgium - (BRU);Bucharest, Romania - (OTP);Budapest, Hungary - (BUD);Chișinău, Moldova - (KIV);Copenhagen, Denmark - (CPH);Cork, Ireland -  (ORK);Dublin, Ireland - (DUB);Düsseldorf, Germany - (DUS);Edinburgh, United Kingdom - (EDI);Frankfurt, Germany - (FRA);Geneva, Switzerland - (GVA);Gothenburg, Sweden - (GOT);Hamburg, Germany - (HAM);Helsinki, Finland - (HEL);Istanbul, Turkey - (IST);Kyiv, Ukraine - (KBP);Lisbon, Portugal - (LIS);London, United Kingdom - (LHR);Luxembourg City, Luxembourg - (LUX);Madrid, Spain - (MAD);Manchester, United Kingdom - (MAN);Marseille, France - (MRS);Milan, Italy - (MXP);Moscow, Russia - (DME);Munich, Germany - (MUC);Nicosia, Cyprus - (LCA);Oslo, Norway - (OSL);Paris, France - (CDG);Prague, Czech Republic - (PRG);Reykjavík, Iceland - (KEF);Riga, Latvia - (RIX);Rome, Italy - (FCO);Saint Petersburg, Russia - (LED);Sofia, Bulgaria - (SOF);Stockholm, Sweden - (ARN);Tallinn, Estonia - (TLL);Thessaloniki, Greece - (SKG);Vienna, Austria - (VIE);Vilnius, Lithuania - (VNO);Warsaw, Poland - (WAW);Zagreb, Croatia - (ZAG);Zürich, Switzerland - (ZRH);Arica, Chile - (ARI);Asunción, Paraguay - (ASU);Bogotá, Colombia - (BOG);Buenos Aires, Argentina - (EZE);Curitiba, Brazil - (CWB);Fortaleza, Brazil - (FOR);Guatemala City, Guatemala - (GUA);Lima, Peru - (LIM);Medellín, Colombia - (MDE);Panama City, Panama - (PTY);Porto Alegre, Brazil - (POA);Quito, Ecuador - (UIO);Rio de Janeiro, Brazil - (GIG);São Paulo, Brazil - (GRU);Santiago, Chile - (SCL);Willemstad, Curaçao - (CUR);St. George's, Grenada - (GND);Amman, Jordan - (AMM);Baghdad, Iraq - (BGW);Baku, Azerbaijan - (GYD);Beirut, Lebanon - (BEY);Doha, Qatar - (DOH);Dubai, United Arab Emirates - (DXB);Kuwait City, Kuwait - (KWI);Manama, Bahrain - (BAH);Muscat, Oman - (MCT);Ramallah - (ZDM);Riyadh, Saudi Arabia - (RUH);Tel Aviv, Israel - (TLV);Ashburn, VA, United States - (IAD);Atlanta, GA, United States - (ATL);Boston, MA, United States - (BOS);Buffalo, NY, United States - (BUF);Calgary, AB, Canada - (YYC);Charlotte, NC, United States - (CLT);Chicago, IL, United States - (ORD);Columbus, OH, United States - (CMH);Dallas, TX, United States - (DFW);Denver, CO, United States - (DEN);Detroit, MI, United States - (DTW);Honolulu, HI, United States - (HNL);Houston, TX, United States - (IAH);Indianapolis, IN, United States - (IND);Jacksonville, FL, United States - (JAX);Kansas City, MO, United States - (MCI);Las Vegas, NV, United States - (LAS);Los Angeles, CA, United States - (LAX);McAllen, TX, United States - (MFE);Memphis, TN, United States - (MEM);Mexico City, Mexico - (MEX);Miami, FL, United States - (MIA);Minneapolis, MN, United States - (MSP);Montgomery, AL, United States - (MGM);Montréal, QC, Canada - (YUL);Nashville, TN, United States - (BNA);Newark, NJ, United States - (EWR);Norfolk, VA, United States - (ORF);Omaha, NE, United States - (OMA);Philadelphia, United States - (PHL);Phoenix, AZ, United States - (PHX);Pittsburgh, PA, United States - (PIT);Port-Au-Prince, Haiti - (PAP);Portland, OR, United States - (PDX);Queretaro, MX, Mexico - (QRO);Richmond, Virginia - (RIC);Sacramento, CA, United States - (SMF);Salt Lake City, UT, United States - (SLC);San Diego, CA, United States - (SAN);San Jose, CA, United States - (SJC);Saskatoon, SK, Canada - (YXE);Seattle, WA, United States - (SEA);St. Louis, MO, United States - (STL);Tampa, FL, United States - (TPA);Toronto, ON, Canada - (YYZ);Vancouver, BC, Canada - (YVR);Tallahassee, FL, United States - (TLH);Winnipeg, MB, Canada - (YWG);Adelaide, SA, Australia - (ADL);Auckland, New Zealand - (AKL);Brisbane, QLD, Australia - (BNE);Melbourne, VIC, Australia - (MEL);Noumea, New caledonia - (NOU);Perth, WA, Australia - (PER);Sydney, NSW, Australia - (SYD)".split(";"),e=a.split("colo=")[1].split("\n")[0],t=(a.split("colo=")[1].split("\n")[0],a.split("tls=")[1].split("\n")[0]),o=a.split("http=")[1].split("\n")[0],s=a.split("sni=")[1].split("\n")[0],r=a.split("ip=")[1].split("\n")[0],l=a.split("uag=")[1].split("\n")[0];for(var d=0;d<i.length;d++)if(-1!=i[d].indexOf(e)){document.getElementById("cdn").innerHTML=i[d];break}document.getElementById("tls").innerHTML=t,document.getElementById("http").innerHTML=o,document.getElementById("sni").innerHTML=s,document.getElementById("ip").innerHTML=r,document.getElementById("useragent").innerHTML=l}})},$(document).ready((function(){getCDNinfo()}))</script></p><p style="text-align:center">感谢陪伴与布道，开源之火不灭。​</p><p style="text-align:center"><script>document.write("本次加载耗时: "+(performance.getEntriesByType("navigation").reduce((e,r)=>e+r.responseEnd-r.startTime,0)+performance.getEntriesByType("resource").reduce((e,r)=>e+r.responseEnd-r.startTime,0)).toFixed(0)+"ms")</script></p><p style="text-align:center">当前 SNI 状态： <span id="sni">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 TLS 版本： <span id="tls">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 HTTP 版本： <span id="http">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前您的客户端 IP 是： <span id="ip">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前分配的 CDN 节点是: <span id="cdn">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">您的 UserAgent 信息是: <span id="useragent">正在统计！或可能被浏览器防追踪拦截！</span></p><p></p></div></div></body></html>