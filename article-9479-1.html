<!doctype html><html lang="en"><head><meta name="msvalidate.01" content="D404690CEFCB54C7762AC84935B99171"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?6618da70c90c8744eead2e9371fb5077";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script type="text/javascript">!function(t,e,n,c,s,a,r){t[n]=t[n]||function(){(t[n].q=t[n].q||[]).push(arguments)},(a=e.createElement(c)).async=1,a.src="https://www.clarity.ms/tag/s5f3f0tojf",(r=e.getElementsByTagName(c)[0]).parentNode.insertBefore(a,r)}(window,document,"clarity","script")</script><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta http-equiv="X-UA-Compatible" content="ie=edge"><link rel="stylesheet" href="/styles/base.css"><link rel="stylesheet" href="/styles/theme.css"><link rel="shortcut icon" href="/favicon.png"><title>使用 Ansible 在树莓派上构建一个基于 Linux 的高性能计算系统 - 归墟星火集 又一个 LinuxCN 站点</title><meta name="generator" content="Hexo 7.3.0"></head><body><div class="header-title"><span class="header-light"></span> <span class="header-light"></span> <span class="header-light"></span> <span>归墟星火集 又一个 LinuxCN 站点 linuxcn.undefined.today<span></span></span></div><div class="container"><ul class="nav"><li><a href="/">首页</a></li><li><a target="_blank" rel="noopener" href="https://undefined.today/">Blog</a></li></ul><div class="content"><div class="post-container"><div class="post-header"><span class="ui-tips">标题：</span><h1 class="ui-keyword post-title">使用 Ansible 在树莓派上构建一个基于 Linux 的高性能计算系统</h1><span class="post-date">2018-03-25</span></div><div class="post-header"><span class="ui-tips">分类：</span> <a href="/categories/%E6%8A%80%E6%9C%AF/">技术</a></div><div class="post-header"><span class="ui-tips">标签：</span> <a href="/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/">树莓派</a> <a href="/tags/HPC/">HPC</a></div><div class="post-content"><blockquote><p>使用低成本的硬件和开源软件设计一个高性能计算集群。</p></blockquote><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201803/25/110033a7poo4or7w7ck3ak.jpg"></p><p>在我的 <a target="_blank" rel="noopener" href="https://opensource.com/article/17/11/openhpc">之前发表在 Opensource.com 上的文章中</a>，我介绍了 <a target="_blank" rel="noopener" href="https://openhpc.community/">OpenHPC</a> 项目，它的目标是致力于加速高性能计算（HPC）的创新。这篇文章将更深入来介绍使用 OpenHPC 的特性来构建一个小型的 HPC 系统。将它称为 <em>HPC 系统</em> 可能有点“扯虎皮拉大旗”的意思，因此，更确切的说法应该是，它是一个基于 OpenHPC 项目发布的 <a target="_blank" rel="noopener" href="https://openhpc.community/downloads/">集群构建方法</a> 的系统。</p><p>这个集群由两台树莓派 3 系统作为计算节点，以及一台虚拟机作为主节点，结构示意如下：</p><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201803/25/110113yb3b36m33txxa6mm.png" alt="Map of HPC cluster" title="Map of HPC cluster"></p><p>我的主节点运行的是 x86_64 架构的 CentOS 操作系统，而计算节点运行了 aarch64 的轻度修改版的 CentOS 操作系统。</p><p>下图是真实的设备工作照：</p><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201803/25/110115czi6plkwzs57pvzz.jpg" alt="HPC hardware setup" title="HPC hardware setup"></p><p>要把我的系统配置成像上图这样的 HPC 系统，我是按照 OpenHPC 的集群构建方法的 <a target="_blank" rel="noopener" href="https://github.com/openhpc/ohpc/releases/download/v1.3.3.GA/Install_guide-CentOS7-Warewulf-SLURM-1.3.3-aarch64.pdf">CentOS 7.4&#x2F;aarch64 + Warewulf + Slurm 安装指南</a> （PDF）的一些步骤来做的。这个方法包括了使用 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Warewulf">Warewulf</a> 的配置说明；因为我的那三个系统是手动安装的，我跳过了 Warewulf 部分以及创建 <a target="_blank" rel="noopener" href="http://people.redhat.com/areber/openhpc/ansible/">Ansible 剧本</a> 的一些步骤。</p><p>在 <a target="_blank" rel="noopener" href="https://www.ansible.com/">Ansible</a> 剧本中设置完成我的集群之后，我就可以向资源管理器提交作业了。在我的这个案例中， <a target="_blank" rel="noopener" href="https://slurm.schedmd.com/">Slurm</a> 充当了资源管理器，它是集群中的一个实例，由它来决定我的作业什么时候在哪里运行。在集群上启动一个简单的作业的方式之一：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[ohpc@centos01 ~]$ srun hostname</span><br><span class="line">calvin</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如果需要更多的资源，我可以去告诉 Slurm，我希望在 8 个 CPU 上去运行我的命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[ohpc@centos01 ~]$ srun -n 8 hostname</span><br><span class="line">hobbes</span><br><span class="line">hobbes</span><br><span class="line">hobbes</span><br><span class="line">hobbes</span><br><span class="line">calvin</span><br><span class="line">calvin</span><br><span class="line">calvin</span><br><span class="line">calvin</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在第一个示例中，Slurm 在一个单个的 CPU 上运行了指定的命令（<code>hostname</code>），而在第二个示例中，Slurm 在 8 个 CPU 上运行了那个命令。我的计算节点一个命名为 <code>calvin</code>，而另一个命名为 <code>hobbes</code>；在上面的命令输出部分可以看到它们的名字。每个计算节点都是由 4 个 CPU 核心的树莓派 3 构成的。</p><p>在我的集群中提交作业的另一种方法是使用命令 <code>sbatch</code>，它可以用于运行脚本，将输出写入到一个文件，而不是我的终端上。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[ohpc@centos01 ~]$ cat script1.sh</span><br><span class="line">#!/bin/sh</span><br><span class="line">date</span><br><span class="line">hostname</span><br><span class="line">sleep 10</span><br><span class="line">date</span><br><span class="line">[ohpc@centos01 ~]$ sbatch script1.sh</span><br><span class="line">Submitted batch job 101</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>它将创建一个名为 <code>slurm-101.out</code> 的输出文件，这个输出文件包含下列的内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Mon 11 Dec 16:42:31 UTC 2017</span><br><span class="line">calvin</span><br><span class="line">Mon 11 Dec 16:42:41 UTC 2017</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>为示范资源管理器的基本功能，简单的串行命令行工具就行，但是，做各种工作去配置一个类似 HPC 系统就有点无聊了。</p><p>一个更有趣的应用是在这个集群的所有可用 CPU 上运行一个 <a target="_blank" rel="noopener" href="https://www.open-mpi.org/">Open MPI</a> 的并行作业。我使用了一个基于 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">康威生命游戏</a> 的应用，它被用于一个名为“使用 Red Hat 企业版 Linux 跨多种架构运行康威生命游戏”的 <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=n8DvxMcOMXk">视频</a>。除了以前基于 MPI 的 <code>Game of Life</code> 版本之外，在我的集群中现在运行的这个版本对每个涉及的主机的单元格颜色都是不同的。下面的脚本以图形输出的方式来交互式启动应用：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ cat life.mpi</span><br><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">module load gnu6 openmpi3</span><br><span class="line"></span><br><span class="line">if [[ &quot;$SLURM_PROCID&quot; != &quot;0&quot; ]]; then</span><br><span class="line">    exit</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">mpirun ./mpi_life -a -p -b</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>我使用下面的命令来启动作业，它告诉 Slurm，为这个作业分配 8 个 CPU：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ srun -n 8 --x11 life.mpi</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>为了演示，这个作业有一个图形界面，它展示了当前计算的结果：</p><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201803/25/110116bicbb2ncc68vuisr.png"></p><p>红色单元格是由其中一个计算节点来计算的，而绿色单元格是由另外一个计算节点来计算的。我也可以让康威生命游戏程序为使用的每个 CPU 核心（这里的每个计算节点有四个核心）去生成不同的颜色，这样它的输出如下：</p><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201803/25/110116hap8pzooqao0oabu.png"></p><p>感谢 OpenHPC 提供的软件包和安装方法，因为它们让我可以去配置一个由两个计算节点和一个主节点的 HPC 式的系统。我可以在资源管理器上提交作业，然后使用 OpenHPC 提供的软件在我的树莓派的 CPU 上去启动 MPI 应用程序。</p><hr><p><em>想学习更多的关于使用 OpenHPC 去构建树莓派集群，请参与 Adrian Reber 在 <a target="_blank" rel="noopener" href="https://devconfcz2018.sched.com/event/DJYi/openhpc-introduction">DevConf.cz 2018</a> 的讨论，它于 1月 26-28 日在 Brno，Czech Republic 举行，以及在 <a target="_blank" rel="noopener" href="https://wiki.centos.org/Events/Dojo/Brussels2018">CentOS Dojo 2018</a> ，它于 2 月 2 日在 Brussels 举行。</em></p><h3 id="关于作者"><a href="#关于作者" class="headerlink" title="关于作者"></a>关于作者</h3><p>Adrian Reber —— Adrian 是 Red Hat 的高级软件工程师，他早在 2010 年就开始了迁移处理过程到高性能计算环境，从那个时候起迁移了许多的处理过程，并因此获得了博士学位，然后加入了 Red Hat 公司并开始去迁移到容器。偶尔他仍然去迁移单个处理过程，并且它至今仍然对高性能计算非常感兴趣。<a target="_blank" rel="noopener" href="https://opensource.com/users/adrianreber">关于我的更多信息点这里</a></p><hr><p>via: <a target="_blank" rel="noopener" href="https://opensource.com/article/18/1/how-build-hpc-system-raspberry-pi-and-openhpc">https://opensource.com/article/18/1/how-build-hpc-system-raspberry-pi-and-openhpc</a></p><p>作者：<a target="_blank" rel="noopener" href="https://opensource.com/users/adrianreber">Adrian Reber</a> 译者：<a target="_blank" rel="noopener" href="https://github.com/qhwdw">qhwdw</a> 校对：<a target="_blank" rel="noopener" href="https://github.com/wxy">wxy</a></p><p>本文由 <a target="_blank" rel="noopener" href="https://github.com/LCTT/TranslateProject">LCTT</a> 原创编译，<a target="_blank" rel="noopener" href="https://linux.cn/">Linux中国</a> 荣誉推出</p></div></div></div><div class="footer"><p class="footer-copyright"><span>Powered by <a target="_blank" href="https://hexo.io">Hexo</a></span> <span>Theme <a target="_blank" href="https://github.com/tinkink-co/hexo-theme-terminal">Terminal</a></span><script type="text/javascript" src="https://cdn.staticfile.net/jquery/3.4.1/jquery.min.js"></script><script>getCDNinfo=function(){$.ajax({url:"/cdn-cgi/trace",success:function(a,n){let i="Antananarivo, Madagascar - (TNR);Cape Town, South Africa - (CPT);Casablanca, Morocco - (CMN);Dar Es Salaam, Tanzania - (DAR);Djibouti City, Djibouti - (JIB);Durban, South Africa - (DUR);Johannesburg, South Africa - (JNB);Kigali, Rwanda - (KGL);Lagos, Nigeria - (LOS);Luanda, Angola - (LAD);Maputo, MZ - (MPM);Mombasa, Kenya - (MBA);Port Louis, Mauritius - (MRU);Réunion, France - (RUN);Bangalore, India - (BLR);Bangkok, Thailand - (BKK);Bandar Seri Begawan, Brunei - (BWN);Cebu, Philippines - (CEB);Chengdu, China - (CTU);Chennai, India - (MAA);Chittagong, Bangladesh - (CGP);Chongqing, China - (CKG);Colombo, Sri Lanka - (CMB);Dhaka, Bangladesh - (DAC);Dongguan, China - (SZX);Foshan, China - (FUO);Fuzhou, China - (FOC);Guangzhou, China - (CAN);Hangzhou, China - (HGH);Hanoi, Vietnam - (HAN);Hengyang, China - (HNY);Ho Chi Minh City, Vietnam - (SGN);Hong Kong - (HKG);Hyderabad, India - (HYD);Islamabad, Pakistan - (ISB);Jakarta, Indonesia - (CGK);Jinan, China - (TNA);Karachi, Pakistan - (KHI);Kathmandu, Nepal - (KTM);Kolkata, India - (CCU);Kuala Lumpur, Malaysia - (KUL);Lahore, Pakistan - (LHE);Langfang, China - (NAY);Luoyang, China - (LYA);Macau - (MFM);Malé, Maldives - (MLE);Manila, Philippines - (MNL);Mumbai, India - (BOM);Nagpur, India - (NAG);Nanning, China - (NNG);New Delhi, India - (DEL);Osaka, Japan - (KIX);Phnom Penh, Cambodia - (PNH);Qingdao, China - (TAO);Seoul, South Korea - (ICN);Shanghai, China - (SHA);Shenyang, China - (SHE);Shijiazhuang, China - (SJW);Singapore, Singapore - (SIN);Suzhou, China - (SZV);Taipei - (TPE);Thimphu, Bhutan - (PBH);Tianjin, China - (TSN);Tokyo, Japan - (NRT);Ulaanbaatar, Mongolia - (ULN);Vientiane, Laos - (VTE);Wuhan, China - (WUH);Wuxi, China - (WUX);Xi'an, China - (XIY);Yerevan, Armenia - (EVN);Zhengzhou, China - (CGO);Zuzhou, China - (CSX);Amsterdam, Netherlands - (AMS);Athens, Greece - (ATH);Barcelona, Spain - (BCN);Belgrade, Serbia - (BEG);Berlin, Germany - (TXL);Brussels, Belgium - (BRU);Bucharest, Romania - (OTP);Budapest, Hungary - (BUD);Chișinău, Moldova - (KIV);Copenhagen, Denmark - (CPH);Cork, Ireland -  (ORK);Dublin, Ireland - (DUB);Düsseldorf, Germany - (DUS);Edinburgh, United Kingdom - (EDI);Frankfurt, Germany - (FRA);Geneva, Switzerland - (GVA);Gothenburg, Sweden - (GOT);Hamburg, Germany - (HAM);Helsinki, Finland - (HEL);Istanbul, Turkey - (IST);Kyiv, Ukraine - (KBP);Lisbon, Portugal - (LIS);London, United Kingdom - (LHR);Luxembourg City, Luxembourg - (LUX);Madrid, Spain - (MAD);Manchester, United Kingdom - (MAN);Marseille, France - (MRS);Milan, Italy - (MXP);Moscow, Russia - (DME);Munich, Germany - (MUC);Nicosia, Cyprus - (LCA);Oslo, Norway - (OSL);Paris, France - (CDG);Prague, Czech Republic - (PRG);Reykjavík, Iceland - (KEF);Riga, Latvia - (RIX);Rome, Italy - (FCO);Saint Petersburg, Russia - (LED);Sofia, Bulgaria - (SOF);Stockholm, Sweden - (ARN);Tallinn, Estonia - (TLL);Thessaloniki, Greece - (SKG);Vienna, Austria - (VIE);Vilnius, Lithuania - (VNO);Warsaw, Poland - (WAW);Zagreb, Croatia - (ZAG);Zürich, Switzerland - (ZRH);Arica, Chile - (ARI);Asunción, Paraguay - (ASU);Bogotá, Colombia - (BOG);Buenos Aires, Argentina - (EZE);Curitiba, Brazil - (CWB);Fortaleza, Brazil - (FOR);Guatemala City, Guatemala - (GUA);Lima, Peru - (LIM);Medellín, Colombia - (MDE);Panama City, Panama - (PTY);Porto Alegre, Brazil - (POA);Quito, Ecuador - (UIO);Rio de Janeiro, Brazil - (GIG);São Paulo, Brazil - (GRU);Santiago, Chile - (SCL);Willemstad, Curaçao - (CUR);St. George's, Grenada - (GND);Amman, Jordan - (AMM);Baghdad, Iraq - (BGW);Baku, Azerbaijan - (GYD);Beirut, Lebanon - (BEY);Doha, Qatar - (DOH);Dubai, United Arab Emirates - (DXB);Kuwait City, Kuwait - (KWI);Manama, Bahrain - (BAH);Muscat, Oman - (MCT);Ramallah - (ZDM);Riyadh, Saudi Arabia - (RUH);Tel Aviv, Israel - (TLV);Ashburn, VA, United States - (IAD);Atlanta, GA, United States - (ATL);Boston, MA, United States - (BOS);Buffalo, NY, United States - (BUF);Calgary, AB, Canada - (YYC);Charlotte, NC, United States - (CLT);Chicago, IL, United States - (ORD);Columbus, OH, United States - (CMH);Dallas, TX, United States - (DFW);Denver, CO, United States - (DEN);Detroit, MI, United States - (DTW);Honolulu, HI, United States - (HNL);Houston, TX, United States - (IAH);Indianapolis, IN, United States - (IND);Jacksonville, FL, United States - (JAX);Kansas City, MO, United States - (MCI);Las Vegas, NV, United States - (LAS);Los Angeles, CA, United States - (LAX);McAllen, TX, United States - (MFE);Memphis, TN, United States - (MEM);Mexico City, Mexico - (MEX);Miami, FL, United States - (MIA);Minneapolis, MN, United States - (MSP);Montgomery, AL, United States - (MGM);Montréal, QC, Canada - (YUL);Nashville, TN, United States - (BNA);Newark, NJ, United States - (EWR);Norfolk, VA, United States - (ORF);Omaha, NE, United States - (OMA);Philadelphia, United States - (PHL);Phoenix, AZ, United States - (PHX);Pittsburgh, PA, United States - (PIT);Port-Au-Prince, Haiti - (PAP);Portland, OR, United States - (PDX);Queretaro, MX, Mexico - (QRO);Richmond, Virginia - (RIC);Sacramento, CA, United States - (SMF);Salt Lake City, UT, United States - (SLC);San Diego, CA, United States - (SAN);San Jose, CA, United States - (SJC);Saskatoon, SK, Canada - (YXE);Seattle, WA, United States - (SEA);St. Louis, MO, United States - (STL);Tampa, FL, United States - (TPA);Toronto, ON, Canada - (YYZ);Vancouver, BC, Canada - (YVR);Tallahassee, FL, United States - (TLH);Winnipeg, MB, Canada - (YWG);Adelaide, SA, Australia - (ADL);Auckland, New Zealand - (AKL);Brisbane, QLD, Australia - (BNE);Melbourne, VIC, Australia - (MEL);Noumea, New caledonia - (NOU);Perth, WA, Australia - (PER);Sydney, NSW, Australia - (SYD)".split(";"),e=a.split("colo=")[1].split("\n")[0],t=(a.split("colo=")[1].split("\n")[0],a.split("tls=")[1].split("\n")[0]),o=a.split("http=")[1].split("\n")[0],s=a.split("sni=")[1].split("\n")[0],r=a.split("ip=")[1].split("\n")[0],l=a.split("uag=")[1].split("\n")[0];for(var d=0;d<i.length;d++)if(-1!=i[d].indexOf(e)){document.getElementById("cdn").innerHTML=i[d];break}document.getElementById("tls").innerHTML=t,document.getElementById("http").innerHTML=o,document.getElementById("sni").innerHTML=s,document.getElementById("ip").innerHTML=r,document.getElementById("useragent").innerHTML=l}})},$(document).ready((function(){getCDNinfo()}))</script></p><p style="text-align:center">感谢陪伴与布道，开源之火不灭。​</p><p style="text-align:center"><script>document.write("本次加载耗时: "+(performance.getEntriesByType("navigation").reduce((e,r)=>e+r.responseEnd-r.startTime,0)+performance.getEntriesByType("resource").reduce((e,r)=>e+r.responseEnd-r.startTime,0)).toFixed(0)+"ms")</script></p><p style="text-align:center">当前 SNI 状态： <span id="sni">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 TLS 版本： <span id="tls">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 HTTP 版本： <span id="http">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前您的客户端 IP 是： <span id="ip">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前分配的 CDN 节点是: <span id="cdn">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">您的 UserAgent 信息是: <span id="useragent">正在统计！或可能被浏览器防追踪拦截！</span></p><p></p></div></div></body></html>