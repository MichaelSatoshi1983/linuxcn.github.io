<!doctype html><html lang="en"><head><meta name="description" content="一个LinuxCN的镜像站"><meta name="msvalidate.01" content="D404690CEFCB54C7762AC84935B99171"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?6618da70c90c8744eead2e9371fb5077";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script type="text/javascript">!function(t,e,n,c,s,a,r){t[n]=t[n]||function(){(t[n].q=t[n].q||[]).push(arguments)},(a=e.createElement(c)).async=1,a.src="https://www.clarity.ms/tag/s5f3f0tojf",(r=e.getElementsByTagName(c)[0]).parentNode.insertBefore(a,r)}(window,document,"clarity","script")</script><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta http-equiv="X-UA-Compatible" content="ie=edge"><link rel="stylesheet" href="/styles/base.css"><link rel="stylesheet" href="/styles/theme.css"><link rel="shortcut icon" href="/favicon.png"><title>数据科学家的命令行技巧 - 归墟星火集 又一个 LinuxCN 站点</title><meta name="generator" content="Hexo 7.3.0"></head><body><div class="header-title"><span class="header-light"></span> <span class="header-light"></span> <span class="header-light"></span> <span>归墟星火集 又一个 LinuxCN 站点 linuxcn.undefined.today<span></span></span></div><div class="container"><ul class="nav"><li><a href="/">首页</a></li><li><a target="_blank" rel="noopener" href="https://undefined.today/">Blog</a></li></ul><div class="content"><div class="post-container"><div class="post-header"><span class="ui-tips">标题：</span><h1 class="ui-keyword post-title">数据科学家的命令行技巧</h1><span class="post-date">2018-12-13</span></div><div class="post-header"><span class="ui-tips">分类：</span> <a href="/categories/%E6%8A%80%E6%9C%AF/">技术</a></div><div class="post-header"><span class="ui-tips">标签：</span> <a href="/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C/">命令行</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/">数据科学</a></div><div class="post-content"><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201812/13/221149dirhh8vthq2vll9j.png"></p><p>对于许多数据科学家来说，数据操作从始至终就是 Pandas 或 Tidyverse。从理论上讲，这样做没有任何问题。毕竟，这就是这些工具存在的原因。然而，对于像分隔符转换这样的简单任务，这些工具是大材小用了。</p><p>立志掌握命令行应该在每个开发人员的学习清单上，特别是数据科学家。学习 shell 的来龙去脉将无可否认地提高你的生产力。除此之外，命令行还是计算领域的一个重要历史课程。例如，awk —— 一种数据驱动的脚本语言。1977 年，在 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Brian_Kernighan">Brain Kernighan</a>（即传奇的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/The_C_Programming_Language">K&amp;R 书</a>中 K）的帮助下，awk 首次出现。今天，大约五十年过去了，awk 仍然活跃在每年<a target="_blank" rel="noopener" href="https://www.amazon.com/Learning-AWK-Programming-cutting-edge-text-processing-ebook/dp/B07BT98HDS">新出版的书</a>里面。因此，可以安全地假设对命令行魔法的付出不会很快贬值。</p><h3 id="我们将涵盖什么"><a href="#我们将涵盖什么" class="headerlink" title="我们将涵盖什么"></a>我们将涵盖什么</h3><ul><li>ICONV</li><li>HEAD</li><li>TR</li><li>WC</li><li>SPLIT</li><li>SORT &amp; UNIQ</li><li>CUT</li><li>PASTE</li><li>JOIN</li><li>GREP</li><li>SED</li><li>AWK</li></ul><h3 id="ICONV"><a href="#ICONV" class="headerlink" title="ICONV"></a>ICONV</h3><p>文件编码可能会很棘手。现在大部分文件都是 UTF-8 编码的。要了解 UTF-8 背后的一些魔力，请查看这个出色的<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=MijmeoH9LT4">视频</a>。尽管如此，有时我们收到的文件不是这种编码。这可能引起对改变编码模式的一些胡乱尝试。这里，<code>iconv</code> 是一个拯救者。<code>iconv</code> 是一个简单的程序，它将获取采用一种编码的文本并输出采用另一种编码的文本。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Converting -f (from) latin1 (ISO-8859-1)</span><br><span class="line"># -t (to) standard UTF_8</span><br><span class="line"></span><br><span class="line">iconv -f ISO-8859-1 -t UTF-8 &lt; input.txt &gt; output.txt</span><br></pre></td></tr></table></figure><p>实用选项：</p><ul><li><code>iconv -l</code> 列出所有已知编码</li><li><code>iconv -c</code> 默默丢弃无法转换的字符</li></ul><h3 id="HEAD"><a href="#HEAD" class="headerlink" title="HEAD"></a>HEAD</h3><p>如果你是一个 Pandas 重度用户，那么会很熟悉 <code>head</code>。通常在处理新数据时，我们想做的第一件事就是了解其内容。这就得启动 Pandas，读取数据然后调用 <code>df.head()</code> —— 要说这有点费劲。没有任何选项的 <code>head</code> 将打印出文件的前 10 行。<code>head</code> 的真正力量在于干净利落的测试操作。例如，如果我们想将文件的分隔符从逗号更改为管道。一个快速测试将是：<code>head mydata.csv | sed &#39;s/,/|/g&#39;</code>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Prints out first 10 lines</span><br><span class="line">head filename.csv</span><br><span class="line"></span><br><span class="line"># Print first 3 lines</span><br><span class="line">head -n 3 filename.csv</span><br></pre></td></tr></table></figure><p>实用选项：</p><ul><li><code>head -n</code> 打印特定行数</li><li><code>head -c</code> 打印特定字节数</li></ul><h3 id="TR"><a href="#TR" class="headerlink" title="TR"></a>TR</h3><p><code>tr</code> 类似于翻译。这个功能强大的实用程序是文件基础清理的主力。理想的用例是替换文件中的分隔符。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Converting a tab delimited file into commas</span><br><span class="line">cat tab_delimited.txt | tr &quot;\t&quot; &quot;,&quot; comma_delimited.csv</span><br></pre></td></tr></table></figure><p><code>tr</code> 另一个功能是你可以用内建 <code>[:class:]</code> 变量（POSIX 字符类）发挥威力。这些包括了：</p><ul><li><code>[:alnum:]</code> 所有字母和数字</li><li><code>[:alpha:]</code> 所有字母</li><li><code>[:blank:]</code> 所有水平空白</li><li><code>[:cntrl:]</code> 所有控制字符</li><li><code>[:digit:]</code> 所有数字</li><li><code>[:graph:]</code> 所有可打印字符，但不包括空格</li><li><code>[:lower:]</code> 所有小写字母</li><li><code>[:print:]</code> 所有可打印字符，包括空格</li><li><code>[:punct:]</code> 所有标点符号</li><li><code>[:space:]</code> 所有水平或垂直空白</li><li><code>[:upper:]</code> 所有大写字母</li><li><code>[:xdigit:]</code> 所有 16 进制数字</li></ul><p>你可以将这些连接在一起以组成强大的程序。以下是一个基本的字数统计程序，可用于检查 README 是否被滥用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat README.md | tr &quot;[:punct:][:space:]&quot; &quot;\n&quot; | tr &quot;[:upper:]&quot; &quot;[:lower:]&quot; | grep . | sort | uniq -c | sort -nr</span><br></pre></td></tr></table></figure><p>另一个使用基本正则表达式的例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Converting all upper case letters to lower case</span><br><span class="line">cat filename.csv | tr &#x27;[A-Z]&#x27; &#x27;[a-z]&#x27;</span><br></pre></td></tr></table></figure><p>实用选项：</p><ul><li><code>tr -d</code> 删除字符</li><li><code>tr -s</code> 压缩字符</li><li><code>\b</code> 退格</li><li><code>\f</code> 换页</li><li><code>\v</code> 垂直制表符</li><li><code>\NNN</code> 八进制字符</li></ul><h3 id="WC"><a href="#WC" class="headerlink" title="WC"></a>WC</h3><p>单词计数。它的价值主要来自其 <code>-l</code> 选项，它会给你提供行数。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Will return number of lines in CSV</span><br><span class="line">wc -l gigantic_comma.csv</span><br></pre></td></tr></table></figure><p>这个工具可以方便地确认各种命令的输出。所以，如果我们在转换文件中的分隔符之后运行 <code>wc -l</code>，我们会期待总行数是一样的，如果不一致，我们就知道有地方出错了。</p><p>实用选项：</p><ul><li><code>wc -c</code> 打印字节数</li><li><code>wc -m</code> 打印字符数</li><li><code>wc -L</code> 打印最长行的长度</li><li><code>wc -w</code> 打印单词数量</li></ul><h3 id="SPLIT"><a href="#SPLIT" class="headerlink" title="SPLIT"></a>SPLIT</h3><p>文件大小的范围可以很广。对于有的任务，拆分文件或许是有好处的，所以使用 <code>split</code> 吧。<code>split</code> 的基本语法是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># We will split our CSV into new_filename every 500 lines</span><br><span class="line">split -l 500 filename.csv new_filename_</span><br><span class="line"># filename.csv</span><br><span class="line"># ls output</span><br><span class="line"># new_filename_aaa</span><br><span class="line"># new_filename_aab</span><br><span class="line"># new_filename_aa</span><br></pre></td></tr></table></figure><p>它有两个奇怪的地方是命名约定和缺少文件扩展名。后缀约定可以通过 <code>-d</code> 标志变为数字。要添加文件扩展名，你需要运行以下 <code>find</code> 命令。它将通过附加 <code>.csv</code> 扩展名来更改当前目录中所有文件的名称，所以小心了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">find . -type f -exec mv &#x27;&#123;&#125;&#x27; &#x27;&#123;&#125;&#x27;.csv \;</span><br><span class="line"># ls output</span><br><span class="line"># filename.csv.csv</span><br><span class="line"># new_filename_aaa.csv</span><br><span class="line"># new_filename_aab.csv</span><br><span class="line"># new_filename_aac.csv</span><br></pre></td></tr></table></figure><p>实用选项：</p><ul><li><code>split -b N</code> 按特定字节大小分割</li><li><code>split -a N</code> 生成长度为 N 的后缀</li><li><code>split -x</code> 使用十六进制后缀</li></ul><h3 id="SORT-UNIQ"><a href="#SORT-UNIQ" class="headerlink" title="SORT &amp; UNIQ"></a>SORT &amp; UNIQ</h3><p>上面两个命令很明显：它们的作用就是字面意思。这两者结合起来可以提供最强大的冲击 (例如，唯一单词的数量)。这是由于 <code>uniq</code> 只作用于重复的相邻行。这也是在输出前进行 <code>sort</code> 的原因。一个有趣的事情是 <code>sort -u</code> 会达到和典型的 <code>sort file.txt | uniq</code> 模式一样的结果。</p><p><code>sort</code> 对数据科学家来说确实具有潜在的有用能力：能够根据特定列对整个 CSV 进行排序。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Sorting a CSV file by the second column alphabetically</span><br><span class="line">sort -t&quot;,&quot; -k2,2 filename.csv</span><br><span class="line"></span><br><span class="line"># Numerically</span><br><span class="line">sort -t&quot;,&quot; -k2n,2 filename.csv</span><br><span class="line"></span><br><span class="line"># Reverse order</span><br><span class="line">sort -t&quot;,&quot; -k2nr,2 filename.csv</span><br></pre></td></tr></table></figure><p>这里的 <code>-t</code> 选项将逗号指定为分隔符，通常假设分隔符是空格或制表符。此外，<code>-k</code> 选项是为了确定我们的键。这里的语法是 <code>-km,n</code>，<code>m</code> 作为开始列，<code>n</code> 作为结束列。</p><p>实用选项：</p><ul><li><code>sort -f</code> 忽略大小写</li><li><code>sort -r</code> 反向排序</li><li><code>sort -R</code> 乱序</li><li><code>uniq -c</code> 统计出现次数</li><li><code>uniq -d</code> 只打印重复行</li></ul><h3 id="CUT"><a href="#CUT" class="headerlink" title="CUT"></a>CUT</h3><p><code>cut</code> 用于删除列。作为演示，如果我们只想删除第一和第三列。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cut -d, -f 1,3 filename.csv</span><br></pre></td></tr></table></figure><p>要选择除了第一行外的所有行。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cut -d, -f 2- filename.csv</span><br></pre></td></tr></table></figure><p>结合其他命令，将 <code>cut</code> 用作过滤器。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Print first 10 lines of column 1 and 3, where &quot;some_string_value&quot; is present</span><br><span class="line">head filename.csv | grep &quot;some_string_value&quot; | cut -d, -f 1,3</span><br></pre></td></tr></table></figure><p>查出第二列中唯一值的数量。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat filename.csv | cut -d, -f 2 | sort | uniq | wc -l</span><br><span class="line"></span><br><span class="line"># Count occurences of unique values, limiting to first 10 results</span><br><span class="line">cat filename.csv | cut -d, -f 2 | sort | uniq -c | head</span><br></pre></td></tr></table></figure><h3 id="PASTE"><a href="#PASTE" class="headerlink" title="PASTE"></a>PASTE</h3><p><code>paste</code> 是一个带有趣味性功能的特定命令。如果你有两个需要合并的文件，并且它们已经排序好了，<code>paste</code> 帮你解决了接下来的步骤。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># names.txt</span><br><span class="line">adam</span><br><span class="line">john</span><br><span class="line">zach</span><br><span class="line"></span><br><span class="line"># jobs.txt</span><br><span class="line">lawyer</span><br><span class="line">youtuber</span><br><span class="line">developer</span><br><span class="line"></span><br><span class="line"># Join the two into a CSV</span><br><span class="line">paste -d &#x27;,&#x27; names.txt jobs.txt &gt; person_data.txt</span><br><span class="line"></span><br><span class="line"># Output</span><br><span class="line">adam,lawyer</span><br><span class="line">john,youtuber</span><br><span class="line">zach,developer</span><br></pre></td></tr></table></figure><p>更多 SQL 式变种，见下文。</p><h3 id="JOIN"><a href="#JOIN" class="headerlink" title="JOIN"></a>JOIN</h3><p><code>join</code> 是一个简单的、<ruby>准切向的 <rt>quasi-tangential</rt></ruby> SQL。最大的区别是 <code>join</code> 将返回所有列以及只能在一个字段上匹配。默认情况下，<code>join</code> 将尝试使用第一列作为匹配键。为了获得不同结果，必须使用以下语法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Join the first file (-1) by the second column</span><br><span class="line"># and the second file (-2) by the first</span><br><span class="line">join -t &quot;,&quot; -1 2 -2 1 first_file.txt second_file.txt</span><br></pre></td></tr></table></figure><p>标准的 <code>join</code> 是内连接。然而，外连接通过 <code>-a</code> 选项也是可行的。另一个值得一提的技巧是 <code>-q</code> 标志，如果发现有缺失的字段，可用于替换值。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Outer join, replace blanks with NULL in columns 1 and 2</span><br><span class="line"># -o which fields to substitute - 0 is key, 1.1 is first column, etc...</span><br><span class="line">join -t&quot;,&quot; -1 2 -a 1 -a2 -e &#x27; NULL&#x27; -o &#x27;0,1.1,2.2&#x27; first_file.txt second_file.txt</span><br></pre></td></tr></table></figure><p>它不是最用户友好的命令，而是绝望时刻的绝望措施。</p><p>实用选项：</p><ul><li><code>join -a</code> 打印不可配对的行</li><li><code>join -e</code> 替换丢失的输入字段</li><li><code>join -j</code> 相当于 <code>-1 FIELD -2 FIELD</code></li></ul><h3 id="GREP"><a href="#GREP" class="headerlink" title="GREP"></a>GREP</h3><p><code>grep</code> 即 <ruby>用正则表达式全局搜索并且打印 <rt>Global search for a Regular Expression and Print</rt></ruby>，可能是最有名的命令，并且名副其实。<code>grep</code> 很强大，特别适合在大型代码库中查找。在数据科学的王国里，它充当其他命令的提炼机制。虽然它的标准用途也很有价值。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Recursively search and list all files in directory containing &#x27;word&#x27;</span><br><span class="line"></span><br><span class="line">grep -lr &#x27;word&#x27; .</span><br><span class="line"></span><br><span class="line"># List number of files containing word</span><br><span class="line"></span><br><span class="line">grep -lr &#x27;word&#x27; . | wc -l</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>计算包含单词或模式的总行数。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">grep -c &#x27;some_value&#x27; filename.csv</span><br><span class="line"></span><br><span class="line"># Same thing, but in all files in current directory by file name</span><br><span class="line"></span><br><span class="line">grep -c &#x27;some_value&#x27; *</span><br></pre></td></tr></table></figure><p>对多个值使用“或”运算符： <code>\|</code>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep &quot;first_value\|second_value&quot; filename.csv</span><br></pre></td></tr></table></figure><p>实用选项：</p><ul><li><code>alias grep=&quot;grep --color=auto&quot;</code> 使 grep 色彩丰富</li><li><code>grep -E</code> 使用扩展正则表达式</li><li><code>grep -w</code> 只匹配整个单词</li><li><code>grep -l</code> 打印匹配的文件名</li><li><code>grep -v</code> 非匹配</li></ul><h3 id="大人物们"><a href="#大人物们" class="headerlink" title="大人物们"></a>大人物们</h3><p><code>sed</code> 和 <code>awk</code> 是本文中最强大的两个命令。为简洁起见，我不打算详细讨论这两个命令。相反，我将介绍各种能证明其令人印象深刻的力量的命令。如果你想了解更多，<a target="_blank" rel="noopener" href="https://www.amazon.com/sed-awk-Dale-Dougherty/dp/1565922255/ref=sr_1_1?ie=UTF8&qid=1524381457&sr=8-1&keywords=sed+and+awk">这儿就有一本书</a>是关于它们的。</p><h3 id="SED"><a href="#SED" class="headerlink" title="SED"></a>SED</h3><p><code>sed</code> 本质上是一个流编辑器。它擅长替换，但也可以用于所有输出重构。</p><p>最基本的 <code>sed</code> 命令由 <code>s/old/new/g</code> 组成。它的意思是搜索 <code>old</code>，全局替换为 <code>new</code>。 如果没有 <code>/g</code>，我们的命令将在 <code>old</code> 第一次出现后终止。</p><p>为了快速了解它的功能，我们可以深入了解一个例子。 在以下情景中，你已有以下文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">balance,name</span><br><span class="line">$1,000,john</span><br><span class="line">$2,000,jack</span><br></pre></td></tr></table></figure><p>我们可能想要做的第一件事是删除美元符号。<code>-i</code> 标志表示原位。<code>&#39;&#39;</code> 表示零长度文件扩展名，从而覆盖我们的初始文件。理想情况下，你可以单独测试，然后输出到新文件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sed -i &#x27;&#x27; &#x27;s/\$//g&#x27; data.txt</span><br><span class="line"># balance,name</span><br><span class="line"># 1,000,john</span><br><span class="line"># 2,000,jack</span><br></pre></td></tr></table></figure><p>接下来，去除 <code>blance</code> 列的逗号。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sed -i &#x27;&#x27; &#x27;s/\([0-9]\),\([0-9]\)/\1\2/g&#x27; data.txt</span><br><span class="line"># balance,name</span><br><span class="line"># 1000,john</span><br><span class="line"># 2000,jack</span><br></pre></td></tr></table></figure><p>最后 jack 有一天决定辞职。所以，再见了，我的朋友。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sed -i &#x27;&#x27; &#x27;/jack/d&#x27; data.txt</span><br><span class="line"># balance,name</span><br><span class="line"># 1000,john</span><br></pre></td></tr></table></figure><p>正如你所看到的，<code>sed</code> 有很多强大的功能，但乐趣并不止于此。</p><h3 id="AWK"><a href="#AWK" class="headerlink" title="AWK"></a>AWK</h3><p>最好的留在最后。<code>awk</code> 不仅仅是一个简单的命令：它是一个成熟的语言。在本文中涉及的所有内容中，<code>awk</code> 是目前为止最酷的。如果你感兴趣，这里有很多很棒的资源 —— 看 <a target="_blank" rel="noopener" href="https://www.amazon.com/AWK-Programming-Language-Alfred-Aho/dp/020107981X/ref=sr_1_1?ie=UTF8&qid=1524388936&sr=8-1&keywords=awk">这里</a>、<a target="_blank" rel="noopener" href="http://www.grymoire.com/Unix/Awk.html">这里</a> 和 <a target="_blank" rel="noopener" href="https://www.tutorialspoint.com/awk/index.htm">这里</a>。</p><p><code>awk</code> 的常见用例包括：</p><ul><li>文字处理</li><li>格式化文本报告</li><li>执行算术运算</li><li>执行字符串操作</li></ul><p><code>awk</code> 可以以最原生的形式并行 <code>grep</code>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk &#x27;/word/&#x27; filename.csv</span><br></pre></td></tr></table></figure><p>或者更加神奇：将 <code>grep</code> 和 <code>cut</code> 组合起来。在这里，对于所有带我们指定单词 <code>word</code> 的行，<code>awk</code> 打印第三和第四列，用 <code>tab</code> 分隔。<code>-F,</code> 用于指定切分时的列分隔符为逗号。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk -F, &#x27;/word/ &#123; print $3 &quot;\t&quot; $4 &#125;&#x27; filename.csv</span><br></pre></td></tr></table></figure><p><code>awk</code> 内置了许多精巧的变量。比如，<code>NF</code> —— 字段数，和 <code>NR</code> —— 记录数。要获取文件中的第 53 条记录：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk -F, &#x27;NR == 53&#x27; filename.csv</span><br></pre></td></tr></table></figure><p>更多的花招是其基于一个或多个值进行过滤的能力。下面的第一个示例将打印第一列等于给定字符串的行的行号和列。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">awk -F, &#x27; $1 == &quot;string&quot; &#123; print NR, $0 &#125; &#x27; filename.csv</span><br><span class="line"></span><br><span class="line"># Filter based off of numerical value in second column</span><br><span class="line">awk -F, &#x27; $2 == 1000 &#123; print NR, $0 &#125; &#x27; filename.csv</span><br></pre></td></tr></table></figure><p>多个数值表达式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Print line number and columns where column three greater</span><br><span class="line"># than 2005 and column five less than one thousand</span><br><span class="line"></span><br><span class="line">awk -F, &#x27; $3 &gt;= 2005 &amp;&amp; $5 &lt;= 1000 &#123; print NR, $0 &#125; &#x27; filename.csv</span><br></pre></td></tr></table></figure><p>求出第三列的总和：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk -F, &#x27;&#123; x+=$3 &#125; END &#123; print x &#125;&#x27; filename.csv</span><br></pre></td></tr></table></figure><p>在第一列等于 <code>something</code> 的那些行，求出第三列值的总和。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk -F, &#x27;$1 == &quot;something&quot; &#123; x+=$3 &#125; END &#123; print x &#125;&#x27; filename.csv</span><br></pre></td></tr></table></figure><p>获取文件的行列数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">awk -F, &#x27;END &#123; print NF, NR &#125;&#x27; filename.csv</span><br><span class="line"></span><br><span class="line"># Prettier version</span><br><span class="line">awk -F, &#x27;BEGIN &#123; print &quot;COLUMNS&quot;, &quot;ROWS&quot; &#125;; END &#123; print NF, NR &#125;&#x27; filename.csv</span><br></pre></td></tr></table></figure><p>打印出现了两次的行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk -F, &#x27;++seen[$0] == 2&#x27; filename.csv</span><br></pre></td></tr></table></figure><p>删除重复的行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Consecutive lines</span><br><span class="line">awk &#x27;a !~ $0; &#123;a=$0&#125;&#x27;]</span><br><span class="line"></span><br><span class="line"># Nonconsecutive lines</span><br><span class="line">awk &#x27;! a[$0]++&#x27; filename.csv</span><br><span class="line"></span><br><span class="line"># More efficient</span><br><span class="line">awk &#x27;!($0 in a) &#123;a[$0];print&#125;</span><br></pre></td></tr></table></figure><p>使用内置函数 <code>gsub()</code> 替换多个值。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk &#x27;&#123;gsub(/scarlet|ruby|puce/, &quot;red&quot;); print&#125;&#x27;</span><br></pre></td></tr></table></figure><p>这个 <code>awk</code> 命令将组合多个 CSV 文件，忽略标题，然后在最后附加它。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk &#x27;FNR==1 &amp;&amp; NR!=1&#123;next;&#125;&#123;print&#125;&#x27; *.csv &gt; final_file.csv</span><br></pre></td></tr></table></figure><p>需要缩小一个庞大的文件？ <code>awk</code> 可以在 <code>sed</code> 的帮助下处理它。具体来说，该命令根据行数将一个大文件分成多个较小的文件。这个一行脚本将增加一个扩展名。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sed &#x27;1d;$d&#x27; filename.csv | awk &#x27;NR%NUMBER_OF_LINES==1&#123;x=&quot;filename-&quot;++i&quot;.csv&quot;;&#125;&#123;print &gt; x&#125;&#x27;</span><br><span class="line"></span><br><span class="line"># Example: splitting big_data.csv into data_(n).csv every 100,000 lines</span><br><span class="line">sed &#x27;1d;$d&#x27; big_data.csv | awk &#x27;NR%100000==1&#123;x=&quot;data_&quot;++i&quot;.csv&quot;;&#125;&#123;print &gt; x&#125;&#x27;</span><br></pre></td></tr></table></figure><h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><p>命令行拥有无穷无尽的力量。本文中介绍的命令足以将你从一无所知提升到英雄人物。除了涵盖的内容之外，还有许多实用程序可以考虑用于日常数据操作。<a target="_blank" rel="noopener" href="http://csvkit.readthedocs.io/en/1.0.3/">Csvkit</a>、<a target="_blank" rel="noopener" href="https://github.com/BurntSushi/xsv">xsv</a> 还有 <a target="_blank" rel="noopener" href="https://github.com/harelba/q">q</a> 是需要记住的三个。如果你希望更深入地了解命令行数据科学，查看<a target="_blank" rel="noopener" href="https://www.amazon.com/Data-Science-Command-Line-Time-Tested/dp/1491947853/ref=sr_1_1?ie=UTF8&qid=1524390894&sr=8-1&keywords=data+science+at+the+command+line">这本书</a>。它也可以<a target="_blank" rel="noopener" href="https://www.datascienceatthecommandline.com/">免费</a>在线获得！</p><hr><p>via: <a target="_blank" rel="noopener" href="http://kadekillary.work/post/cli-4-ds/">http://kadekillary.work/post/cli-4-ds/</a></p><p>作者：<a target="_blank" rel="noopener" href="http://kadekillary.work/authors/kadekillary">Kade Killary</a> 选题：<a target="_blank" rel="noopener" href="https://github.com/lujun9972">lujun9972</a> 译者：<a target="_blank" rel="noopener" href="https://github.com/graveaccent">GraveAccent</a> 校对：<a target="_blank" rel="noopener" href="https://github.com/wxy">wxy</a></p><p>本文由 <a target="_blank" rel="noopener" href="https://github.com/LCTT/TranslateProject">LCTT</a> 原创编译，<a target="_blank" rel="noopener" href="https://linux.cn/">Linux中国</a> 荣誉推出</p></div></div></div><div class="footer"><p class="footer-copyright"><span>Powered by <a target="_blank" href="https://hexo.io">Hexo</a></span> <span>Theme <a target="_blank" href="https://github.com/tinkink-co/hexo-theme-terminal">Terminal</a></span><script type="text/javascript" src="https://cdn.staticfile.net/jquery/3.4.1/jquery.min.js"></script><script>getCDNinfo=function(){$.ajax({url:"/cdn-cgi/trace",success:function(a,n){let i="Antananarivo, Madagascar - (TNR);Cape Town, South Africa - (CPT);Casablanca, Morocco - (CMN);Dar Es Salaam, Tanzania - (DAR);Djibouti City, Djibouti - (JIB);Durban, South Africa - (DUR);Johannesburg, South Africa - (JNB);Kigali, Rwanda - (KGL);Lagos, Nigeria - (LOS);Luanda, Angola - (LAD);Maputo, MZ - (MPM);Mombasa, Kenya - (MBA);Port Louis, Mauritius - (MRU);Réunion, France - (RUN);Bangalore, India - (BLR);Bangkok, Thailand - (BKK);Bandar Seri Begawan, Brunei - (BWN);Cebu, Philippines - (CEB);Chengdu, China - (CTU);Chennai, India - (MAA);Chittagong, Bangladesh - (CGP);Chongqing, China - (CKG);Colombo, Sri Lanka - (CMB);Dhaka, Bangladesh - (DAC);Dongguan, China - (SZX);Foshan, China - (FUO);Fuzhou, China - (FOC);Guangzhou, China - (CAN);Hangzhou, China - (HGH);Hanoi, Vietnam - (HAN);Hengyang, China - (HNY);Ho Chi Minh City, Vietnam - (SGN);Hong Kong - (HKG);Hyderabad, India - (HYD);Islamabad, Pakistan - (ISB);Jakarta, Indonesia - (CGK);Jinan, China - (TNA);Karachi, Pakistan - (KHI);Kathmandu, Nepal - (KTM);Kolkata, India - (CCU);Kuala Lumpur, Malaysia - (KUL);Lahore, Pakistan - (LHE);Langfang, China - (NAY);Luoyang, China - (LYA);Macau - (MFM);Malé, Maldives - (MLE);Manila, Philippines - (MNL);Mumbai, India - (BOM);Nagpur, India - (NAG);Nanning, China - (NNG);New Delhi, India - (DEL);Osaka, Japan - (KIX);Phnom Penh, Cambodia - (PNH);Qingdao, China - (TAO);Seoul, South Korea - (ICN);Shanghai, China - (SHA);Shenyang, China - (SHE);Shijiazhuang, China - (SJW);Singapore, Singapore - (SIN);Suzhou, China - (SZV);Taipei - (TPE);Thimphu, Bhutan - (PBH);Tianjin, China - (TSN);Tokyo, Japan - (NRT);Ulaanbaatar, Mongolia - (ULN);Vientiane, Laos - (VTE);Wuhan, China - (WUH);Wuxi, China - (WUX);Xi'an, China - (XIY);Yerevan, Armenia - (EVN);Zhengzhou, China - (CGO);Zuzhou, China - (CSX);Amsterdam, Netherlands - (AMS);Athens, Greece - (ATH);Barcelona, Spain - (BCN);Belgrade, Serbia - (BEG);Berlin, Germany - (TXL);Brussels, Belgium - (BRU);Bucharest, Romania - (OTP);Budapest, Hungary - (BUD);Chișinău, Moldova - (KIV);Copenhagen, Denmark - (CPH);Cork, Ireland -  (ORK);Dublin, Ireland - (DUB);Düsseldorf, Germany - (DUS);Edinburgh, United Kingdom - (EDI);Frankfurt, Germany - (FRA);Geneva, Switzerland - (GVA);Gothenburg, Sweden - (GOT);Hamburg, Germany - (HAM);Helsinki, Finland - (HEL);Istanbul, Turkey - (IST);Kyiv, Ukraine - (KBP);Lisbon, Portugal - (LIS);London, United Kingdom - (LHR);Luxembourg City, Luxembourg - (LUX);Madrid, Spain - (MAD);Manchester, United Kingdom - (MAN);Marseille, France - (MRS);Milan, Italy - (MXP);Moscow, Russia - (DME);Munich, Germany - (MUC);Nicosia, Cyprus - (LCA);Oslo, Norway - (OSL);Paris, France - (CDG);Prague, Czech Republic - (PRG);Reykjavík, Iceland - (KEF);Riga, Latvia - (RIX);Rome, Italy - (FCO);Saint Petersburg, Russia - (LED);Sofia, Bulgaria - (SOF);Stockholm, Sweden - (ARN);Tallinn, Estonia - (TLL);Thessaloniki, Greece - (SKG);Vienna, Austria - (VIE);Vilnius, Lithuania - (VNO);Warsaw, Poland - (WAW);Zagreb, Croatia - (ZAG);Zürich, Switzerland - (ZRH);Arica, Chile - (ARI);Asunción, Paraguay - (ASU);Bogotá, Colombia - (BOG);Buenos Aires, Argentina - (EZE);Curitiba, Brazil - (CWB);Fortaleza, Brazil - (FOR);Guatemala City, Guatemala - (GUA);Lima, Peru - (LIM);Medellín, Colombia - (MDE);Panama City, Panama - (PTY);Porto Alegre, Brazil - (POA);Quito, Ecuador - (UIO);Rio de Janeiro, Brazil - (GIG);São Paulo, Brazil - (GRU);Santiago, Chile - (SCL);Willemstad, Curaçao - (CUR);St. George's, Grenada - (GND);Amman, Jordan - (AMM);Baghdad, Iraq - (BGW);Baku, Azerbaijan - (GYD);Beirut, Lebanon - (BEY);Doha, Qatar - (DOH);Dubai, United Arab Emirates - (DXB);Kuwait City, Kuwait - (KWI);Manama, Bahrain - (BAH);Muscat, Oman - (MCT);Ramallah - (ZDM);Riyadh, Saudi Arabia - (RUH);Tel Aviv, Israel - (TLV);Ashburn, VA, United States - (IAD);Atlanta, GA, United States - (ATL);Boston, MA, United States - (BOS);Buffalo, NY, United States - (BUF);Calgary, AB, Canada - (YYC);Charlotte, NC, United States - (CLT);Chicago, IL, United States - (ORD);Columbus, OH, United States - (CMH);Dallas, TX, United States - (DFW);Denver, CO, United States - (DEN);Detroit, MI, United States - (DTW);Honolulu, HI, United States - (HNL);Houston, TX, United States - (IAH);Indianapolis, IN, United States - (IND);Jacksonville, FL, United States - (JAX);Kansas City, MO, United States - (MCI);Las Vegas, NV, United States - (LAS);Los Angeles, CA, United States - (LAX);McAllen, TX, United States - (MFE);Memphis, TN, United States - (MEM);Mexico City, Mexico - (MEX);Miami, FL, United States - (MIA);Minneapolis, MN, United States - (MSP);Montgomery, AL, United States - (MGM);Montréal, QC, Canada - (YUL);Nashville, TN, United States - (BNA);Newark, NJ, United States - (EWR);Norfolk, VA, United States - (ORF);Omaha, NE, United States - (OMA);Philadelphia, United States - (PHL);Phoenix, AZ, United States - (PHX);Pittsburgh, PA, United States - (PIT);Port-Au-Prince, Haiti - (PAP);Portland, OR, United States - (PDX);Queretaro, MX, Mexico - (QRO);Richmond, Virginia - (RIC);Sacramento, CA, United States - (SMF);Salt Lake City, UT, United States - (SLC);San Diego, CA, United States - (SAN);San Jose, CA, United States - (SJC);Saskatoon, SK, Canada - (YXE);Seattle, WA, United States - (SEA);St. Louis, MO, United States - (STL);Tampa, FL, United States - (TPA);Toronto, ON, Canada - (YYZ);Vancouver, BC, Canada - (YVR);Tallahassee, FL, United States - (TLH);Winnipeg, MB, Canada - (YWG);Adelaide, SA, Australia - (ADL);Auckland, New Zealand - (AKL);Brisbane, QLD, Australia - (BNE);Melbourne, VIC, Australia - (MEL);Noumea, New caledonia - (NOU);Perth, WA, Australia - (PER);Sydney, NSW, Australia - (SYD)".split(";"),e=a.split("colo=")[1].split("\n")[0],t=(a.split("colo=")[1].split("\n")[0],a.split("tls=")[1].split("\n")[0]),o=a.split("http=")[1].split("\n")[0],s=a.split("sni=")[1].split("\n")[0],r=a.split("ip=")[1].split("\n")[0],l=a.split("uag=")[1].split("\n")[0];for(var d=0;d<i.length;d++)if(-1!=i[d].indexOf(e)){document.getElementById("cdn").innerHTML=i[d];break}document.getElementById("tls").innerHTML=t,document.getElementById("http").innerHTML=o,document.getElementById("sni").innerHTML=s,document.getElementById("ip").innerHTML=r,document.getElementById("useragent").innerHTML=l}})},$(document).ready((function(){getCDNinfo()}))</script></p><p style="text-align:center">感谢陪伴与布道，开源之火不灭。​</p><p style="text-align:center"><script>document.write("本次加载耗时: "+(performance.getEntriesByType("navigation").reduce((e,r)=>e+r.responseEnd-r.startTime,0)+performance.getEntriesByType("resource").reduce((e,r)=>e+r.responseEnd-r.startTime,0)).toFixed(0)+"ms")</script></p><p style="text-align:center">当前 SNI 状态： <span id="sni">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 TLS 版本： <span id="tls">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 HTTP 版本： <span id="http">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前您的客户端 IP 是： <span id="ip">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前分配的 CDN 节点是: <span id="cdn">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">您的 UserAgent 信息是: <span id="useragent">正在统计！或可能被浏览器防追踪拦截！</span></p><p></p><script defer src="https://pv.undefined.today/tracker.min.js" data-website-id="LinuxCNMirror-tracker"></script></div></div></body></html>