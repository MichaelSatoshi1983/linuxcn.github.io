<!doctype html><html lang="en"><head><meta name="msvalidate.01" content="D404690CEFCB54C7762AC84935B99171"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?6618da70c90c8744eead2e9371fb5077";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script type="text/javascript">!function(t,e,n,c,s,a,r){t[n]=t[n]||function(){(t[n].q=t[n].q||[]).push(arguments)},(a=e.createElement(c)).async=1,a.src="https://www.clarity.ms/tag/s5f3f0tojf",(r=e.getElementsByTagName(c)[0]).parentNode.insertBefore(a,r)}(window,document,"clarity","script")</script><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta http-equiv="X-UA-Compatible" content="ie=edge"><link rel="stylesheet" href="/styles/base.css"><link rel="stylesheet" href="/styles/theme.css"><link rel="shortcut icon" href="/favicon.png"><title>并发服务器（四）：libuv - 归墟星火集 又一个 LinuxCN 站点</title><meta name="generator" content="Hexo 7.3.0"></head><body><div class="header-title"><span class="header-light"></span> <span class="header-light"></span> <span class="header-light"></span> <span>归墟星火集 又一个 LinuxCN 站点 linuxcn.undefined.today<span></span></span></div><div class="container"><ul class="nav"><li><a href="/">首页</a></li><li><a target="_blank" rel="noopener" href="https://undefined.today/">Blog</a></li></ul><div class="content"><div class="post-container"><div class="post-header"><span class="ui-tips">标题：</span><h1 class="ui-keyword post-title">并发服务器（四）：libuv</h1><span class="post-date">2018-03-02</span></div><div class="post-header"><span class="ui-tips">分类：</span> <a href="/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">软件开发</a></div><div class="post-header"><span class="ui-tips">标签：</span> <a href="/tags/%E5%B9%B6%E5%8F%91/">并发</a></div><div class="post-content"><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201803/02/012014luutflxu75l56ffn.jpg"></p><p>这是并发网络服务器系列文章的第四部分。在这一部分中，我们将使用 libuv 再次重写我们的服务器，并且也会讨论关于使用一个线程池在回调中去处理耗时任务。最终，我们去看一下底层的 libuv，花一点时间去学习如何用异步 API 对文件系统阻塞操作进行封装。</p><p>本系列的所有文章：</p><ul><li><a href="/article-8993-1.html">第一节 - 简介</a></li><li><a href="/article-9002-1.html">第二节 - 线程</a></li><li><a href="/article-9117-1.html">第三节 - 事件驱动</a></li><li><a target="_blank" rel="noopener" href="http://eli.thegreenplace.net/2017/concurrent-servers-part-4-libuv/">第四节 - libuv</a></li></ul><h3 id="使用-libuv-抽象出事件驱动循环"><a href="#使用-libuv-抽象出事件驱动循环" class="headerlink" title="使用 libuv 抽象出事件驱动循环"></a>使用 libuv 抽象出事件驱动循环</h3><p>在 <a href="/article-9117-1.html">第三节</a> 中，我们看到了基于 <code>select</code> 和 <code>epoll</code> 的服务器的相似之处，并且，我说过，在它们之间抽象出细微的差别是件很有吸引力的事。许多库已经做到了这些，所以在这一部分中我将去选一个并使用它。我选的这个库是 <a target="_blank" rel="noopener" href="http://libuv.org/">libuv</a>，它最初设计用于 Node.js 底层的可移植平台层，并且，后来发现在其它的项目中也有使用。libuv 是用 C 写的，因此，它具有很高的可移植性，非常适用嵌入到像 JavaScript 和 Python 这样的高级语言中。</p><p>虽然 libuv 为了抽象出底层平台细节已经变成了一个相当大的框架，但它仍然是以 <em>事件循环</em> 思想为中心的。在我们第三部分的事件驱动服务器中，事件循环是显式定义在 <code>main</code> 函数中的；当使用 libuv 时，该循环通常隐藏在库自身中，而用户代码仅需要注册事件句柄（作为一个回调函数）和运行这个循环。此外，libuv 会在给定的平台上使用更快的事件循环实现，对于 Linux 它是 <code>epoll</code>，等等。</p><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201803/02/012056juwug04uzgz0w77w.png" alt="libuv loop"></p><p>libuv 支持多路事件循环，因此事件循环在库中是非常重要的；它有一个句柄 —— <code>uv_loop_t</code>，以及创建&#x2F;杀死&#x2F;启动&#x2F;停止循环的函数。也就是说，在这篇文章中，我将仅需要使用 “默认的” 循环，libuv 可通过 <code>uv_default_loop()</code> 提供它；多路循环大多用于多线程事件驱动的服务器，这是一个更高级别的话题，我将留在这一系列文章的以后部分。</p><h3 id="使用-libuv-的并发服务器"><a href="#使用-libuv-的并发服务器" class="headerlink" title="使用 libuv 的并发服务器"></a>使用 libuv 的并发服务器</h3><p>为了对 libuv 有一个更深的印象，让我们跳转到我们的可靠协议的服务器，它通过我们的这个系列已经有了一个强大的重新实现。这个服务器的结构与第三部分中的基于 <code>select</code> 和 <code>epoll</code> 的服务器有一些相似之处，因为，它也依赖回调。完整的 <a target="_blank" rel="noopener" href="https://github.com/eliben/code-for-blog/blob/master/2017/async-socket-server/uv-server.c">示例代码在这里</a>；我们开始设置这个服务器的套接字绑定到一个本地端口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">int portnum = 9090;</span><br><span class="line">if (argc &gt;= 2) &#123;</span><br><span class="line">  portnum = atoi(argv[1]);</span><br><span class="line">&#125;</span><br><span class="line">printf(&quot;Serving on port %d\n&quot;, portnum);</span><br><span class="line"></span><br><span class="line">int rc;</span><br><span class="line">uv_tcp_t server_stream;</span><br><span class="line">if ((rc = uv_tcp_init(uv_default_loop(), &amp;server_stream)) &lt; 0) &#123;</span><br><span class="line">  die(&quot;uv_tcp_init failed: %s&quot;, uv_strerror(rc));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">struct sockaddr_in server_address;</span><br><span class="line">if ((rc = uv_ip4_addr(&quot;0.0.0.0&quot;, portnum, &amp;server_address)) &lt; 0) &#123;</span><br><span class="line">  die(&quot;uv_ip4_addr failed: %s&quot;, uv_strerror(rc));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if ((rc = uv_tcp_bind(&amp;server_stream, (const struct sockaddr*)&amp;server_address, 0)) &lt; 0) &#123;</span><br><span class="line">  die(&quot;uv_tcp_bind failed: %s&quot;, uv_strerror(rc));</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>除了它被封装进 libuv API 中之外，你看到的是一个相当标准的套接字。在它的返回中，我们取得了一个可工作于任何 libuv 支持的平台上的可移植接口。</p><p>这些代码也展示了很认真负责的错误处理；多数的 libuv 函数返回一个整数状态，返回一个负数意味着出现了一个错误。在我们的服务器中，我们把这些错误看做致命问题进行处理，但也可以设想一个更优雅的错误恢复。</p><p>现在，那个套接字已经绑定，是时候去监听它了。这里我们运行首个回调注册：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// Listen on the socket for new peers to connect. When a new peer connects,</span><br><span class="line">// the on_peer_connected callback will be invoked.</span><br><span class="line">if ((rc = uv_listen((uv_stream_t*)&amp;server_stream, N_BACKLOG, on_peer_connected)) &lt; 0) &#123;</span><br><span class="line">  die(&quot;uv_listen failed: %s&quot;, uv_strerror(rc));</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>uv_listen</code> 注册一个事件回调，当新的对端连接到这个套接字时将会调用事件循环。我们的回调在这里被称为 <code>on_peer_connected</code>，我们一会儿将去查看它。</p><p>最终，<code>main</code> 运行这个 libuv 循环，直到它被停止（<code>uv_run</code> 仅在循环被停止或者发生错误时返回）。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// Run the libuv event loop.</span><br><span class="line">uv_run(uv_default_loop(), UV_RUN_DEFAULT);</span><br><span class="line"></span><br><span class="line">// If uv_run returned, close the default loop before exiting.</span><br><span class="line">return uv_loop_close(uv_default_loop());</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>注意，在运行事件循环之前，只有一个回调是通过 <code>main</code> 注册的；我们稍后将看到怎么去添加更多的回调。在事件循环的整个运行过程中，添加和删除回调并不是一个问题 —— 事实上，大多数服务器就是这么写的。</p><p>这是一个 <code>on_peer_connected</code>，它处理到服务器的新的客户端连接：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">void on_peer_connected(uv_stream_t* server_stream, int status) &#123;</span><br><span class="line">  if (status &lt; 0) &#123;</span><br><span class="line">    fprintf(stderr, &quot;Peer connection error: %s\n&quot;, uv_strerror(status));</span><br><span class="line">    return;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // client will represent this peer; it&#x27;s allocated on the heap and only</span><br><span class="line">  // released when the client disconnects. The client holds a pointer to</span><br><span class="line">  // peer_state_t in its data field; this peer state tracks the protocol state</span><br><span class="line">  // with this client throughout interaction.</span><br><span class="line">  uv_tcp_t* client = (uv_tcp_t*)xmalloc(sizeof(*client));</span><br><span class="line">  int rc;</span><br><span class="line">  if ((rc = uv_tcp_init(uv_default_loop(), client)) &lt; 0) &#123;</span><br><span class="line">    die(&quot;uv_tcp_init failed: %s&quot;, uv_strerror(rc));</span><br><span class="line">  &#125;</span><br><span class="line">  client-&gt;data = NULL;</span><br><span class="line"></span><br><span class="line">  if (uv_accept(server_stream, (uv_stream_t*)client) == 0) &#123;</span><br><span class="line">    struct sockaddr_storage peername;</span><br><span class="line">    int namelen = sizeof(peername);</span><br><span class="line">    if ((rc = uv_tcp_getpeername(client, (struct sockaddr*)&amp;peername,</span><br><span class="line">                                 &amp;namelen)) &lt; 0) &#123;</span><br><span class="line">      die(&quot;uv_tcp_getpeername failed: %s&quot;, uv_strerror(rc));</span><br><span class="line">    &#125;</span><br><span class="line">    report_peer_connected((const struct sockaddr_in*)&amp;peername, namelen);</span><br><span class="line"></span><br><span class="line">    // Initialize the peer state for a new client: we start by sending the peer</span><br><span class="line">    // the initial &#x27;*&#x27; ack.</span><br><span class="line">    peer_state_t* peerstate = (peer_state_t*)xmalloc(sizeof(*peerstate));</span><br><span class="line">    peerstate-&gt;state = INITIAL_ACK;</span><br><span class="line">    peerstate-&gt;sendbuf[0] = &#x27;*&#x27;;</span><br><span class="line">    peerstate-&gt;sendbuf_end = 1;</span><br><span class="line">    peerstate-&gt;client = client;</span><br><span class="line">    client-&gt;data = peerstate;</span><br><span class="line"></span><br><span class="line">    // Enqueue the write request to send the ack; when it&#x27;s done,</span><br><span class="line">    // on_wrote_init_ack will be called. The peer state is passed to the write</span><br><span class="line">    // request via the data pointer; the write request does not own this peer</span><br><span class="line">    // state - it&#x27;s owned by the client handle.</span><br><span class="line">    uv_buf_t writebuf = uv_buf_init(peerstate-&gt;sendbuf, peerstate-&gt;sendbuf_end);</span><br><span class="line">    uv_write_t* req = (uv_write_t*)xmalloc(sizeof(*req));</span><br><span class="line">    req-&gt;data = peerstate;</span><br><span class="line">    if ((rc = uv_write(req, (uv_stream_t*)client, &amp;writebuf, 1,</span><br><span class="line">                       on_wrote_init_ack)) &lt; 0) &#123;</span><br><span class="line">      die(&quot;uv_write failed: %s&quot;, uv_strerror(rc));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">    uv_close((uv_handle_t*)client, on_client_closed);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这些代码都有很好的注释，但是，这里有一些重要的 libuv 语法我想去强调一下：</p><ul><li>传入自定义数据到回调中：因为 C 语言还没有闭包，这可能是个挑战，libuv 在它的所有的处理类型中有一个 <code>void* data</code> 字段；这些字段可以被用于传递用户数据。例如，注意 <code>client-&gt;data</code> 是如何指向到一个 <code>peer_state_t</code> 结构上，以便于 <code>uv_write</code> 和 <code>uv_read_start</code> 注册的回调可以知道它们正在处理的是哪个客户端的数据。</li><li>内存管理：在带有垃圾回收的语言中进行事件驱动编程是非常容易的，因为，回调通常运行在一个与它们注册的地方完全不同的栈帧中，使得基于栈的内存管理很困难。它总是需要传递堆分配的数据到 libuv 回调中（当所有回调运行时，除了 <code>main</code>，其它的都运行在栈上），并且，为了避免泄漏，许多情况下都要求这些数据去安全释放（<code>free()</code>）。这些都是些需要实践的内容 <sup>注1</sup> 。</li></ul><p>这个服务器上对端的状态如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">typedef struct &#123;</span><br><span class="line">  ProcessingState state;</span><br><span class="line">  char sendbuf[SENDBUF_SIZE];</span><br><span class="line">  int sendbuf_end;</span><br><span class="line">  uv_tcp_t* client;</span><br><span class="line">&#125; peer_state_t;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>它与第三部分中的状态非常类似；我们不再需要 <code>sendptr</code>，因为，在调用 “done writing” 回调之前，<code>uv_write</code> 将确保发送它提供的整个缓冲。我们也为其它的回调使用保持了一个到客户端的指针。这里是 <code>on_wrote_init_ack</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">void on_wrote_init_ack(uv_write_t* req, int status) &#123;</span><br><span class="line">  if (status) &#123;</span><br><span class="line">    die(&quot;Write error: %s\n&quot;, uv_strerror(status));</span><br><span class="line">  &#125;</span><br><span class="line">  peer_state_t* peerstate = (peer_state_t*)req-&gt;data;</span><br><span class="line">  // Flip the peer state to WAIT_FOR_MSG, and start listening for incoming data</span><br><span class="line">  // from this peer.</span><br><span class="line">  peerstate-&gt;state = WAIT_FOR_MSG;</span><br><span class="line">  peerstate-&gt;sendbuf_end = 0;</span><br><span class="line"></span><br><span class="line">  int rc;</span><br><span class="line">  if ((rc = uv_read_start((uv_stream_t*)peerstate-&gt;client, on_alloc_buffer,</span><br><span class="line">                          on_peer_read)) &lt; 0) &#123;</span><br><span class="line">    die(&quot;uv_read_start failed: %s&quot;, uv_strerror(rc));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // Note: the write request doesn&#x27;t own the peer state, hence we only free the</span><br><span class="line">  // request itself, not the state.</span><br><span class="line">  free(req);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>然后，我们确信知道了这个初始的 <code>&#39;*&#39;</code> 已经被发送到对端，我们通过调用 <code>uv_read_start</code> 去监听从这个对端来的入站数据，它注册一个将被事件循环调用的回调（<code>on_peer_read</code>），不论什么时候，事件循环都在套接字上接收来自客户端的调用：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">void on_peer_read(uv_stream_t* client, ssize_t nread, const uv_buf_t* buf) &#123;</span><br><span class="line">  if (nread &lt; 0) &#123;</span><br><span class="line">    if (nread != uv_eof) &#123;</span><br><span class="line">      fprintf(stderr, &quot;read error: %s\n&quot;, uv_strerror(nread));</span><br><span class="line">    &#125;</span><br><span class="line">    uv_close((uv_handle_t*)client, on_client_closed);</span><br><span class="line">  &#125; else if (nread == 0) &#123;</span><br><span class="line">    // from the documentation of uv_read_cb: nread might be 0, which does not</span><br><span class="line">    // indicate an error or eof. this is equivalent to eagain or ewouldblock</span><br><span class="line">    // under read(2).</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">    // nread &gt; 0</span><br><span class="line">    assert(buf-&gt;len &gt;= nread);</span><br><span class="line"></span><br><span class="line">    peer_state_t* peerstate = (peer_state_t*)client-&gt;data;</span><br><span class="line">    if (peerstate-&gt;state == initial_ack) &#123;</span><br><span class="line">      // if the initial ack hasn&#x27;t been sent for some reason, ignore whatever</span><br><span class="line">      // the client sends in.</span><br><span class="line">      free(buf-&gt;base);</span><br><span class="line">      return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // run the protocol state machine.</span><br><span class="line">    for (int i = 0; i &lt; nread; ++i) &#123;</span><br><span class="line">      switch (peerstate-&gt;state) &#123;</span><br><span class="line">      case initial_ack:</span><br><span class="line">        assert(0 &amp;&amp; &quot;can&#x27;t reach here&quot;);</span><br><span class="line">        break;</span><br><span class="line">      case wait_for_msg:</span><br><span class="line">        if (buf-&gt;base[i] == &#x27;^&#x27;) &#123;</span><br><span class="line">          peerstate-&gt;state = in_msg;</span><br><span class="line">        &#125;</span><br><span class="line">        break;</span><br><span class="line">      case in_msg:</span><br><span class="line">        if (buf-&gt;base[i] == &#x27;$&#x27;) &#123;</span><br><span class="line">          peerstate-&gt;state = wait_for_msg;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">          assert(peerstate-&gt;sendbuf_end &lt; sendbuf_size);</span><br><span class="line">          peerstate-&gt;sendbuf[peerstate-&gt;sendbuf_end++] = buf-&gt;base[i] + 1;</span><br><span class="line">        &#125;</span><br><span class="line">        break;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (peerstate-&gt;sendbuf_end &gt; 0) &#123;</span><br><span class="line">      // we have data to send. the write buffer will point to the buffer stored</span><br><span class="line">      // in the peer state for this client.</span><br><span class="line">      uv_buf_t writebuf =</span><br><span class="line">          uv_buf_init(peerstate-&gt;sendbuf, peerstate-&gt;sendbuf_end);</span><br><span class="line">      uv_write_t* writereq = (uv_write_t*)xmalloc(sizeof(*writereq));</span><br><span class="line">      writereq-&gt;data = peerstate;</span><br><span class="line">      int rc;</span><br><span class="line">      if ((rc = uv_write(writereq, (uv_stream_t*)client, &amp;writebuf, 1,</span><br><span class="line">                         on_wrote_buf)) &lt; 0) &#123;</span><br><span class="line">        die(&quot;uv_write failed: %s&quot;, uv_strerror(rc));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  free(buf-&gt;base);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这个服务器的运行时行为非常类似于第三部分的事件驱动服务器：所有的客户端都在一个单个的线程中并发处理。并且类似的，一些特定的行为必须在服务器代码中维护：服务器的逻辑实现为一个集成的回调，并且长周期运行是禁止的，因为它会阻塞事件循环。这一点也很类似。让我们进一步探索这个问题。</p><h3 id="在事件驱动循环中的长周期运行的操作"><a href="#在事件驱动循环中的长周期运行的操作" class="headerlink" title="在事件驱动循环中的长周期运行的操作"></a>在事件驱动循环中的长周期运行的操作</h3><p>单线程的事件驱动代码使它先天就容易受到一些常见问题的影响：长周期运行的代码会阻塞整个循环。参见如下的程序：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">void on_timer(uv_timer_t* timer) &#123;</span><br><span class="line">  uint64_t timestamp = uv_hrtime();</span><br><span class="line">  printf(&quot;on_timer [%&quot; PRIu64 &quot; ms]\n&quot;, (timestamp / 1000000) % 100000);</span><br><span class="line"></span><br><span class="line">  // &quot;Work&quot;</span><br><span class="line">  if (random() % 5 == 0) &#123;</span><br><span class="line">    printf(&quot;Sleeping...\n&quot;);</span><br><span class="line">    sleep(3);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(int argc, const char** argv) &#123;</span><br><span class="line">  uv_timer_t timer;</span><br><span class="line">  uv_timer_init(uv_default_loop(), &amp;timer);</span><br><span class="line">  uv_timer_start(&amp;timer, on_timer, 0, 1000);</span><br><span class="line">  return uv_run(uv_default_loop(), UV_RUN_DEFAULT);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>它用一个单个注册的回调运行一个 libuv 事件循环：<code>on_timer</code>，它被每秒钟循环调用一次。回调报告一个时间戳，并且，偶尔通过睡眠 3 秒去模拟一个长周期运行。这是运行示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ ./uv-timer-sleep-demo</span><br><span class="line">on_timer [4840 ms]</span><br><span class="line">on_timer [5842 ms]</span><br><span class="line">on_timer [6843 ms]</span><br><span class="line">on_timer [7844 ms]</span><br><span class="line">Sleeping...</span><br><span class="line">on_timer [11845 ms]</span><br><span class="line">on_timer [12846 ms]</span><br><span class="line">Sleeping...</span><br><span class="line">on_timer [16847 ms]</span><br><span class="line">on_timer [17849 ms]</span><br><span class="line">on_timer [18850 ms]</span><br><span class="line">...</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>on_timer</code> 忠实地每秒执行一次，直到随机出现的睡眠为止。在那个时间点，<code>on_timer</code> 不再被调用，直到睡眠时间结束；事实上，<em>没有其它的回调</em> 会在这个时间帧中被调用。这个睡眠调用阻塞了当前线程，它正是被调用的线程，并且也是事件循环使用的线程。当这个线程被阻塞后，事件循环也被阻塞。</p><p>这个示例演示了在事件驱动的调用中为什么回调不能被阻塞是多少的重要。并且，同样适用于 Node.js 服务器、客户端侧的 Javascript、大多数的 GUI 编程框架、以及许多其它的异步编程模型。</p><p>但是，有时候运行耗时的任务是不可避免的。并不是所有任务都有一个异步 API；例如，我们可能使用一些仅有同步 API 的库去处理，或者，正在执行一个可能的长周期计算。我们如何用事件驱动编程去结合这些代码？线程可以帮到你！</p><h3 id="“转换”-阻塞调用为异步调用的线程"><a href="#“转换”-阻塞调用为异步调用的线程" class="headerlink" title="“转换” 阻塞调用为异步调用的线程"></a>“转换” 阻塞调用为异步调用的线程</h3><p>一个线程池可以用于转换阻塞调用为异步调用，通过与事件循环并行运行，并且当任务完成时去由它去公布事件。以阻塞函数 <code>do_work()</code> 为例，这里介绍了它是怎么运行的：</p><ol><li>不在一个回调中直接调用 <code>do_work()</code> ，而是将它打包进一个 “任务”，让线程池去运行这个任务。当任务完成时，我们也为循环去调用它注册一个回调；我们称它为 <code>on_work_done()</code>。</li><li>在这个时间点，我们的回调就可以返回了，而事件循环保持运行；在同一时间点，线程池中的有一个线程运行这个任务。</li><li>一旦任务运行完成，通知主线程（指正在运行事件循环的线程），并且事件循环调用 <code>on_work_done()</code>。</li></ol><p>让我们看一下，使用 libuv 的工作调度 API，是怎么去解决我们前面的计时器&#x2F;睡眠示例中展示的问题的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">void on_after_work(uv_work_t* req, int status) &#123;</span><br><span class="line">  free(req);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void on_work(uv_work_t* req) &#123;</span><br><span class="line">  // &quot;Work&quot;</span><br><span class="line">  if (random() % 5 == 0) &#123;</span><br><span class="line">    printf(&quot;Sleeping...\n&quot;);</span><br><span class="line">    sleep(3);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void on_timer(uv_timer_t* timer) &#123;</span><br><span class="line">  uint64_t timestamp = uv_hrtime();</span><br><span class="line">  printf(&quot;on_timer [%&quot; PRIu64 &quot; ms]\n&quot;, (timestamp / 1000000) % 100000);</span><br><span class="line"></span><br><span class="line">  uv_work_t* work_req = (uv_work_t*)malloc(sizeof(*work_req));</span><br><span class="line">  uv_queue_work(uv_default_loop(), work_req, on_work, on_after_work);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(int argc, const char** argv) &#123;</span><br><span class="line">  uv_timer_t timer;</span><br><span class="line">  uv_timer_init(uv_default_loop(), &amp;timer);</span><br><span class="line">  uv_timer_start(&amp;timer, on_timer, 0, 1000);</span><br><span class="line">  return uv_run(uv_default_loop(), UV_RUN_DEFAULT);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>通过一个 <code>work_req</code> <sup>注2</sup> 类型的句柄，我们进入一个任务队列，代替在 <code>on_timer</code> 上直接调用 sleep，这个函数在任务中（<code>on_work</code>）运行，并且，一旦任务完成（<code>on_after_work</code>），这个函数被调用一次。<code>on_work</code> 是指 “work”（阻塞中的&#x2F;耗时的操作）进行的地方。注意在这两个回调传递到 <code>uv_queue_work</code> 时的一个关键区别：<code>on_work</code> 运行在线程池中，而 <code>on_after_work</code> 运行在事件循环中的主线程上 —— 就好像是其它的回调一样。</p><p>让我们看一下这种方式的运行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ ./uv-timer-work-demo</span><br><span class="line">on_timer [89571 ms]</span><br><span class="line">on_timer [90572 ms]</span><br><span class="line">on_timer [91573 ms]</span><br><span class="line">on_timer [92575 ms]</span><br><span class="line">Sleeping...</span><br><span class="line">on_timer [93576 ms]</span><br><span class="line">on_timer [94577 ms]</span><br><span class="line">Sleeping...</span><br><span class="line">on_timer [95577 ms]</span><br><span class="line">on_timer [96578 ms]</span><br><span class="line">on_timer [97578 ms]</span><br><span class="line">...</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>即便在 sleep 函数被调用时，定时器也每秒钟滴答一下，睡眠现在运行在一个单独的线程中，并且不会阻塞事件循环。</p><h3 id="一个用于练习的素数测试服务器"><a href="#一个用于练习的素数测试服务器" class="headerlink" title="一个用于练习的素数测试服务器"></a>一个用于练习的素数测试服务器</h3><p>因为通过睡眠去模拟工作并不是件让人兴奋的事，我有一个事先准备好的更综合的一个示例 —— 一个基于套接字接受来自客户端的数字的服务器，检查这个数字是否是素数，然后去返回一个 “prime” 或者 “composite”。完整的 <a target="_blank" rel="noopener" href="https://github.com/eliben/code-for-blog/blob/master/2017/async-socket-server/uv-isprime-server.c">服务器代码在这里</a> —— 我不在这里粘贴了，因为它太长了，更希望读者在一些自己的练习中去体会它。</p><p>这个服务器使用了一个原生的素数测试算法，因此，对于大的素数可能花很长时间才返回一个回答。在我的机器中，对于 2305843009213693951，它花了 ~5 秒钟去计算，但是，你的方法可能不同。</p><p>练习 1：服务器有一个设置（通过一个名为 <code>MODE</code> 的环境变量）要么在套接字回调（意味着在主线程上）中运行素数测试，要么在 libuv 工作队列中。当多个客户端同时连接时，使用这个设置来观察服务器的行为。当它计算一个大的任务时，在阻塞模式中，服务器将不回复其它客户端，而在非阻塞模式中，它会回复。</p><p>练习 2：libuv 有一个缺省大小的线程池，并且线程池的大小可以通过环境变量配置。你可以通过使用多个客户端去实验找出它的缺省值是多少？找到线程池缺省值后，使用不同的设置去看一下，在重负载下怎么去影响服务器的响应能力。</p><h3 id="在非阻塞文件系统中使用工作队列"><a href="#在非阻塞文件系统中使用工作队列" class="headerlink" title="在非阻塞文件系统中使用工作队列"></a>在非阻塞文件系统中使用工作队列</h3><p>对于只是呆板的演示和 CPU 密集型的计算来说，将可能的阻塞操作委托给一个线程池并不是明智的；libuv 在它的文件系统 API 中本身就大量使用了这种能力。通过这种方式，libuv 使用一个异步 API，以一个轻便的方式显示出它强大的文件系统的处理能力。</p><p>让我们使用 <code>uv_fs_read()</code>，例如，这个函数从一个文件中（表示为一个 <code>uv_fs_t</code> 句柄）读取一个文件到一个缓冲中 <sup>注3，并且当读取完成后调用一个回调。换句话说， <code>uv_fs_read()</code> 总是立即返回，即使是文件在一个类似</sup> NFS 的系统上，而数据到达缓冲区可能需要一些时间。换句话说，这个 API 与这种方式中其它的 libuv API 是异步的。这是怎么工作的呢？</p><p>在这一点上，我们看一下 libuv 的底层；内部实际上非常简单，并且它是一个很好的练习。作为一个可移植的库，libuv 对于 Windows 和 Unix 系统在它的许多函数上有不同的实现。我们去看一下在 libuv 源树中的 <code>src/unix/fs.c</code>。</p><p>这是 <code>uv_fs_read</code> 的代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">int uv_fs_read(uv_loop_t* loop, uv_fs_t* req,</span><br><span class="line">               uv_file file,</span><br><span class="line">               const uv_buf_t bufs[],</span><br><span class="line">               unsigned int nbufs,</span><br><span class="line">               int64_t off,</span><br><span class="line">               uv_fs_cb cb) &#123;</span><br><span class="line">  if (bufs == NULL || nbufs == 0)</span><br><span class="line">    return -EINVAL;</span><br><span class="line"></span><br><span class="line">  INIT(READ);</span><br><span class="line">  req-&gt;file = file;</span><br><span class="line"></span><br><span class="line">  req-&gt;nbufs = nbufs;</span><br><span class="line">  req-&gt;bufs = req-&gt;bufsml;</span><br><span class="line">  if (nbufs &gt; ARRAY_SIZE(req-&gt;bufsml))</span><br><span class="line">    req-&gt;bufs = uv__malloc(nbufs * sizeof(*bufs));</span><br><span class="line"></span><br><span class="line">  if (req-&gt;bufs == NULL) &#123;</span><br><span class="line">    if (cb != NULL)</span><br><span class="line">      uv__req_unregister(loop, req);</span><br><span class="line">    return -ENOMEM;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  memcpy(req-&gt;bufs, bufs, nbufs * sizeof(*bufs));</span><br><span class="line"></span><br><span class="line">  req-&gt;off = off;</span><br><span class="line">  POST;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>第一次看可能觉得很困难，因为它延缓真实的工作到 <code>INIT</code> 和 <code>POST</code> 宏中，以及为 <code>POST</code> 设置了一些本地变量。这样做可以避免了文件中的许多重复代码。</p><p>这是 <code>INIT</code> 宏：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#define INIT(subtype)                                                         \</span><br><span class="line">  do &#123;                                                                        \</span><br><span class="line">    req-&gt;type = UV_FS;                                                        \</span><br><span class="line">    if (cb != NULL)                                                           \</span><br><span class="line">      uv__req_init(loop, req, UV_FS);                                         \</span><br><span class="line">    req-&gt;fs_type = UV_FS_ ## subtype;                                         \</span><br><span class="line">    req-&gt;result = 0;                                                          \</span><br><span class="line">    req-&gt;ptr = NULL;                                                          \</span><br><span class="line">    req-&gt;loop = loop;                                                         \</span><br><span class="line">    req-&gt;path = NULL;                                                         \</span><br><span class="line">    req-&gt;new_path = NULL;                                                     \</span><br><span class="line">    req-&gt;cb = cb;                                                             \</span><br><span class="line">  &#125;                                                                           \</span><br><span class="line">  while (0)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>它设置了请求，并且更重要的是，设置 <code>req-&gt;fs_type</code> 域为真实的 FS 请求类型。因为 <code>uv_fs_read</code> 调用 <code>INIT(READ)</code>，它意味着 <code>req-&gt;fs_type</code> 被分配一个常数 <code>UV_FS_READ</code>。</p><p>这是 <code>POST</code> 宏：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#define POST                                                                  \</span><br><span class="line">  do &#123;                                                                        \</span><br><span class="line">    if (cb != NULL) &#123;                                                         \</span><br><span class="line">      uv__work_submit(loop, &amp;req-&gt;work_req, uv__fs_work, uv__fs_done);        \</span><br><span class="line">      return 0;                                                               \</span><br><span class="line">    &#125;                                                                         \</span><br><span class="line">    else &#123;                                                                    \</span><br><span class="line">      uv__fs_work(&amp;req-&gt;work_req);                                            \</span><br><span class="line">      return req-&gt;result;                                                     \</span><br><span class="line">    &#125;                                                                         \</span><br><span class="line">  &#125;                                                                           \</span><br><span class="line">  while (0)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>它做什么取决于回调是否为 <code>NULL</code>。在 libuv 文件系统 API 中，一个 <code>NULL</code> 回调意味着我们真实地希望去执行一个 <em>同步</em> 操作。在这种情况下，<code>POST</code> 直接调用 <code>uv__fs_work</code>（我们需要了解一下这个函数的功能），而对于一个非 <code>NULL</code> 回调，它把 <code>uv__fs_work</code> 作为一个工作项提交到工作队列（指的是线程池），然后，注册 <code>uv__fs_done</code> 作为回调；该函数执行一些登记并调用用户提供的回调。</p><p>如果我们去看 <code>uv__fs_work</code> 的代码，我们将看到它使用很多宏按照需求将工作分发到实际的文件系统调用。在我们的案例中，对于 <code>UV_FS_READ</code> 这个调用将被 <code>uv__fs_read</code> 生成，它（最终）使用普通的 POSIX API 去读取。这个函数可以在一个 <em>阻塞</em> 方式中很安全地实现。因为，它通过异步 API 调用时被置于一个线程池中。</p><p>在 Node.js 中，<code>fs.readFile</code> 函数是映射到 <code>uv_fs_read</code> 上。因此，可以在一个非阻塞模式中读取文件，甚至是当底层文件系统 API 是阻塞方式时。</p><hr><ul><li>注1： 为确保服务器不泄露内存，我在一个启用泄露检查的 Valgrind 中运行它。因为服务器经常是被设计为永久运行，这是一个挑战；为克服这个问题，我在服务器上添加了一个 “kill 开关” —— 一个从客户端接收的特定序列，以使它可以停止事件循环并退出。这个代码在 <code>theon_wrote_buf</code> 句柄中。</li><li>注2： 在这里我们不过多地使用 <code>work_req</code>；讨论的素数测试服务器接下来将展示怎么被用于去传递上下文信息到回调中。</li><li>注3： <code>uv_fs_read()</code> 提供了一个类似于 <code>preadv</code> Linux 系统调用的通用 API：它使用多缓冲区用于排序，并且支持一个到文件中的偏移。基于我们讨论的目的可以忽略这些特性。</li></ul><hr><p>via: <a target="_blank" rel="noopener" href="https://eli.thegreenplace.net/2017/concurrent-servers-part-4-libuv/">https://eli.thegreenplace.net/2017/concurrent-servers-part-4-libuv/</a></p><p>作者：<a target="_blank" rel="noopener" href="https://eli.thegreenplace.net/">Eli Bendersky</a> 译者：<a target="_blank" rel="noopener" href="https://github.com/qhwdw">qhwdw</a> 校对：<a target="_blank" rel="noopener" href="https://github.com/wxy">wxy</a></p><p>本文由 <a target="_blank" rel="noopener" href="https://github.com/LCTT/TranslateProject">LCTT</a> 原创编译，<a target="_blank" rel="noopener" href="https://linux.cn/">Linux中国</a> 荣誉推出</p></div></div></div><div class="footer"><p class="footer-copyright"><span>Powered by <a target="_blank" href="https://hexo.io">Hexo</a></span> <span>Theme <a target="_blank" href="https://github.com/tinkink-co/hexo-theme-terminal">Terminal</a></span><script type="text/javascript" src="https://cdn.staticfile.net/jquery/3.4.1/jquery.min.js"></script><script>getCDNinfo=function(){$.ajax({url:"/cdn-cgi/trace",success:function(a,n){let i="Antananarivo, Madagascar - (TNR);Cape Town, South Africa - (CPT);Casablanca, Morocco - (CMN);Dar Es Salaam, Tanzania - (DAR);Djibouti City, Djibouti - (JIB);Durban, South Africa - (DUR);Johannesburg, South Africa - (JNB);Kigali, Rwanda - (KGL);Lagos, Nigeria - (LOS);Luanda, Angola - (LAD);Maputo, MZ - (MPM);Mombasa, Kenya - (MBA);Port Louis, Mauritius - (MRU);Réunion, France - (RUN);Bangalore, India - (BLR);Bangkok, Thailand - (BKK);Bandar Seri Begawan, Brunei - (BWN);Cebu, Philippines - (CEB);Chengdu, China - (CTU);Chennai, India - (MAA);Chittagong, Bangladesh - (CGP);Chongqing, China - (CKG);Colombo, Sri Lanka - (CMB);Dhaka, Bangladesh - (DAC);Dongguan, China - (SZX);Foshan, China - (FUO);Fuzhou, China - (FOC);Guangzhou, China - (CAN);Hangzhou, China - (HGH);Hanoi, Vietnam - (HAN);Hengyang, China - (HNY);Ho Chi Minh City, Vietnam - (SGN);Hong Kong - (HKG);Hyderabad, India - (HYD);Islamabad, Pakistan - (ISB);Jakarta, Indonesia - (CGK);Jinan, China - (TNA);Karachi, Pakistan - (KHI);Kathmandu, Nepal - (KTM);Kolkata, India - (CCU);Kuala Lumpur, Malaysia - (KUL);Lahore, Pakistan - (LHE);Langfang, China - (NAY);Luoyang, China - (LYA);Macau - (MFM);Malé, Maldives - (MLE);Manila, Philippines - (MNL);Mumbai, India - (BOM);Nagpur, India - (NAG);Nanning, China - (NNG);New Delhi, India - (DEL);Osaka, Japan - (KIX);Phnom Penh, Cambodia - (PNH);Qingdao, China - (TAO);Seoul, South Korea - (ICN);Shanghai, China - (SHA);Shenyang, China - (SHE);Shijiazhuang, China - (SJW);Singapore, Singapore - (SIN);Suzhou, China - (SZV);Taipei - (TPE);Thimphu, Bhutan - (PBH);Tianjin, China - (TSN);Tokyo, Japan - (NRT);Ulaanbaatar, Mongolia - (ULN);Vientiane, Laos - (VTE);Wuhan, China - (WUH);Wuxi, China - (WUX);Xi'an, China - (XIY);Yerevan, Armenia - (EVN);Zhengzhou, China - (CGO);Zuzhou, China - (CSX);Amsterdam, Netherlands - (AMS);Athens, Greece - (ATH);Barcelona, Spain - (BCN);Belgrade, Serbia - (BEG);Berlin, Germany - (TXL);Brussels, Belgium - (BRU);Bucharest, Romania - (OTP);Budapest, Hungary - (BUD);Chișinău, Moldova - (KIV);Copenhagen, Denmark - (CPH);Cork, Ireland -  (ORK);Dublin, Ireland - (DUB);Düsseldorf, Germany - (DUS);Edinburgh, United Kingdom - (EDI);Frankfurt, Germany - (FRA);Geneva, Switzerland - (GVA);Gothenburg, Sweden - (GOT);Hamburg, Germany - (HAM);Helsinki, Finland - (HEL);Istanbul, Turkey - (IST);Kyiv, Ukraine - (KBP);Lisbon, Portugal - (LIS);London, United Kingdom - (LHR);Luxembourg City, Luxembourg - (LUX);Madrid, Spain - (MAD);Manchester, United Kingdom - (MAN);Marseille, France - (MRS);Milan, Italy - (MXP);Moscow, Russia - (DME);Munich, Germany - (MUC);Nicosia, Cyprus - (LCA);Oslo, Norway - (OSL);Paris, France - (CDG);Prague, Czech Republic - (PRG);Reykjavík, Iceland - (KEF);Riga, Latvia - (RIX);Rome, Italy - (FCO);Saint Petersburg, Russia - (LED);Sofia, Bulgaria - (SOF);Stockholm, Sweden - (ARN);Tallinn, Estonia - (TLL);Thessaloniki, Greece - (SKG);Vienna, Austria - (VIE);Vilnius, Lithuania - (VNO);Warsaw, Poland - (WAW);Zagreb, Croatia - (ZAG);Zürich, Switzerland - (ZRH);Arica, Chile - (ARI);Asunción, Paraguay - (ASU);Bogotá, Colombia - (BOG);Buenos Aires, Argentina - (EZE);Curitiba, Brazil - (CWB);Fortaleza, Brazil - (FOR);Guatemala City, Guatemala - (GUA);Lima, Peru - (LIM);Medellín, Colombia - (MDE);Panama City, Panama - (PTY);Porto Alegre, Brazil - (POA);Quito, Ecuador - (UIO);Rio de Janeiro, Brazil - (GIG);São Paulo, Brazil - (GRU);Santiago, Chile - (SCL);Willemstad, Curaçao - (CUR);St. George's, Grenada - (GND);Amman, Jordan - (AMM);Baghdad, Iraq - (BGW);Baku, Azerbaijan - (GYD);Beirut, Lebanon - (BEY);Doha, Qatar - (DOH);Dubai, United Arab Emirates - (DXB);Kuwait City, Kuwait - (KWI);Manama, Bahrain - (BAH);Muscat, Oman - (MCT);Ramallah - (ZDM);Riyadh, Saudi Arabia - (RUH);Tel Aviv, Israel - (TLV);Ashburn, VA, United States - (IAD);Atlanta, GA, United States - (ATL);Boston, MA, United States - (BOS);Buffalo, NY, United States - (BUF);Calgary, AB, Canada - (YYC);Charlotte, NC, United States - (CLT);Chicago, IL, United States - (ORD);Columbus, OH, United States - (CMH);Dallas, TX, United States - (DFW);Denver, CO, United States - (DEN);Detroit, MI, United States - (DTW);Honolulu, HI, United States - (HNL);Houston, TX, United States - (IAH);Indianapolis, IN, United States - (IND);Jacksonville, FL, United States - (JAX);Kansas City, MO, United States - (MCI);Las Vegas, NV, United States - (LAS);Los Angeles, CA, United States - (LAX);McAllen, TX, United States - (MFE);Memphis, TN, United States - (MEM);Mexico City, Mexico - (MEX);Miami, FL, United States - (MIA);Minneapolis, MN, United States - (MSP);Montgomery, AL, United States - (MGM);Montréal, QC, Canada - (YUL);Nashville, TN, United States - (BNA);Newark, NJ, United States - (EWR);Norfolk, VA, United States - (ORF);Omaha, NE, United States - (OMA);Philadelphia, United States - (PHL);Phoenix, AZ, United States - (PHX);Pittsburgh, PA, United States - (PIT);Port-Au-Prince, Haiti - (PAP);Portland, OR, United States - (PDX);Queretaro, MX, Mexico - (QRO);Richmond, Virginia - (RIC);Sacramento, CA, United States - (SMF);Salt Lake City, UT, United States - (SLC);San Diego, CA, United States - (SAN);San Jose, CA, United States - (SJC);Saskatoon, SK, Canada - (YXE);Seattle, WA, United States - (SEA);St. Louis, MO, United States - (STL);Tampa, FL, United States - (TPA);Toronto, ON, Canada - (YYZ);Vancouver, BC, Canada - (YVR);Tallahassee, FL, United States - (TLH);Winnipeg, MB, Canada - (YWG);Adelaide, SA, Australia - (ADL);Auckland, New Zealand - (AKL);Brisbane, QLD, Australia - (BNE);Melbourne, VIC, Australia - (MEL);Noumea, New caledonia - (NOU);Perth, WA, Australia - (PER);Sydney, NSW, Australia - (SYD)".split(";"),e=a.split("colo=")[1].split("\n")[0],t=(a.split("colo=")[1].split("\n")[0],a.split("tls=")[1].split("\n")[0]),o=a.split("http=")[1].split("\n")[0],s=a.split("sni=")[1].split("\n")[0],r=a.split("ip=")[1].split("\n")[0],l=a.split("uag=")[1].split("\n")[0];for(var d=0;d<i.length;d++)if(-1!=i[d].indexOf(e)){document.getElementById("cdn").innerHTML=i[d];break}document.getElementById("tls").innerHTML=t,document.getElementById("http").innerHTML=o,document.getElementById("sni").innerHTML=s,document.getElementById("ip").innerHTML=r,document.getElementById("useragent").innerHTML=l}})},$(document).ready((function(){getCDNinfo()}))</script></p><p style="text-align:center">感谢陪伴与布道，开源之火不灭。​</p><p style="text-align:center"><script>document.write("本次加载耗时: "+(performance.getEntriesByType("navigation").reduce((e,r)=>e+r.responseEnd-r.startTime,0)+performance.getEntriesByType("resource").reduce((e,r)=>e+r.responseEnd-r.startTime,0)).toFixed(0)+"ms")</script></p><p style="text-align:center">当前 SNI 状态： <span id="sni">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 TLS 版本： <span id="tls">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 HTTP 版本： <span id="http">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前您的客户端 IP 是： <span id="ip">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前分配的 CDN 节点是: <span id="cdn">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">您的 UserAgent 信息是: <span id="useragent">正在统计！或可能被浏览器防追踪拦截！</span></p><p></p></div></div></body></html>