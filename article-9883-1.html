<!doctype html><html lang="en"><head><meta name="description" content="一个LinuxCN的镜像站"><meta name="msvalidate.01" content="D404690CEFCB54C7762AC84935B99171"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?6618da70c90c8744eead2e9371fb5077";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script type="text/javascript">!function(t,e,n,c,s,a,r){t[n]=t[n]||function(){(t[n].q=t[n].q||[]).push(arguments)},(a=e.createElement(c)).async=1,a.src="https://www.clarity.ms/tag/s5f3f0tojf",(r=e.getElementsByTagName(c)[0]).parentNode.insertBefore(a,r)}(window,document,"clarity","script")</script><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta http-equiv="X-UA-Compatible" content="ie=edge"><link rel="stylesheet" href="/styles/base.css"><link rel="stylesheet" href="/styles/theme.css"><link rel="shortcut icon" href="/favicon.png"><title>Kubernetes 分布式应用部署实战：以人脸识别应用为例 - 归墟星火集 又一个 LinuxCN 站点</title><meta name="generator" content="Hexo 7.3.0"></head><body><div class="header-title"><span class="header-light"></span> <span class="header-light"></span> <span class="header-light"></span> <span>归墟星火集 又一个 LinuxCN 站点 linuxcn.undefined.today<span></span></span></div><div class="container"><ul class="nav"><li><a href="/">首页</a></li><li><a target="_blank" rel="noopener" href="https://undefined.today/">Blog</a></li></ul><div class="content"><div class="post-container"><div class="post-header"><span class="ui-tips">标题：</span><h1 class="ui-keyword post-title">Kubernetes 分布式应用部署实战：以人脸识别应用为例</h1><span class="post-date">2018-07-30</span></div><div class="post-header"><span class="ui-tips">分类：</span> <a href="/categories/%E6%8A%80%E6%9C%AF/">技术</a></div><div class="post-header"><span class="ui-tips">标签：</span> <a href="/tags/Kubernetes/">Kubernetes</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/">人脸识别</a></div><div class="post-content"><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201807/30/182100utggq5s2nlwyxzsl.jpg"></p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>伙计们，请搬好小板凳坐好，下面将是一段漫长的旅程，期望你能够乐在其中。</p><p>我将基于 <a target="_blank" rel="noopener" href="https://kubernetes.io/">Kubernetes</a> 部署一个分布式应用。我曾试图编写一个尽可能真实的应用，但由于时间和精力有限，最终砍掉了很多细节。</p><p>我将聚焦 Kubernetes 及其部署。</p><p>让我们开始吧。</p><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><h3 id="TL-DR"><a href="#TL-DR" class="headerlink" title="TL;DR"></a>TL;DR</h3><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201807/30/182110rjm2ufth3k7kdtky.jpg"></p><p>该应用本身由 6 个组件构成。代码可以从如下链接中找到：<a target="_blank" rel="noopener" href="https://github.com/Skarlso/kube-cluster-sample">Kubenetes 集群示例</a>。</p><p>这是一个人脸识别服务，通过比较已知个人的图片，识别给定图片对应的个人。前端页面用表格形式简要的展示图片及对应的个人。具体而言，向 <a target="_blank" rel="noopener" href="https://github.com/Skarlso/kube-cluster-sample">接收器</a> 发送请求，请求包含指向一个图片的链接。图片可以位于任何位置。接受器将图片地址存储到数据库 (MySQL) 中，然后向队列发送处理请求，请求中包含已保存图片的 ID。这里我们使用 <a target="_blank" rel="noopener" href="http://nsq.io/">NSQ</a> 建立队列。</p><p><a target="_blank" rel="noopener" href="https://github.com/Skarlso/kube-cluster-sample/tree/master/image_processor">图片处理</a> 服务一直监听处理请求队列，从中获取任务。处理过程包括如下几步：获取图片 ID，读取图片，通过 <a target="_blank" rel="noopener" href="https://grpc.io/">gRPC</a> 将图片路径发送至 Python 编写的 <a target="_blank" rel="noopener" href="https://github.com/Skarlso/kube-cluster-sample/tree/master/face_recognition">人脸识别</a> 后端。如果识别成功，后端给出图片对应个人的名字。图片处理器进而根据个人 ID 更新图片记录，将其标记为处理成功。如果识别不成功，图片被标记为待解决。如果图片识别过程中出现错误，图片被标记为失败。</p><p>标记为失败的图片可以通过计划任务等方式进行重试。</p><p>那么具体是如何工作的呢？我们深入探索一下。</p><h3 id="接收器"><a href="#接收器" class="headerlink" title="接收器"></a>接收器</h3><p>接收器服务是整个流程的起点，通过如下形式的 API 接收请求：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -d &#x27;&#123;&quot;path&quot;:&quot;/unknown_images/unknown0001.jpg&quot;&#125;&#x27; http://127.0.0.1:8000/image/post</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>此时，接收器将<ruby>路径 <rt>path</rt></ruby>存储到共享数据库集群中，该实体存储后将从数据库服务收到对应的 ID。本应用采用“<ruby>实体对象 <rt>Entity Object</rt></ruby>的唯一标识由持久层提供”的模型。获得实体 ID 后，接收器向 NSQ 发送消息，至此接收器的工作完成。</p><h3 id="图片处理器"><a href="#图片处理器" class="headerlink" title="图片处理器"></a>图片处理器</h3><p>从这里开始变得有趣起来。图片处理器首次运行时会创建两个 Go <ruby>协程 <rt>routine</rt></ruby>，具体为：</p><h3 id="Consume"><a href="#Consume" class="headerlink" title="Consume"></a>Consume</h3><p>这是一个 NSQ 消费者，需要完成三项必需的任务。首先，监听队列中的消息。其次，当有新消息到达时，将对应的 ID 追加到一个线程安全的 ID 片段中，以供第二个协程处理。最后，告知第二个协程处理新任务，方法为 <a target="_blank" rel="noopener" href="https://golang.org/pkg/sync/#Cond">sync.Condition</a>。</p><h3 id="ProcessImages"><a href="#ProcessImages" class="headerlink" title="ProcessImages"></a>ProcessImages</h3><p>该协程会处理指定 ID 片段，直到对应片段全部处理完成。当处理完一个片段后，该协程并不是在一个通道上睡眠等待，而是进入悬挂状态。对每个 ID，按如下步骤顺序处理：</p><ul><li>与人脸识别服务建立 gRPC 连接，其中人脸识别服务会在人脸识别部分进行介绍</li><li>从数据库获取图片对应的实体</li><li>为 <a target="_blank" rel="noopener" href="https://skarlso.github.io/2018/03/15/kubernetes-distributed-application/#circuit-breaker">断路器</a> 准备两个函数<ul><li>函数 1: 用于 RPC 方法调用的主函数</li><li>函数 2: 基于 ping 的断路器健康检查</li></ul></li><li>调用函数 1 将图片路径发送至人脸识别服务，其中路径应该是人脸识别服务可以访问的，最好是共享的，例如 NFS</li><li>如果调用失败，将图片实体状态更新为 FAILEDPROCESSING</li><li>如果调用成功，返回值是一个图片的名字，对应数据库中的一个个人。通过联合 SQL 查询，获取对应个人的 ID</li><li>将数据库中的图片实体状态更新为 PROCESSED，更新图片被识别成的个人的 ID</li></ul><p>这个服务可以复制多份同时运行。</p><h3 id="断路器"><a href="#断路器" class="headerlink" title="断路器"></a>断路器</h3><p>即使对于一个复制资源几乎没有开销的系统，也会有意外的情况发生，例如网络故障或任何两个服务之间的通信存在问题等。我在 gRPC 调用中实现了一个简单的断路器，这十分有趣。</p><p>下面给出工作原理：</p><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201807/30/182155wue0igyuwuws9iss.jpg"></p><p>当出现 5 次不成功的服务调用时，断路器启动并阻断后续的调用请求。经过指定的时间后，它对服务进行健康检查并判断是否恢复。如果问题依然存在，等待时间会进一步增大。如果已经恢复，断路器停止对服务调用的阻断，允许请求流量通过。</p><h3 id="前端"><a href="#前端" class="headerlink" title="前端"></a>前端</h3><p>前端只包含一个极其简单的表格视图，通过 Go 自身的 html&#x2F;模板显示一系列图片。</p><h3 id="人脸识别"><a href="#人脸识别" class="headerlink" title="人脸识别"></a>人脸识别</h3><p>人脸识别是整个识别的关键点。仅因为追求灵活性，我将这个服务设计为基于 gRPC 的服务。最初我使用 Go 编写，但后续发现基于 Python 的实现更加适合。事实上，不算 gRPC 部分的代码，人脸识别部分仅有 7 行代码。我使用的<a target="_blank" rel="noopener" href="https://github.com/ageitgey/face_recognition">人脸识别</a>库极为出色，它包含 OpenCV 的全部 C 绑定。维护 API 标准意味着只要标准本身不变，实现可以任意改变。</p><p>注意：我曾经试图使用 <a target="_blank" rel="noopener" href="https://gocv.io/">GoCV</a>，这是一个极好的 Go 库，但欠缺所需的 C 绑定。推荐马上了解一下这个库，它会让你大吃一惊，例如编写若干行代码即可实现实时摄像处理。</p><p>这个 Python 库的工作方式本质上很简单。准备一些你认识的人的图片，把信息记录下来。对于我而言，我有一个图片文件夹，包含若干图片，名称分别为 <code>hannibal_1.jpg</code>、 <code>hannibal_2.jpg</code>、 <code>gergely_1.jpg</code>、 <code>john_doe.jpg</code>。在数据库中，我使用两个表记录信息，分别为 <code>person</code>、 <code>person_images</code>，具体如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">+----+----------+</span><br><span class="line">| id | name     |</span><br><span class="line">+----+----------+</span><br><span class="line">|  1 | Gergely  |</span><br><span class="line">|  2 | John Doe |</span><br><span class="line">|  3 | Hannibal |</span><br><span class="line">+----+----------+</span><br><span class="line">+----+----------------+-----------+</span><br><span class="line">| id | image_name     | person_id |</span><br><span class="line">+----+----------------+-----------+</span><br><span class="line">|  1 | hannibal_1.jpg |         3 |</span><br><span class="line">|  2 | hannibal_2.jpg |         3 |</span><br><span class="line">+----+----------------+-----------+</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>人脸识别库识别出未知图片后，返回图片的名字。我们接着使用类似下面的联合查询找到对应的个人。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select person.name, person.id from person inner join person_images as pi on person.id = pi.person_id where image_name = &#x27;hannibal_2.jpg&#x27;;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>gRPC 调用返回的个人 ID 用于更新图片的 <code>person</code> 列。</p><h3 id="NSQ"><a href="#NSQ" class="headerlink" title="NSQ"></a>NSQ</h3><p>NSQ 是 Go 编写的小规模队列，可扩展且占用系统内存较少。NSQ 包含一个查询服务，用于消费者接收消息；包含一个守护进程，用于发送消息。</p><p>在 NSQ 的设计理念中，消息发送程序应该与守护进程在同一台主机上，故发送程序仅需发送至 localhost。但守护进程与查询服务相连接，这使其构成了全局队列。</p><p>这意味着有多少 NSQ 守护进程就有多少对应的发送程序。但由于其资源消耗极小，不会影响主程序的资源使用。</p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>为了尽可能增加灵活性以及使用 Kubernetes 的 ConfigSet 特性，我在开发过程中使用 <code>.env</code> 文件记录配置信息，例如数据库服务的地址以及 NSQ 的查询地址。在生产环境或 Kubernetes 环境中，我将使用环境变量属性配置。</p><h3 id="应用小结"><a href="#应用小结" class="headerlink" title="应用小结"></a>应用小结</h3><p>这就是待部署应用的全部架构信息。应用的各个组件都是可变更的，他们之间仅通过数据库、消息队列和 gRPC 进行耦合。考虑到更新机制的原理，这是部署分布式应用所必须的；在部署部分我会继续分析。</p><h2 id="使用-Kubernetes-部署应用"><a href="#使用-Kubernetes-部署应用" class="headerlink" title="使用 Kubernetes 部署应用"></a>使用 Kubernetes 部署应用</h2><h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><p>Kubernetes 是什么？</p><p>这里我会提到一些基础知识，但不会深入细节，细节可以用一本书的篇幅描述，例如 <a target="_blank" rel="noopener" href="http://shop.oreilly.com/product/0636920043874.do">Kubernetes 构建与运行</a>。另外，如果你愿意挑战自己，可以查看官方文档：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/">Kubernetes 文档</a>。</p><p>Kubernetes 是容器化服务及应用的管理器。它易于扩展，可以管理大量容器；更重要的是，可以通过基于 yaml 的模板文件高度灵活地进行配置。人们经常把 Kubernetes 比作 Docker Swarm，但 Kubernetes 的功能不仅仅如此。例如，Kubernetes 不关心底层容器实现，你可以使用 LXC 与 Kubernetes 的组合，效果与使用 Docker 一样好。Kubernetes 在管理容器的基础上，可以管理已部署的服务或应用集群。如何操作呢？让我们概览一下用于构成 Kubernetes 的模块。</p><p>在 Kubernetes 中，你给出期望的应用状态，Kubernetes 会尽其所能达到对应的状态。状态可以是已部署、已暂停，有 2 个副本等，以此类推。</p><p>Kubernetes 使用标签和注释标记组件，包括服务、部署、副本组、守护进程组等在内的全部组件都被标记。考虑如下场景，为了识别 pod 与应用的对应关系，使用 <code>app: myapp</code> 标签。假设应用已部署 2 个容器，如果你移除其中一个容器的 <code>app</code> 标签，Kubernetes 只能识别到一个容器（隶属于应用），进而启动一个新的具有 <code>myapp</code> 标签的实例。</p><h3 id="Kubernetes-集群"><a href="#Kubernetes-集群" class="headerlink" title="Kubernetes 集群"></a>Kubernetes 集群</h3><p>要使用 Kubernetes，需要先搭建一个 Kubernetes 集群。搭建 Kubernetes 集群可能是一个痛苦的经历，但所幸有工具可以帮助我们。Minikube 为我们在本地搭建一个单节点集群。AWS 的一个 beta 服务工作方式类似于 Kubernetes 集群，你只需请求节点并定义你的部署即可。Kubernetes 集群组件的文档如下：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/overview/components/">Kubernetes 集群组件</a>。</p><h3 id="节点"><a href="#节点" class="headerlink" title="节点"></a>节点</h3><p><ruby>节点 <rt>node</rt></ruby>是工作单位，形式可以是虚拟机、物理机，也可以是各种类型的云主机。</p><h3 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h3><p>Pod 是本地容器逻辑上组成的集合，即一个 Pod 中可能包含若干个容器。Pod 创建后具有自己的 DNS 和虚拟 IP，这样 Kubernetes 可以对到达流量进行负载均衡。你几乎不需要直接和容器打交道；即使是调试的时候，例如查看日志，你通常调用 <code>kubectl logs deployment/your-app -f</code> 查看部署日志，而不是使用 <code>-c container_name</code> 查看具体某个容器的日志。<code>-f</code> 参数表示从日志尾部进行流式输出。</p><h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><p>在 Kubernetes 中创建任何类型的资源时，后台使用一个<ruby>部署 <rt>deployment</rt></ruby>组件，它指定了资源的期望状态。使用部署对象，你可以将 Pod 或服务变更为另外的状态，也可以更新应用或上线新版本应用。你一般不会直接操作副本组 (后续会描述)，而是通过部署对象创建并管理。</p><h3 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h3><p>默认情况下，Pod 会获取一个 IP 地址。但考虑到 Pod 是 Kubernetes 中的易失性组件，我们需要更加持久的组件。不论是队列，MySQL、内部 API 或前端，都需要长期运行并使用保持不变的 IP 或更好的 DNS 记录。</p><p>为解决这个问题，Kubernetes 提供了<ruby>服务 <rt>service</rt></ruby>组件，可以定义访问模式，支持的模式包括负载均衡、简单 IP 或内部 DNS。</p><p>Kubernetes 如何获知服务运行正常呢？你可以配置健康性检查和可用性检查。健康性检查是指检查容器是否处于运行状态，但容器处于运行状态并不意味着服务运行正常。对此，你应该使用可用性检查，即请求应用的一个特别<ruby>接口 <rt>endpoint</rt></ruby>。</p><p>由于服务非常重要，推荐你找时间阅读以下文档：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/services-networking/service/">服务</a>。严肃的说，需要阅读的东西很多，有 24 页 A4 纸的篇幅，涉及网络、服务及自动发现。这也有助于你决定是否真的打算在生产环境中使用 Kubernetes。</p><h3 id="DNS-服务发现"><a href="#DNS-服务发现" class="headerlink" title="DNS &#x2F; 服务发现"></a>DNS &#x2F; 服务发现</h3><p>在 Kubernetes 集群中创建服务后，该服务会从名为 <code>kube-proxy</code> 和 <code>kube-dns</code> 的特殊 Kubernetes 部署中获取一个 DNS 记录。它们两个用于提供集群内的服务发现。如果你有一个正在运行的 MySQL 服务并配置 <code>clusterIP: no</code>，那么集群内部任何人都可以通过 <code>mysql.default.svc.cluster.local</code> 访问该服务，其中：</p><ul><li><code>mysql</code> – 服务的名称</li><li><code>default</code> – 命名空间的名称</li><li><code>svc</code> – 对应服务分类</li><li><code>cluster.local</code> – 本地集群的域名</li></ul><p>可以使用自定义设置更改本地集群的域名。如果想让服务可以从集群外访问，需要使用 DNS 服务，并使用例如 Nginx 将 IP 地址绑定至记录。服务对应的对外 IP 地址可以使用如下命令查询：</p><ul><li>节点端口方式 – <code>kubectl get -o jsonpath=&quot;&#123;.spec.ports[0].nodePort&#125;&quot; services mysql</code></li><li>负载均衡方式 – <code>kubectl get -o jsonpath=&quot;&#123;.spec.ports[0].LoadBalancer&#125;&quot; services mysql</code></li></ul><h3 id="模板文件"><a href="#模板文件" class="headerlink" title="模板文件"></a>模板文件</h3><p>类似 Docker Compose、TerraForm 或其它的服务管理工具，Kubernetes 也提供了基础设施描述模板。这意味着，你几乎不用手动操作。</p><p>以 Nginx 部署为例，查看下面的 yaml 模板：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment #(1)</span><br><span class="line">metadata: #(2)</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">  labels: #(3)</span><br><span class="line">    app: nginx</span><br><span class="line">spec: #(4)</span><br><span class="line">  replicas: 3 #(5)</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers: #(6)</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.7.9</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在这个示例部署中，我们做了如下操作：</p><ul><li>(1) 使用 <code>kind</code> 关键字定义模板类型</li><li>(2) 使用 <code>metadata</code> 关键字，增加该部署的识别信息</li><li>(3) 使用 <code>labels</code> 标记每个需要创建的资源</li><li>(4) 然后使用 <code>spec</code> 关键字描述所需的状态</li><li>(5) nginx 应用需要 3 个副本</li><li>(6) Pod 中容器的模板定义部分</li><li>容器名称为 nginx</li><li>容器模板为 nginx:1.7.9 （本例使用 Docker 镜像）</li></ul><h3 id="副本组"><a href="#副本组" class="headerlink" title="副本组"></a>副本组</h3><p><ruby>副本组 <rt>ReplicaSet</rt></ruby>是一个底层的副本管理器，用于保证运行正确数目的应用副本。相比而言，部署是更高层级的操作，应该用于管理副本组。除非你遇到特殊的情况，需要控制副本的特性，否则你几乎不需要直接操作副本组。</p><h3 id="守护进程组"><a href="#守护进程组" class="headerlink" title="守护进程组"></a>守护进程组</h3><p>上面提到 Kubernetes 始终使用标签，还有印象吗？<ruby>守护进程组 <rt>DaemonSet</rt></ruby>是一个控制器，用于确保守护进程化的应用一直运行在具有特定标签的节点中。</p><p>例如，你将所有节点增加 <code>logger</code> 或 <code>mission_critical</code> 的标签，以便运行日志 &#x2F; 审计服务的守护进程。接着，你创建一个守护进程组并使用 <code>logger</code> 或 <code>mission_critical</code> 节点选择器。Kubernetes 会查找具有该标签的节点，确保守护进程的实例一直运行在这些节点中。因而，节点中运行的所有进程都可以在节点内访问对应的守护进程。</p><p>以我的应用为例，NSQ 守护进程可以用守护进程组实现。具体而言，将对应节点增加 <code>recevier</code> 标签，创建一个守护进程组并配置 <code>receiver</code> 应用选择器，这样这些节点上就会一直运行接收者组件。</p><p>守护进程组具有副本组的全部优势，可扩展且由 Kubernetes 管理，意味着 Kubernetes 管理其全生命周期的事件，确保持续运行，即使出现故障，也会立即替换。</p><h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><p>在 Kubernetes 中，扩展是稀松平常的事情。副本组负责 Pod 运行的实例数目。就像你在 nginx 部署那个示例中看到的那样，对应设置项 <code>replicas:3</code>。我们可以按应用所需，让 Kubernetes 运行多份应用副本。</p><p>当然，设置项有很多。你可以指定让多个副本运行在不同的节点上，也可以指定各种不同的应用启动等待时间。想要在这方面了解更多，可以阅读 <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">水平扩展</a> 和 <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tutorials/kubernetes-basics/scale-interactive/">Kubernetes 中的交互式扩展</a>；当然 <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/">副本组</a> 的细节对你也有帮助，毕竟 Kubernetes 中的扩展功能都来自于该模块。</p><h3 id="Kubernetes-部分小结"><a href="#Kubernetes-部分小结" class="headerlink" title="Kubernetes 部分小结"></a>Kubernetes 部分小结</h3><p>Kubernetes 是容器编排的便捷工具，工作单元为 Pod，具有分层架构。最顶层是部署，用于操作其它资源，具有高度可配置性。对于你的每个命令调用，Kubernetes 提供了对应的 API，故理论上你可以编写自己的代码，向 Kubernetes API 发送数据，得到与 <code>kubectl</code> 命令同样的效果。</p><p>截至目前，Kubernetes 原生支持所有主流云服务供应商，而且完全开源。如果你愿意，可以贡献代码；如果你希望对工作原理有深入了解，可以查阅代码：<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes">GitHub 上的 Kubernetes 项目</a>。</p><h3 id="Minikube"><a href="#Minikube" class="headerlink" title="Minikube"></a>Minikube</h3><p>接下来我会使用 <a target="_blank" rel="noopener" href="https://github.com/kubernetes/minikube/">Minikube</a> 这款本地 Kubernetes 集群模拟器。它并不擅长模拟多节点集群，但可以很容易地给你提供本地学习环境，让你开始探索，这很棒。Minikube 基于可高度调优的虚拟机，由 VirtualBox 类似的虚拟化工具提供。</p><p>我用到的全部 Kubernetes 模板文件可以在这里找到：<a target="_blank" rel="noopener" href="https://github.com/Skarlso/kube-cluster-sample/tree/master/kube_files">Kubernetes 文件</a>。</p><p>注意：在你后续测试可扩展性时，会发现副本一直处于 <code>Pending</code> 状态，这是因为 minikube 集群中只有一个节点，不应该允许多副本运行在同一个节点上，否则明显只是耗尽了可用资源。使用如下命令可以查看可用资源：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes -o yaml</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="构建容器"><a href="#构建容器" class="headerlink" title="构建容器"></a>构建容器</h3><p>Kubernetes 支持大多数现有的容器技术。我这里使用 Docker。每一个构建的服务容器，对应代码库中的一个 Dockerfile 文件。我推荐你仔细阅读它们，其中大多数都比较简单。对于 Go 服务，我采用了最近引入的多步构建的方式。Go 服务基于 Alpine Linux 镜像创建。人脸识别程序使用 Python、NSQ 和 MySQL 使用对应的容器。</p><h3 id="上下文"><a href="#上下文" class="headerlink" title="上下文"></a>上下文</h3><p>Kubernetes 使用命名空间。如果你不额外指定命名空间，Kubernetes 会使用 <code>default</code> 命名空间。为避免污染默认命名空间，我会一直指定命名空间，具体操作如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">❯ kubectl config set-context kube-face-cluster --namespace=face</span><br><span class="line">Context &quot;kube-face-cluster&quot; created.</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>创建上下文之后，应马上启用：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">❯ kubectl config use-context kube-face-cluster</span><br><span class="line">Switched to context &quot;kube-face-cluster&quot;.</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>此后，所有 <code>kubectl</code> 命令都会使用 <code>face</code> 命名空间。</p><p>（LCTT 译注：作者后续并没有使用 face 命名空间，模板文件中的命名空间仍为 default，可能 face 命名空间用于开发环境。如果希望使用 face 命令空间，需要将内部 DNS 地址中的 default 改成 face；如果只是测试，可以不执行这两条命令。）</p><h2 id="应用部署"><a href="#应用部署" class="headerlink" title="应用部署"></a>应用部署</h2><p>Pods 和 服务概览:</p><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201807/30/182244ug3n5n07025e3zlv.jpg"></p><h3 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h3><p>第一个要部署的服务是数据库。</p><p>按照 Kubernetes 的示例 <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/run-application/run-single-instance-stateful-application/#deploy-mysql">Kubenetes MySQL</a> 进行部署，即可以满足我的需求。注意：示例配置文件的 MYSQL_PASSWORD 字段使用了明文密码，我将使用 <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/configuration/secret/">Kubernetes Secrets</a> 对象以提高安全性。</p><p>我创建了一个 Secret 对象，对应的本地 yaml 文件如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-face-secret</span><br><span class="line">type: Opaque</span><br><span class="line">data:</span><br><span class="line">  mysql_password: base64codehere</span><br><span class="line">  mysql_userpassword: base64codehere</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>其中 base64 编码通过如下命令生成：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo -n &quot;ubersecurepassword&quot; | base64</span><br><span class="line">echo -n &quot;root:ubersecurepassword&quot; | base64</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（LCTT 译注：secret yaml 文件中的 data 应该有两条，一条对应 <code>mysql_password</code>，仅包含密码；另一条对应 <code>mysql_userpassword</code>，包含用户和密码。后文会用到 <code>mysql_userpassword</code>，但没有提及相应的生成）</p><p>我的部署 yaml 对应部分如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">- name: MYSQL_ROOT_PASSWORD</span><br><span class="line">  valueFrom:</span><br><span class="line">    secretKeyRef:</span><br><span class="line">      name: kube-face-secret</span><br><span class="line">      key: mysql_password</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>另外值得一提的是，我使用卷将数据库持久化，卷对应的定义如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: mysql-persistent-storage</span><br><span class="line">          mountPath: /var/lib/mysql</span><br><span class="line">...</span><br><span class="line">      volumes:</span><br><span class="line">      - name: mysql-persistent-storage</span><br><span class="line">        persistentVolumeClaim:</span><br><span class="line">          claimName: mysql-pv-claim</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>其中 <code>presistentVolumeClain</code> 是关键，告知 Kubernetes 当前资源需要持久化存储。持久化存储的提供方式对用户透明。类似 Pods，如果想了解更多细节，参考文档：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/storage/persistent-volumes">Kubernetes 持久化存储</a>。</p><p>（LCTT 译注：使用 <code>presistentVolumeClain</code> 之前需要创建 <code>presistentVolume</code>，对于单节点可以使用本地存储，对于多节点需要使用共享存储，因为 Pod 可以能调度到任何一个节点）</p><p>使用如下命令部署 MySQL 服务：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f mysql.yaml</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里比较一下 <code>create</code> 和 <code>apply</code>。<code>apply</code> 是一种<ruby>宣告式 <rt>declarative</rt></ruby>的对象配置命令，而 <code>create</code> 是<ruby>命令式 <rt>imperative</rt> 的命令。当下我们需要知道的是， <code>create</code> 通常对应一项任务，例如运行某个组件或创建一个部署；相比而言，当我们使用 <code>apply</code> 的时候，用户并没有指定具体操作，Kubernetes 会根据集群目前的状态定义需要执行的操作。故如果不存在名为 <code>mysql</code> 的服务，当我执行 <code>apply -f mysql.yaml</code> 时，Kubernetes 会创建该服务。如果再次执行这个命令，Kubernetes 会忽略该命令。但如果我再次运行 <code>create</code> ，Kubernetes 会报错，告知服务已经创建。</ruby></p><p>想了解更多信息，请阅读如下文档：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/overview/object-management-kubectl/overview/">Kubernetes 对象管理</a>，<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/overview/object-management-kubectl/imperative-config/">命令式配置</a>和<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/overview/object-management-kubectl/declarative-config/">宣告式配置</a>。</p><p>运行如下命令查看执行进度信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 描述完整信息</span><br><span class="line">kubectl describe deployment mysql</span><br><span class="line"># 仅描述 Pods 信息</span><br><span class="line">kubectl get pods -l app=mysql</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（第一个命令）输出示例如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">  Type           Status  Reason</span><br><span class="line">  ----           ------  ------</span><br><span class="line">  Available      True    MinimumReplicasAvailable</span><br><span class="line">  Progressing    True    NewReplicaSetAvailable</span><br><span class="line">OldReplicaSets:  &lt;none&gt;</span><br><span class="line">NewReplicaSet:   mysql-55cd6b9f47 (1/1 replicas created)</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>对于 <code>get pods</code> 命令，输出示例如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NAME                     READY     STATUS    RESTARTS   AGE</span><br><span class="line">mysql-78dbbd9c49-k6sdv   1/1       Running   0          18s</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>可以使用下面的命令测试数据库实例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl run -it --rm --image=mysql:5.6 --restart=Never mysql-client -- mysql -h mysql -pyourpasswordhere</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>特别提醒：如果你在这里修改了密码，重新 apply 你的 yaml 文件并不能更新容器。因为数据库是持久化的，密码并不会改变。你需要先使用 <code>kubectl delete -f mysql.yaml</code> 命令删除整个部署。</p><p>运行 <code>show databases</code> 后，应该可以看到如下信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line"></span><br><span class="line">mysql&gt;</span><br><span class="line">mysql&gt;</span><br><span class="line">mysql&gt; show databases;</span><br><span class="line">+--------------------+</span><br><span class="line">| Database           |</span><br><span class="line">+--------------------+</span><br><span class="line">| information_schema |</span><br><span class="line">| kube               |</span><br><span class="line">| mysql              |</span><br><span class="line">| performance_schema |</span><br><span class="line">+--------------------+</span><br><span class="line">4 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; exit</span><br><span class="line">Bye</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>你会注意到，我还将一个<a target="_blank" rel="noopener" href="https://github.com/Skarlso/kube-cluster-sample/blob/master/database_setup.sql">数据库初始化 SQL</a> 文件挂载到容器中，MySQL 容器会自动运行该文件，导入我将用到的部分数据和模式。</p><p>对应的卷定义如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">  volumeMounts:</span><br><span class="line">  - name: mysql-persistent-storage</span><br><span class="line">    mountPath: /var/lib/mysql</span><br><span class="line">  - name: bootstrap-script</span><br><span class="line">    mountPath: /docker-entrypoint-initdb.d/database_setup.sql</span><br><span class="line">volumes:</span><br><span class="line">- name: mysql-persistent-storage</span><br><span class="line">  persistentVolumeClaim:</span><br><span class="line">    claimName: mysql-pv-claim</span><br><span class="line">- name: bootstrap-script</span><br><span class="line">  hostPath:</span><br><span class="line">    path: /Users/hannibal/golang/src/github.com/Skarlso/kube-cluster-sample/database_setup.sql</span><br><span class="line">    type: File</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（LCTT 译注：数据库初始化脚本需要改成对应的路径，如果是多节点，需要是共享存储中的路径。另外，作者给的 sql 文件似乎有误，<code>person_images</code> 表中的 <code>person_id</code> 列数字都小 1，作者默认 <code>id</code> 从 0 开始，但应该是从 1 开始）</p><p>运行如下命令查看引导脚本是否正确执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">~/golang/src/github.com/Skarlso/kube-cluster-sample/kube_files master*</span><br><span class="line">❯ kubectl run -it --rm --image=mysql:5.6 --restart=Never mysql-client -- mysql -h mysql -uroot -pyourpasswordhere kube</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line"></span><br><span class="line">mysql&gt; show tables;</span><br><span class="line">+----------------+</span><br><span class="line">| Tables_in_kube |</span><br><span class="line">+----------------+</span><br><span class="line">| images         |</span><br><span class="line">| person         |</span><br><span class="line">| person_images  |</span><br><span class="line">+----------------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（LCTT 译注：上述代码块中的第一行是作者执行命令所在路径，执行第二行的命令无需在该目录中进行）</p><p>上述操作完成了数据库服务的初始化。使用如下命令可以查看服务日志：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl logs deployment/mysql -f</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="NSQ-查询"><a href="#NSQ-查询" class="headerlink" title="NSQ 查询"></a>NSQ 查询</h3><p>NSQ 查询将以内部服务的形式运行。由于不需要外部访问，这里使用 <code>clusterIP: None</code> 在 Kubernetes 中将其设置为<ruby>无头服务 <rt>headless service</rt></ruby>，意味着该服务不使用负载均衡模式，也不使用单独的服务 IP。DNS 将基于服务<ruby>选择器 <rt>selectors</rt></ruby>。</p><p>我们的 NSQ 查询服务对应的选择器为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">selector:</span><br><span class="line">  matchLabels:</span><br><span class="line">    app: nsqlookup</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>那么，内部 DNS 对应的实体类似于：<code>nsqlookup.default.svc.cluster.local</code>。</p><p>无头服务的更多细节，可以参考：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/services-networking/service/#headless-services">无头服务</a>。</p><p>NSQ 服务与 MySQL 服务大同小异，只需要少许修改即可。如前所述，我将使用 NSQ 原生的 Docker 镜像，名称为 <code>nsqio/nsq</code>。镜像包含了全部的 nsq 命令，故 nsqd 也将使用该镜像，只是使用的命令不同。对于 nsqlookupd，命令如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">command: [&quot;/nsqlookupd&quot;]</span><br><span class="line">args: [&quot;--broadcast-address=nsqlookup.default.svc.cluster.local&quot;]</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>你可能会疑惑，<code>--broadcast-address</code> 参数是做什么用的？默认情况下，<code>nsqlookup</code> 使用容器的主机名作为广播地址；这意味着，当用户运行回调时，回调试图访问的地址类似于 <code>http://nsqlookup-234kf-asdf:4161/lookup?topics=image</code>，但这显然不是我们期望的。将广播地址设置为内部 DNS 后，回调地址将是 <code>http://nsqlookup.default.svc.cluster.local:4161/lookup?topic=images</code>，这正是我们期望的。</p><p>NSQ 查询还需要转发两个端口，一个用于广播，另一个用于 nsqd 守护进程的回调。在 Dockerfile 中暴露相应端口，在 Kubernetes 模板中使用它们，类似如下：</p><p>容器模板：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ports:</span><br><span class="line">- containerPort: 4160</span><br><span class="line">  hostPort: 4160</span><br><span class="line">- containerPort: 4161</span><br><span class="line">  hostPort: 4161</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>服务模板：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: main</span><br><span class="line">    protocol: TCP</span><br><span class="line">    port: 4160</span><br><span class="line">    targetPort: 4160</span><br><span class="line">  - name: secondary</span><br><span class="line">    protocol: TCP</span><br><span class="line">    port: 4161</span><br><span class="line">    targetPort: 4161</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>端口名称是必须的，Kubernetes 基于名称进行区分。（LCTT 译注：端口名更新为作者 GitHub 对应文件中的名称）</p><p>像之前那样，使用如下命令创建服务：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f nsqlookup.yaml</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>nsqlookupd 部分到此结束。截至目前，我们已经准备好两个主要的组件。</p><h3 id="接收器-1"><a href="#接收器-1" class="headerlink" title="接收器"></a>接收器</h3><p>这部分略微复杂。接收器需要完成三项工作：</p><ul><li>创建一些部署</li><li>创建 nsq 守护进程</li><li>将本服务对外公开</li></ul><h4 id="部署-1"><a href="#部署-1" class="headerlink" title="部署"></a>部署</h4><p>第一个要创建的部署是接收器本身，容器镜像为 <code>skarlso/kube-receiver-alpine</code>。</p><h4 id="NSQ-守护进程"><a href="#NSQ-守护进程" class="headerlink" title="NSQ 守护进程"></a>NSQ 守护进程</h4><p>接收器需要使用 NSQ 守护进程。如前所述，接收器在其内部运行一个 NSQ，这样与 nsq 的通信可以在本地进行，无需通过网络。为了让接收器可以这样操作，NSQ 需要与接收器部署在同一个节点上。</p><p>NSQ 守护进程也需要一些调整的参数配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">ports:</span><br><span class="line">- containerPort: 4150</span><br><span class="line">  hostPort: 4150</span><br><span class="line">- containerPort: 4151</span><br><span class="line">  hostPort: 4151</span><br><span class="line">env:</span><br><span class="line">- name: NSQLOOKUP_ADDRESS</span><br><span class="line">  value: nsqlookup.default.svc.cluster.local</span><br><span class="line">- name: NSQ_BROADCAST_ADDRESS</span><br><span class="line">  value: nsqd.default.svc.cluster.local</span><br><span class="line">command: [&quot;/nsqd&quot;]</span><br><span class="line">args: [&quot;--lookupd-tcp-address=$(NSQLOOKUP_ADDRESS):4160&quot;, &quot;--broadcast-address=$(NSQ_BROADCAST_ADDRESS)&quot;]</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>其中我们配置了 <code>lookup-tcp-address</code> 和 <code>broadcast-address</code> 参数。前者是 nslookup 服务的 DNS 地址，后者用于回调，就像 nsqlookupd 配置中那样。</p><h4 id="对外公开"><a href="#对外公开" class="headerlink" title="对外公开"></a>对外公开</h4><p>下面即将创建第一个对外公开的服务。有两种方式可供选择。考虑到该 API 负载较高，可以使用负载均衡的方式。另外，如果希望将其部署到生产环境中的任选节点，也应该使用负载均衡方式。</p><p>但由于我使用的本地集群只有一个节点，那么使用 <code>NodePort</code> 的方式就足够了。<code>NodePort</code> 方式将服务暴露在对应节点的固定端口上。如果未指定端口，将从 30000-32767 数字范围内随机选其一个。也可以指定端口，可以在模板文件中使用 <code>nodePort</code> 设置即可。可以通过 <code>&lt;NodeIP&gt;:&lt;NodePort&gt;</code> 访问该服务。如果使用多个节点，负载均衡可以将多个 IP 合并为一个 IP。</p><p>更多信息，请参考文档：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services---service-types">服务发布</a>。</p><p>结合上面的信息，我们定义了接收器服务，对应的模板如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: receiver-service</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - protocol: TCP</span><br><span class="line">    port: 8000</span><br><span class="line">    targetPort: 8000</span><br><span class="line">  selector:</span><br><span class="line">    app: receiver</span><br><span class="line">  type: NodePort</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如果希望固定使用 8000 端口，需要增加 <code>nodePort</code> 配置，具体如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: receiver-service</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - protocol: TCP</span><br><span class="line">    port: 8000</span><br><span class="line">    targetPort: 8000</span><br><span class="line">  selector:</span><br><span class="line">    app: receiver</span><br><span class="line">  type: NodePort</span><br><span class="line">  nodePort: 8000</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（LCTT 译注：虽然作者没有写，但我们应该知道需要运行的部署命令 <code>kubectl apply -f receiver.yaml</code>。）</p><h3 id="图片处理器-1"><a href="#图片处理器-1" class="headerlink" title="图片处理器"></a>图片处理器</h3><p>图片处理器用于将图片传送至识别组件。它需要访问 nslookupd、 mysql 以及后续部署的人脸识别服务的 gRPC 接口。事实上，这是一个无聊的服务，甚至其实并不是服务（LCTT 译注：第一个服务是指在整个架构中，图片处理器作为一个服务；第二个服务是指 Kubernetes 服务）。它并需要对外暴露端口，这是第一个只包含部署的组件。长话短说，下面是完整的模板：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: image-processor-deployment</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: image-processor</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: image-processor</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: image-processor</span><br><span class="line">        image: skarlso/kube-processor-alpine:latest</span><br><span class="line">        env:</span><br><span class="line">        - name: MYSQL_CONNECTION</span><br><span class="line">          value: &quot;mysql.default.svc.cluster.local&quot;</span><br><span class="line">        - name: MYSQL_USERPASSWORD</span><br><span class="line">          valueFrom:</span><br><span class="line">            secretKeyRef:</span><br><span class="line">              name: kube-face-secret</span><br><span class="line">              key: mysql_userpassword</span><br><span class="line">        - name: MYSQL_PORT</span><br><span class="line">          # TIL: If this is 3306 without &quot; kubectl throws an error.</span><br><span class="line">          value: &quot;3306&quot;</span><br><span class="line">        - name: MYSQL_DBNAME</span><br><span class="line">          value: kube</span><br><span class="line">        - name: NSQ_LOOKUP_ADDRESS</span><br><span class="line">          value: &quot;nsqlookup.default.svc.cluster.local:4161&quot;</span><br><span class="line">        - name: GRPC_ADDRESS</span><br><span class="line">          value: &quot;face-recog.default.svc.cluster.local:50051&quot;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>文件中唯一需要提到的是用于配置应用的多个环境变量属性，主要关注 nsqlookupd 地址 和 gRPC 地址。</p><p>运行如下命令完成部署：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f image_processor.yaml</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="人脸识别-1"><a href="#人脸识别-1" class="headerlink" title="人脸识别"></a>人脸识别</h3><p>人脸识别服务的确包含一个 Kubernetes 服务，具体而言是一个比较简单、仅供图片处理器使用的服务。模板如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: face-recog</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - protocol: TCP</span><br><span class="line">    port: 50051</span><br><span class="line">    targetPort: 50051</span><br><span class="line">  selector:</span><br><span class="line">    app: face-recog</span><br><span class="line">  clusterIP: None</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>更有趣的是，该服务涉及两个卷，分别为 <code>known_people</code> 和 <code>unknown_people</code>。你能猜到卷中包含什么内容吗？对，是图片。<code>known_people</code> 卷包含所有新图片，接收器收到图片后将图片发送至该卷对应的路径，即挂载点。在本例中，挂载点为 <code>/unknown_people</code>，人脸识别服务需要能够访问该路径。</p><p>对于 Kubernetes 和 Docker 而言，这很容易。卷可以使用挂载的 S3 或 某种 nfs，也可以是宿主机到虚拟机的本地挂载。可选方式有很多 （至少有一打那么多）。为简洁起见，我将使用本地挂载方式。</p><p>挂载卷分为两步。第一步，需要在 Dockerfile 中指定卷：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">VOLUME [ &quot;/unknown_people&quot;, &quot;/known_people&quot; ]</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>第二步，就像之前为 MySQL Pod 挂载卷那样，需要在 Kubernetes 模板中配置；相比而言，这里使用 <code>hostPath</code>，而不是 MySQL 例子中的 <code>PersistentVolumeClaim</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">  volumeMounts:</span><br><span class="line">  - name: known-people-storage</span><br><span class="line">    mountPath: /known_people</span><br><span class="line">  - name: unknown-people-storage</span><br><span class="line">    mountPath: /unknown_people</span><br><span class="line">volumes:</span><br><span class="line">- name: known-people-storage</span><br><span class="line">  hostPath:</span><br><span class="line">    path: /Users/hannibal/Temp/known_people</span><br><span class="line">    type: Directory</span><br><span class="line">- name: unknown-people-storage</span><br><span class="line">  hostPath:</span><br><span class="line">    path: /Users/hannibal/Temp/</span><br><span class="line">    type: Directory</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>（LCTT 译注：对于多节点模式，由于人脸识别服务和接收器服务可能不在一个节点上，故需要使用共享存储而不是节点本地存储。另外，出于 Python 代码的逻辑，推荐保持两个文件夹的嵌套结构，即 known_people 作为子目录。）</p><p>我们还需要为 <code>known_people</code> 文件夹做配置设置，用于人脸识别程序。当然，使用环境变量属性可以完成该设置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">env:</span><br><span class="line">- name: KNOWN_PEOPLE</span><br><span class="line">  value: &quot;/known_people&quot;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Python 代码按如下方式搜索图片：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">known_people = os.getenv(&#x27;KNOWN_PEOPLE&#x27;, &#x27;known_people&#x27;)</span><br><span class="line">print(&quot;Known people images location is: %s&quot; % known_people)</span><br><span class="line">images = self.image_files_in_folder(known_people)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>其中 <code>image_files_in_folder</code> 函数定义如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def image_files_in_folder(self, folder):</span><br><span class="line">    return [os.path.join(folder, f) for f in os.listdir(folder) if re.match(r&#x27;.*\.(jpg|jpeg|png)&#x27;, f, flags=re.I)]</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>看起来不错。</p><p>如果接收器现在收到一个类似下面的请求（接收器会后续将其发送出去）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -d &#x27;&#123;&quot;path&quot;:&quot;/unknown_people/unknown220.jpg&quot;&#125;&#x27; http://192.168.99.100:30251/image/post</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>图像处理器会在 <code>/unknown_people</code> 目录搜索名为 unknown220.jpg 的图片，接着在 <code>known_folder</code> 文件中找到 <code>unknown220.jpg</code> 对应个人的图片，最后返回匹配图片的名称。</p><p>查看日志，大致信息如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 接收器</span><br><span class="line">❯ curl -d &#x27;&#123;&quot;path&quot;:&quot;/unknown_people/unknown219.jpg&quot;&#125;&#x27; http://192.168.99.100:30251/image/post</span><br><span class="line">got path: &#123;Path:/unknown_people/unknown219.jpg&#125;</span><br><span class="line">image saved with id: 4</span><br><span class="line">image sent to nsq</span><br><span class="line"></span><br><span class="line"># 图片处理器</span><br><span class="line">2018/03/26 18:11:21 INF    1 [images/ch] querying nsqlookupd http://nsqlookup.default.svc.cluster.local:4161/lookup?topic=images</span><br><span class="line">2018/03/26 18:11:59 Got a message: 4</span><br><span class="line">2018/03/26 18:11:59 Processing image id:  4</span><br><span class="line">2018/03/26 18:12:00 got person:  Hannibal</span><br><span class="line">2018/03/26 18:12:00 updating record with person id</span><br><span class="line">2018/03/26 18:12:00 done</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>我们已经使用 Kubernetes 部署了应用正常工作所需的全部服务。</p><h3 id="前端-1"><a href="#前端-1" class="headerlink" title="前端"></a>前端</h3><p>更进一步，可以使用简易的 Web 应用更好的显示数据库中的信息。这也是一个对外公开的服务，使用的参数可以参考接收器。</p><p>部署后效果如下：</p><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201807/30/182349h0s7o6yi9o8760ir.jpg"></p><h3 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h3><p>到目前为止我们做了哪些操作呢？我一直在部署服务，用到的命令汇总如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f mysql.yaml</span><br><span class="line">kubectl apply -f nsqlookup.yaml</span><br><span class="line">kubectl apply -f receiver.yaml</span><br><span class="line">kubectl apply -f image_processor.yaml</span><br><span class="line">kubectl apply -f face_recognition.yaml</span><br><span class="line">kubectl apply -f frontend.yaml</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>命令顺序可以打乱，因为除了图片处理器的 NSQ 消费者外的应用在启动时并不会建立连接，而且图片处理器的 NSQ 消费者会不断重试。</p><p>使用 <code>kubectl get pods</code> 查询正在运行的 Pods，示例如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">❯ kubectl get pods</span><br><span class="line">NAME                                          READY     STATUS    RESTARTS   AGE</span><br><span class="line">face-recog-6bf449c6f-qg5tr                    1/1       Running   0          1m</span><br><span class="line">image-processor-deployment-6467468c9d-cvx6m   1/1       Running   0          31s</span><br><span class="line">mysql-7d667c75f4-bwghw                        1/1       Running   0          36s</span><br><span class="line">nsqd-584954c44c-299dz                         1/1       Running   0          26s</span><br><span class="line">nsqlookup-7f5bdfcb87-jkdl7                    1/1       Running   0          11s</span><br><span class="line">receiver-deployment-5cb4797598-sf5ds          1/1       Running   0          26s</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>运行 <code>minikube service list</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">❯ minikube service list</span><br><span class="line">|-------------|----------------------|-----------------------------|</span><br><span class="line">|  NAMESPACE  |         NAME         |             URL             |</span><br><span class="line">|-------------|----------------------|-----------------------------|</span><br><span class="line">| default     | face-recog           | No node port                |</span><br><span class="line">| default     | kubernetes           | No node port                |</span><br><span class="line">| default     | mysql                | No node port                |</span><br><span class="line">| default     | nsqd                 | No node port                |</span><br><span class="line">| default     | nsqlookup            | No node port                |</span><br><span class="line">| default     | receiver-service     | http://192.168.99.100:30251 |</span><br><span class="line">| kube-system | kube-dns             | No node port                |</span><br><span class="line">| kube-system | kubernetes-dashboard | http://192.168.99.100:30000 |</span><br><span class="line">|-------------|----------------------|-----------------------------|</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="滚动更新"><a href="#滚动更新" class="headerlink" title="滚动更新"></a>滚动更新</h2><p><ruby>滚动更新 <rt>Rolling Update</rt></ruby>过程中会发生什么呢？</p><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201807/30/182422mewkb7dxw87rej8v.jpg"></p><p>在软件开发过程中，需要变更应用的部分组件是常有的事情。如果我希望在不影响其它组件的情况下变更一个组件，我们的集群会发生什么变化呢？我们还需要最大程度的保持向后兼容性，以免影响用户体验。谢天谢地，Kubernetes 可以帮我们做到这些。</p><p>目前的 API 一次只能处理一个图片，不能批量处理，对此我并不满意。</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p>目前，我们使用下面的代码段处理单个图片的情形：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">// PostImage 对图片提交做出响应，将图片信息保存到数据库中</span><br><span class="line">// 并将该信息发送给 NSQ 以供后续处理使用</span><br><span class="line">func PostImage(w http.ResponseWriter, r *http.Request) &#123;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">    router := mux.NewRouter()</span><br><span class="line">    router.HandleFunc(&quot;/image/post&quot;, PostImage).Methods(&quot;POST&quot;)</span><br><span class="line">    log.Fatal(http.ListenAndServe(&quot;:8000&quot;, router))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>我们有两种选择。一种是增加新接口 <code>/images/post</code> 给用户使用；另一种是在原接口基础上修改。</p><p>新版客户端有回退特性，在新接口不可用时回退使用旧接口。但旧版客户端没有这个特性，故我们不能马上修改代码逻辑。考虑如下场景，你有 90 台服务器，计划慢慢执行滚动更新，依次对各台服务器进行业务更新。如果一台服务需要大约 1 分钟更新业务，那么整体更新完成需要大约 1 个半小时的时间（不考虑并行更新的情形）。</p><p>更新过程中，一些服务器运行新代码，一些服务器运行旧代码。用户请求被负载均衡到各个节点，你无法控制请求到达哪台服务器。如果客户端的新接口请求被调度到运行旧代码的服务器，请求会失败；客户端可能会回退使用旧接口，（但由于我们已经修改旧接口，本质上仍然是调用新接口），故除非请求刚好到达到运行新代码的服务器，否则一直都会失败。这里我们假设不使用<ruby>粘性会话 <rt>sticky sessions</rt></ruby>。</p><p>而且，一旦所有服务器更新完毕，旧版客户端不再能够使用你的服务。</p><p>这里，你可能会说你并不需要保留旧代码；某些情况下，确实如此。因此，我们打算直接修改旧代码，让其通过少量参数调用新代码。这样操作操作相当于移除了旧代码。当所有客户端迁移完毕后，这部分代码也可以安全地删除。</p><h3 id="新的接口"><a href="#新的接口" class="headerlink" title="新的接口"></a>新的接口</h3><p>让我们添加新的路由方法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">router.HandleFunc(&quot;/images/post&quot;, PostImages).Methods(&quot;POST&quot;)</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>更新旧的路由方法，使其调用新的路由方法，修改部分如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">// PostImage 对图片提交做出响应，将图片信息保存到数据库中</span><br><span class="line">// 并将该信息发送给 NSQ 以供后续处理使用</span><br><span class="line">func PostImage(w http.ResponseWriter, r *http.Request) &#123;</span><br><span class="line">    var p Path</span><br><span class="line">    err := json.NewDecoder(r.Body).Decode(&amp;p)</span><br><span class="line">    if err != nil &#123;</span><br><span class="line">      fmt.Fprintf(w, &quot;got error while decoding body: %s&quot;, err)</span><br><span class="line">      return</span><br><span class="line">    &#125;</span><br><span class="line">    fmt.Fprintf(w, &quot;got path: %+v\n&quot;, p)</span><br><span class="line">    var ps Paths</span><br><span class="line">    paths := make([]Path, 0)</span><br><span class="line">    paths = append(paths, p)</span><br><span class="line">    ps.Paths = paths</span><br><span class="line">    var pathsJSON bytes.Buffer</span><br><span class="line">    err = json.NewEncoder(&amp;pathsJSON).Encode(ps)</span><br><span class="line">    if err != nil &#123;</span><br><span class="line">      fmt.Fprintf(w, &quot;failed to encode paths: %s&quot;, err)</span><br><span class="line">      return</span><br><span class="line">    &#125;</span><br><span class="line">    r.Body = ioutil.NopCloser(&amp;pathsJSON)</span><br><span class="line">    r.ContentLength = int64(pathsJSON.Len())</span><br><span class="line">    PostImages(w, r)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>当然，方法名可能容易混淆，但你应该能够理解我想表达的意思。我将请求中的单个路径封装成新方法所需格式，然后将其作为请求发送给新接口处理。仅此而已。在 <a target="_blank" rel="noopener" href="https://github.com/Skarlso/kube-cluster-sample/pull/1">滚动更新批量图片的 PR</a> 中可以找到更多的修改方式。</p><p>至此，我们使用两种方法调用接收器：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 单路径模式</span><br><span class="line">curl -d &#x27;&#123;&quot;path&quot;:&quot;unknown4456.jpg&quot;&#125;&#x27; http://127.0.0.1:8000/image/post</span><br><span class="line"></span><br><span class="line"># 多路径模式</span><br><span class="line">curl -d &#x27;&#123;&quot;paths&quot;:[&#123;&quot;path&quot;:&quot;unknown4456.jpg&quot;&#125;]&#125;&#x27; http://127.0.0.1:8000/images/post</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里用到的客户端是 curl。一般而言，如果客户端本身是一个服务，我会做一些修改，在新接口返回 404 时继续尝试旧接口。</p><p>为了简洁，我不打算为 NSQ 和其它组件增加批量图片处理的能力。这些组件仍然是一次处理一个图片。这部分修改将留给你作为扩展内容。 :)</p><h3 id="新镜像"><a href="#新镜像" class="headerlink" title="新镜像"></a>新镜像</h3><p>为实现滚动更新，我首先需要为接收器服务创建一个新的镜像。新镜像使用新标签，告诉大家版本号为 v1.1。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker build -t skarlso/kube-receiver-alpine:v1.1 .</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>新镜像创建后，我们可以开始滚动更新了。</p><h3 id="滚动更新-1"><a href="#滚动更新-1" class="headerlink" title="滚动更新"></a>滚动更新</h3><p>在 Kubernetes 中，可以使用多种方式完成滚动更新。</p><h4 id="手动更新"><a href="#手动更新" class="headerlink" title="手动更新"></a>手动更新</h4><p>不妨假设在我配置文件中使用的容器版本为 <code>v1.0</code>，那么实现滚动更新只需运行如下命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl rolling-update receiver --image:skarlso/kube-receiver-alpine:v1.1</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如果滚动更新过程中出现问题，我们总是可以回滚：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl rolling-update receiver --rollback</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>容器将回滚到使用上一个版本镜像，操作简捷无烦恼。</p><h4 id="应用新的配置文件"><a href="#应用新的配置文件" class="headerlink" title="应用新的配置文件"></a>应用新的配置文件</h4><p>手动更新的不足在于无法版本管理。</p><p>试想下面的场景。你使用手工更新的方式对若干个服务器进行滚动升级，但其它人并不知道这件事。之后，另外一个人修改了模板文件并将其应用到集群中，更新了全部服务器；更新过程中，突然发现服务不可用了。</p><p>长话短说，由于模板无法识别已经手动更新的服务器，这些服务器会按模板变更成错误的状态。这种做法很危险，千万不要这样做。</p><p>推荐的做法是，使用新版本信息更新模板文件，然后使用 <code>apply</code> 命令应用模板文件。</p><p>对于滚动扩展，Kubernetes 推荐通过部署结合副本组完成。但这意味着待滚动更新的应用至少有 2 个副本，否则无法完成 （除非将 <code>maxUnavailable</code> 设置为 1）。我在模板文件中增加了副本数量、设置了接收器容器的新镜像版本。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">  replicas: 2</span><br><span class="line">...</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: receiver</span><br><span class="line">        image: skarlso/kube-receiver-alpine:v1.1</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>更新过程中，你会看到如下信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">❯ kubectl rollout status deployment/receiver-deployment</span><br><span class="line">Waiting for rollout to finish: 1 out of 2 new replicas have been updated...</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>通过在模板中增加 <code>strategy</code> 段，你可以增加更多的滚动扩展配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">strategy:</span><br><span class="line">  type: RollingUpdate</span><br><span class="line">  rollingUpdate:</span><br><span class="line">    maxSurge: 1</span><br><span class="line">    maxUnavailable: 0</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>关于滚动更新的更多信息，可以参考如下文档：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#rolling-back-a-deployment">部署的滚动更新</a>，<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#updating-a-deployment">部署的更新</a>， <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#updating-your-application-without-a-service-outage">部署的管理</a> 和 <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/run-application/rolling-update-replication-controller/">使用副本控制器完成滚动更新</a>等。</p><p>MINIKUBE 用户需要注意：由于我们使用单个主机上使用单节点配置，应用只有 1 份副本，故需要将 <code>maxUnavailable</code> 设置为 <code>1</code>。否则 Kubernetes 会阻止更新，新版本会一直处于 <code>Pending</code> 状态；这是因为我们在任何时刻都不允许出现没有（正在运行的） <code>receiver</code> 容器的场景。</p><h3 id="扩展-1"><a href="#扩展-1" class="headerlink" title="扩展"></a>扩展</h3><p>Kubernetes 让扩展成为相当容易的事情。由于 Kubernetes 管理整个集群，你仅需在模板文件中添加你需要的副本数目即可。</p><p>这篇文章已经比较全面了，但文章的长度也越来越长。我计划再写一篇后续文章，在 AWS 上使用多节点、多副本方式实现扩展。敬请期待。</p><h3 id="清理环境"><a href="#清理环境" class="headerlink" title="清理环境"></a>清理环境</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete deployments --all</span><br><span class="line">kubectl delete services -all</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="写在最后的话"><a href="#写在最后的话" class="headerlink" title="写在最后的话"></a>写在最后的话</h2><p>各位看官，本文就写到这里了。我们在 Kubernetes 上编写、部署、更新和扩展（老实说，并没有实现）了一个分布式应用。</p><p>如果你有任何疑惑，请在下面的评论区留言交流，我很乐意回答相关问题。</p><p>希望阅读本文让你感到愉快。我知道，这是一篇相对长的文章，我也曾经考虑进行拆分；但整合在一起的单页教程也有其好处，例如利于搜索、保存页面或更进一步将页面打印为 PDF 文档。</p><p>Gergely 感谢你阅读本文。</p><hr><p>via: <a target="_blank" rel="noopener" href="https://skarlso.github.io/2018/03/15/kubernetes-distributed-application/">https://skarlso.github.io/2018/03/15/kubernetes-distributed-application/</a></p><p>作者：<a target="_blank" rel="noopener" href="https://github.com/Skarlso">hannibal</a> 译者：<a target="_blank" rel="noopener" href="https://github.com/pinewall">pinewall</a> 校对：<a target="_blank" rel="noopener" href="https://github.com/wxy">wxy</a></p><p>本文由 <a target="_blank" rel="noopener" href="https://github.com/LCTT/TranslateProject">LCTT</a> 原创编译，<a target="_blank" rel="noopener" href="https://linux.cn/">Linux中国</a> 荣誉推出</p></div></div></div><div class="footer"><p class="footer-copyright"><span>Powered by <a target="_blank" href="https://hexo.io">Hexo</a></span> <span>Theme <a target="_blank" href="https://github.com/tinkink-co/hexo-theme-terminal">Terminal</a></span><script type="text/javascript" src="https://cdn.staticfile.net/jquery/3.4.1/jquery.min.js"></script><script>getCDNinfo=function(){$.ajax({url:"/cdn-cgi/trace",success:function(a,n){let i="Antananarivo, Madagascar - (TNR);Cape Town, South Africa - (CPT);Casablanca, Morocco - (CMN);Dar Es Salaam, Tanzania - (DAR);Djibouti City, Djibouti - (JIB);Durban, South Africa - (DUR);Johannesburg, South Africa - (JNB);Kigali, Rwanda - (KGL);Lagos, Nigeria - (LOS);Luanda, Angola - (LAD);Maputo, MZ - (MPM);Mombasa, Kenya - (MBA);Port Louis, Mauritius - (MRU);Réunion, France - (RUN);Bangalore, India - (BLR);Bangkok, Thailand - (BKK);Bandar Seri Begawan, Brunei - (BWN);Cebu, Philippines - (CEB);Chengdu, China - (CTU);Chennai, India - (MAA);Chittagong, Bangladesh - (CGP);Chongqing, China - (CKG);Colombo, Sri Lanka - (CMB);Dhaka, Bangladesh - (DAC);Dongguan, China - (SZX);Foshan, China - (FUO);Fuzhou, China - (FOC);Guangzhou, China - (CAN);Hangzhou, China - (HGH);Hanoi, Vietnam - (HAN);Hengyang, China - (HNY);Ho Chi Minh City, Vietnam - (SGN);Hong Kong - (HKG);Hyderabad, India - (HYD);Islamabad, Pakistan - (ISB);Jakarta, Indonesia - (CGK);Jinan, China - (TNA);Karachi, Pakistan - (KHI);Kathmandu, Nepal - (KTM);Kolkata, India - (CCU);Kuala Lumpur, Malaysia - (KUL);Lahore, Pakistan - (LHE);Langfang, China - (NAY);Luoyang, China - (LYA);Macau - (MFM);Malé, Maldives - (MLE);Manila, Philippines - (MNL);Mumbai, India - (BOM);Nagpur, India - (NAG);Nanning, China - (NNG);New Delhi, India - (DEL);Osaka, Japan - (KIX);Phnom Penh, Cambodia - (PNH);Qingdao, China - (TAO);Seoul, South Korea - (ICN);Shanghai, China - (SHA);Shenyang, China - (SHE);Shijiazhuang, China - (SJW);Singapore, Singapore - (SIN);Suzhou, China - (SZV);Taipei - (TPE);Thimphu, Bhutan - (PBH);Tianjin, China - (TSN);Tokyo, Japan - (NRT);Ulaanbaatar, Mongolia - (ULN);Vientiane, Laos - (VTE);Wuhan, China - (WUH);Wuxi, China - (WUX);Xi'an, China - (XIY);Yerevan, Armenia - (EVN);Zhengzhou, China - (CGO);Zuzhou, China - (CSX);Amsterdam, Netherlands - (AMS);Athens, Greece - (ATH);Barcelona, Spain - (BCN);Belgrade, Serbia - (BEG);Berlin, Germany - (TXL);Brussels, Belgium - (BRU);Bucharest, Romania - (OTP);Budapest, Hungary - (BUD);Chișinău, Moldova - (KIV);Copenhagen, Denmark - (CPH);Cork, Ireland -  (ORK);Dublin, Ireland - (DUB);Düsseldorf, Germany - (DUS);Edinburgh, United Kingdom - (EDI);Frankfurt, Germany - (FRA);Geneva, Switzerland - (GVA);Gothenburg, Sweden - (GOT);Hamburg, Germany - (HAM);Helsinki, Finland - (HEL);Istanbul, Turkey - (IST);Kyiv, Ukraine - (KBP);Lisbon, Portugal - (LIS);London, United Kingdom - (LHR);Luxembourg City, Luxembourg - (LUX);Madrid, Spain - (MAD);Manchester, United Kingdom - (MAN);Marseille, France - (MRS);Milan, Italy - (MXP);Moscow, Russia - (DME);Munich, Germany - (MUC);Nicosia, Cyprus - (LCA);Oslo, Norway - (OSL);Paris, France - (CDG);Prague, Czech Republic - (PRG);Reykjavík, Iceland - (KEF);Riga, Latvia - (RIX);Rome, Italy - (FCO);Saint Petersburg, Russia - (LED);Sofia, Bulgaria - (SOF);Stockholm, Sweden - (ARN);Tallinn, Estonia - (TLL);Thessaloniki, Greece - (SKG);Vienna, Austria - (VIE);Vilnius, Lithuania - (VNO);Warsaw, Poland - (WAW);Zagreb, Croatia - (ZAG);Zürich, Switzerland - (ZRH);Arica, Chile - (ARI);Asunción, Paraguay - (ASU);Bogotá, Colombia - (BOG);Buenos Aires, Argentina - (EZE);Curitiba, Brazil - (CWB);Fortaleza, Brazil - (FOR);Guatemala City, Guatemala - (GUA);Lima, Peru - (LIM);Medellín, Colombia - (MDE);Panama City, Panama - (PTY);Porto Alegre, Brazil - (POA);Quito, Ecuador - (UIO);Rio de Janeiro, Brazil - (GIG);São Paulo, Brazil - (GRU);Santiago, Chile - (SCL);Willemstad, Curaçao - (CUR);St. George's, Grenada - (GND);Amman, Jordan - (AMM);Baghdad, Iraq - (BGW);Baku, Azerbaijan - (GYD);Beirut, Lebanon - (BEY);Doha, Qatar - (DOH);Dubai, United Arab Emirates - (DXB);Kuwait City, Kuwait - (KWI);Manama, Bahrain - (BAH);Muscat, Oman - (MCT);Ramallah - (ZDM);Riyadh, Saudi Arabia - (RUH);Tel Aviv, Israel - (TLV);Ashburn, VA, United States - (IAD);Atlanta, GA, United States - (ATL);Boston, MA, United States - (BOS);Buffalo, NY, United States - (BUF);Calgary, AB, Canada - (YYC);Charlotte, NC, United States - (CLT);Chicago, IL, United States - (ORD);Columbus, OH, United States - (CMH);Dallas, TX, United States - (DFW);Denver, CO, United States - (DEN);Detroit, MI, United States - (DTW);Honolulu, HI, United States - (HNL);Houston, TX, United States - (IAH);Indianapolis, IN, United States - (IND);Jacksonville, FL, United States - (JAX);Kansas City, MO, United States - (MCI);Las Vegas, NV, United States - (LAS);Los Angeles, CA, United States - (LAX);McAllen, TX, United States - (MFE);Memphis, TN, United States - (MEM);Mexico City, Mexico - (MEX);Miami, FL, United States - (MIA);Minneapolis, MN, United States - (MSP);Montgomery, AL, United States - (MGM);Montréal, QC, Canada - (YUL);Nashville, TN, United States - (BNA);Newark, NJ, United States - (EWR);Norfolk, VA, United States - (ORF);Omaha, NE, United States - (OMA);Philadelphia, United States - (PHL);Phoenix, AZ, United States - (PHX);Pittsburgh, PA, United States - (PIT);Port-Au-Prince, Haiti - (PAP);Portland, OR, United States - (PDX);Queretaro, MX, Mexico - (QRO);Richmond, Virginia - (RIC);Sacramento, CA, United States - (SMF);Salt Lake City, UT, United States - (SLC);San Diego, CA, United States - (SAN);San Jose, CA, United States - (SJC);Saskatoon, SK, Canada - (YXE);Seattle, WA, United States - (SEA);St. Louis, MO, United States - (STL);Tampa, FL, United States - (TPA);Toronto, ON, Canada - (YYZ);Vancouver, BC, Canada - (YVR);Tallahassee, FL, United States - (TLH);Winnipeg, MB, Canada - (YWG);Adelaide, SA, Australia - (ADL);Auckland, New Zealand - (AKL);Brisbane, QLD, Australia - (BNE);Melbourne, VIC, Australia - (MEL);Noumea, New caledonia - (NOU);Perth, WA, Australia - (PER);Sydney, NSW, Australia - (SYD)".split(";"),e=a.split("colo=")[1].split("\n")[0],t=(a.split("colo=")[1].split("\n")[0],a.split("tls=")[1].split("\n")[0]),o=a.split("http=")[1].split("\n")[0],s=a.split("sni=")[1].split("\n")[0],r=a.split("ip=")[1].split("\n")[0],l=a.split("uag=")[1].split("\n")[0];for(var d=0;d<i.length;d++)if(-1!=i[d].indexOf(e)){document.getElementById("cdn").innerHTML=i[d];break}document.getElementById("tls").innerHTML=t,document.getElementById("http").innerHTML=o,document.getElementById("sni").innerHTML=s,document.getElementById("ip").innerHTML=r,document.getElementById("useragent").innerHTML=l}})},$(document).ready((function(){getCDNinfo()}))</script></p><p style="text-align:center">感谢陪伴与布道，开源之火不灭。​</p><p style="text-align:center"><script>document.write("本次加载耗时: "+(performance.getEntriesByType("navigation").reduce((e,r)=>e+r.responseEnd-r.startTime,0)+performance.getEntriesByType("resource").reduce((e,r)=>e+r.responseEnd-r.startTime,0)).toFixed(0)+"ms")</script></p><p style="text-align:center">当前 SNI 状态： <span id="sni">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 TLS 版本： <span id="tls">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 HTTP 版本： <span id="http">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前您的客户端 IP 是： <span id="ip">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前分配的 CDN 节点是: <span id="cdn">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">您的 UserAgent 信息是: <span id="useragent">正在统计！或可能被浏览器防追踪拦截！</span></p><p></p><script defer src="https://pv.undefined.today/tracker.min.js" data-website-id="LinuxCNMirror-tracker"></script></div></div></body></html>