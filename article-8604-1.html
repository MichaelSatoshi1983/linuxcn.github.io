<!doctype html><html lang="en"><head><meta name="msvalidate.01" content="D404690CEFCB54C7762AC84935B99171"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?6618da70c90c8744eead2e9371fb5077";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script type="text/javascript">!function(t,e,n,c,s,a,r){t[n]=t[n]||function(){(t[n].q=t[n].q||[]).push(arguments)},(a=e.createElement(c)).async=1,a.src="https://www.clarity.ms/tag/s5f3f0tojf",(r=e.getElementsByTagName(c)[0]).parentNode.insertBefore(a,r)}(window,document,"clarity","script")</script><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta http-equiv="X-UA-Compatible" content="ie=edge"><link rel="stylesheet" href="/styles/base.css"><link rel="stylesheet" href="/styles/theme.css"><link rel="shortcut icon" href="/favicon.png"><title>机器学习的新捷径：通过 SYCL 在 GPU 上加速 C++ - 归墟星火集 又一个 LinuxCN 站点</title><meta name="generator" content="Hexo 7.3.0"></head><body><div class="header-title"><span class="header-light"></span> <span class="header-light"></span> <span class="header-light"></span> <span>归墟星火集 又一个 LinuxCN 站点 linuxcn.undefined.today<span></span></span></div><div class="container"><ul class="nav"><li><a href="/">首页</a></li><li><a target="_blank" rel="noopener" href="https://undefined.today/">Blog</a></li></ul><div class="content"><div class="post-container"><div class="post-header"><span class="ui-tips">标题：</span><h1 class="ui-keyword post-title">机器学习的新捷径：通过 SYCL 在 GPU 上加速 C++</h1><span class="post-date">2017-06-13</span></div><div class="post-header"><span class="ui-tips">分类：</span> <a href="/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">软件开发</a></div><div class="post-header"><span class="ui-tips">标签：</span> <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a> <a href="/tags/SYCL/">SYCL</a> <a href="/tags/OpenCL/">OpenCL</a></div><div class="post-content"><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201706/13/174644t3bpa2ra424e24e3.jpg"></p><p>在机器学习、计算机视觉以及高性能计算领域，充分利用显卡计算应用程序的能力已成为当前的热门。类似 OpenCL 的技术通过硬件无关的编程模型展现了这种能力，使得你可以编写抽象于不同体系架构的代码。它的目标是“一次编写，到处运行”，不管它是 Intel CPU、AMD 独立显卡还是 DSP 等等。不幸的是，对于日常程序员，OpenCL 的学习曲线陡峭；一个简单的 Hello World 程序可能就需要上百行晦涩难懂的代码。因此，为了减轻这种痛苦，Khronos 组织已经开发了一个称为 <a target="_blank" rel="noopener" href="https://www.khronos.org/sycl">SYCL</a> 的新标准，这是一个在 OpenCL 之上的 C++ 抽象层。通过 SYCL，你可以使用干净、现代的 C++ 开发出这些通用 GPU（GPGPU）应用程序，而无需拘泥于 OpenCL。下面是一个使用 SYCL 开发，通过并行 STL 实现的向量乘法事例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;vector&gt;</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line"></span><br><span class="line">#include &lt;sycl/execution_policy&gt;</span><br><span class="line">#include &lt;experimental/algorithm&gt;</span><br><span class="line">#include &lt;sycl/helpers/sycl_buffers.hpp&gt;</span><br><span class="line"></span><br><span class="line">using namespace std::experimental::parallel;</span><br><span class="line">using namespace sycl::helpers;</span><br><span class="line"></span><br><span class="line">int main() &#123;</span><br><span class="line">  constexpr size_t array_size = 1024*512;</span><br><span class="line">  std::array&lt;cl::sycl::cl_int, array_size&gt; a;</span><br><span class="line">  std::iota(begin(a),end(a),0);</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line">    cl::sycl::buffer&lt;int&gt; b(a.data(), cl::sycl::range&lt;1&gt;(a.size()));</span><br><span class="line">    cl::sycl::queue q;</span><br><span class="line">    sycl::sycl_execution_policy&lt;class Mul&gt; sycl_policy(q);</span><br><span class="line">    transform(sycl_policy, begin(b), end(b), begin(b),</span><br><span class="line">              [](int x) &#123; return x*2; &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>为了作为对比，下面是一个通过 C++ API 使用 OpenCL 编写的大概对应版本（无需花过多时间阅读，只需注意到它看起来难看而且冗长）。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;array&gt;</span><br><span class="line">#include &lt;numeric&gt;</span><br><span class="line">#include &lt;CL/cl.hpp&gt;</span><br><span class="line"></span><br><span class="line">int main()&#123;</span><br><span class="line">    std::vector&lt;cl::Platform&gt; all_platforms;</span><br><span class="line">    cl::Platform::get(&amp;all_platforms);</span><br><span class="line">    if(all_platforms.size()==0)&#123;</span><br><span class="line">        std::cout&lt;&lt;&quot; No platforms found. Check OpenCL installation!\n&quot;;</span><br><span class="line">        exit(1);</span><br><span class="line">    &#125;</span><br><span class="line">    cl::Platform default_platform=all_platforms[0];</span><br><span class="line"></span><br><span class="line">    std::vector&lt;cl::Device&gt; all_devices;</span><br><span class="line">    default_platform.getDevices(CL_DEVICE_TYPE_ALL, &amp;all_devices);</span><br><span class="line">    if(all_devices.size()==0)&#123;</span><br><span class="line">        std::cout&lt;&lt;&quot; No devices found. Check OpenCL installation!\n&quot;;</span><br><span class="line">        exit(1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cl::Device default_device=all_devices[0];</span><br><span class="line">    cl::Context context(&#123;default_device&#125;);</span><br><span class="line"></span><br><span class="line">    cl::Program::Sources sources;</span><br><span class="line">    std::string kernel_code=</span><br><span class="line">        &quot;   void kernel mul2(global int* A)&#123;&quot;</span><br><span class="line">        &quot;       A[get_global_id(0)]=A[get_global_id(0)]*2;&quot;</span><br><span class="line">        &quot;   &#125;&quot;;</span><br><span class="line">    sources.push_back(&#123;kernel_code.c_str(),kernel_code.length()&#125;);</span><br><span class="line"></span><br><span class="line">    cl::Program program(context,sources);</span><br><span class="line">    if(program.build(&#123;default_device&#125;)!=CL_SUCCESS)&#123;</span><br><span class="line">        std::cout&lt;&lt;&quot; Error building: &quot;&lt;&lt;program.getBuildInfo&lt;CL_PROGRAM_BUILD_LOG&gt;(default_device)&lt;&lt;&quot;\n&quot;;</span><br><span class="line">        exit(1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    constexpr size_t array_size = 1024*512;</span><br><span class="line">    std::array&lt;cl_int, array_size&gt; a;</span><br><span class="line">    std::iota(begin(a),end(a),0);</span><br><span class="line"></span><br><span class="line">    cl::Buffer buffer_A(context,CL_MEM_READ_WRITE,sizeof(int)*a.size());</span><br><span class="line">    cl::CommandQueue queue(context,default_device);</span><br><span class="line"></span><br><span class="line">    if (queue.enqueueWriteBuffer(buffer_A,CL_TRUE,0,sizeof(int)*a.size(),a.data()) != CL_SUCCESS) &#123;</span><br><span class="line">        std::cout &lt;&lt; &quot;Failed to write memory;n&quot;;</span><br><span class="line">        exit(1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cl::Kernel kernel_add = cl::Kernel(program,&quot;mul2&quot;);</span><br><span class="line">    kernel_add.setArg(0,buffer_A);</span><br><span class="line"></span><br><span class="line">    if (queue.enqueueNDRangeKernel(kernel_add,cl::NullRange,cl::NDRange(a.size()),cl::NullRange) != CL_SUCCESS) &#123;</span><br><span class="line">        std::cout &lt;&lt; &quot;Failed to enqueue kernel\n&quot;;</span><br><span class="line">        exit(1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (queue.finish() != CL_SUCCESS) &#123;</span><br><span class="line">        std::cout &lt;&lt; &quot;Failed to finish kernel\n&quot;;</span><br><span class="line">        exit(1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (queue.enqueueReadBuffer(buffer_A,CL_TRUE,0,sizeof(int)*a.size(),a.data()) != CL_SUCCESS) &#123;</span><br><span class="line">        std::cout &lt;&lt; &quot;Failed to read result\n&quot;;</span><br><span class="line">        exit(1);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在这篇博文中我会介绍使用 SYCL 加速你 GPU 上的 C++ 代码。</p><h3 id="GPGPU-简介"><a href="#GPGPU-简介" class="headerlink" title="GPGPU 简介"></a>GPGPU 简介</h3><p>在我开始介绍如何使用 SYCL 之前，我首先给那些不熟悉这方面的人简要介绍一下为什么你可能想要在 GPU 上运行计算任务。如果已经使用过 OpenCL、CUDA 或类似的库，可以跳过这一节。</p><p>GPU 和 CPU 的一个关键不同就是 GPU 有大量小的、简单的处理单元，而不是少量（对于普通消费者桌面硬件通常是 1-8 个）复杂而强大的核。</p><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201706/13/174714eahc6khachn6z5hk.png" alt="CPU 架构"></p><p>上面是一个 4 核 CPU 的简单漫画示意图。每个核都有一组寄存器以及不同等级的缓存（有些是共享缓存、有些不是），然后是主内存。</p><p><img src="https://linuxcn.img.undefined.today/data/attachment/album/201706/13/174715iziw6x8iueqzienc.png" alt="GPU 架构"></p><p>在 GPU 上，多个小处理单元被组成一个执行单元。每个小处理单元都附有少量内存，每个执行单元都有一些共享内存用于它的处理单元。除此之外，还有一些 GPU 范围的内存，然后是 CPU 使用的主内存。执行单元内部的单元是 <em>lockstep</em> ，每个单元都在不同的数据片上执行相同的指令。</p><p>这可以使 GPU 同时处理大量的数据。如果是在 CPU 上，也许你可以使用多线程和向量指令在给定时间内完成大量的工作，但是 GPU 所能处理的远多于此。在 GPU 上一次性能够处理的数据规模使得它非常适合于类似图形（duh）、数学处理、神经网络等等。</p><p>GPGPU 编程的很多方面使得它和日常的 CPU 编程完全不同。例如，从主内存传输数据到 GPU 是<em>很慢的</em>。<em>真的</em>很慢。会完全干掉你的性能使你慢下来。因此，GPU 编程的权衡是尽可能多地利用加速器的高吞吐量来掩盖数据来往的延迟。</p><p>这里还有一些不那么明显的问题，例如分支的开销。由于执行单元内的处理单元按照 lockstep 工作，使它们执行不同路径（不同的控制流）的嵌套分支就是个真正的问题。这通常通过在所有单元上执行所有分支并标记出无用结果来解决。这是一个基于嵌套级别的指数级的复杂度，这当然是坏事情。当然，有一些优化方法可以拯救该问题，但需要注意：你从 CPU 领域带来的简单假设和知识在 GPU 领域可能导致大问题。</p><p>在我们回到 SYCL 之前，需要介绍一些术语。<ruby>主机 <rp>（ </rp><rt>host</rt> <rp>）</rp></ruby>是主 CPU 运行的机器，<ruby>设备 <rp>（ </rp><rt>device</rt> <rp>）</rp></ruby>是会运行你 OpenCL 代码的地方。设备可能就是主机，但也可能是你机器上的一些加速器、模拟器等。<ruby>内核 <rp>（ </rp><rt>kernel</rt> <rp>）</rp></ruby>是一个特殊函数，它是在你设备上运行代码的入口点。通常还会提供一些主机设置好的缓存给它用于输入和输出数据。</p><h3 id="回到-SYCL"><a href="#回到-SYCL" class="headerlink" title="回到 SYCL"></a>回到 SYCL</h3><p>这里有两个可用的 SYCL 实现：<a target="_blank" rel="noopener" href="https://github.com/Xilinx/triSYCL">triSYCL</a>，由 Xilinx 开发的实验性开源版本（通常作为标准的试验台使用），以及 <a target="_blank" rel="noopener" href="https://www.codeplay.com/products/computesuite/computecpp">ComputeCpp</a>，由 Codeplay（我在 Codeplay 工作，但这篇文章是在没有我雇主建议的情况下使用我自己时间编写的） 开发的工业级实现（当前处于开发测试版）。只有 ComputeCpp 支持在 GPU 上执行内核，因此在这篇文章中我们会使用它。</p><p>第一步是在你的机器上配置以及运行 ComputeCpp。主要组件是一个实现了 SYCL API 的运行时库，以及一个基于 Clang 的编译器，它负责编译你的主机代码和设备代码。在本文写作时，已经在 Ubuntu 和 CentOS 上官方支持 Intel CPU 以及某些 AMD GPU。在其它 Linux 发行版上让它工作也非常简单（例如，我让它在我的 Arch 系统上运行）。对更多的硬件和操作系统的支持正在进行中，查看<a target="_blank" rel="noopener" href="https://www.codeplay.com/products/computesuite/computecpp/reference/platform-support-notes">支持平台文档</a>获取最新列表。<a target="_blank" rel="noopener" href="https://www.codeplay.com/products/computesuite/computecpp/reference/release-notes/">这里</a>列出了依赖和组件。你也可能想要下载 <a target="_blank" rel="noopener" href="https://github.com/codeplaysoftware/computecpp-sdk">SDK</a>，其中包括了示例、文档、构建系统集成文件，以及其它。在这篇文章中我会使用 <a target="_blank" rel="noopener" href="https://github.com/KhronosGroup/SyclParallelSTL">SYCL 并行 STL</a>，如果你想要自己在家学习的话也要下载它。</p><p>一旦你设置好了一切，我们就可以开始通用 GPU 编程了！正如简介中提到的，我的第一个示例使用 SYCL 并行 STL 实现。我们现在来看看如何使用纯 SYCL 编写代码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;CL/sycl.hpp&gt;</span><br><span class="line"></span><br><span class="line">#include &lt;array&gt;</span><br><span class="line">#include &lt;numeric&gt;</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line"></span><br><span class="line">int main() &#123;</span><br><span class="line">      const size_t array_size = 1024*512;</span><br><span class="line">      std::array&lt;cl::sycl::cl_int, array_size&gt; in,out;</span><br><span class="line">      std::iota(begin(in),end(in),0);</span><br><span class="line"></span><br><span class="line">      &#123;</span><br><span class="line">          cl::sycl::queue device_queue;</span><br><span class="line">          cl::sycl::range&lt;1&gt; n_items&#123;array_size&#125;;</span><br><span class="line">          cl::sycl::buffer&lt;cl::sycl::cl_int, 1&gt; in_buffer(in.data(), n_items);</span><br><span class="line">          cl::sycl::buffer&lt;cl::sycl::cl_int, 1&gt; out_buffer(out.data(), n_items);</span><br><span class="line"></span><br><span class="line">          device_queue.submit([&amp;](cl::sycl::handler &amp;cgh) &#123;</span><br><span class="line">              constexpr auto sycl_read = cl::sycl::access::mode::read;</span><br><span class="line">              constexpr auto sycl_write = cl::sycl::access::mode::write;</span><br><span class="line"></span><br><span class="line">              auto in_accessor = in_buffer.get_access&lt;sycl_read&gt;(cgh);</span><br><span class="line">              auto out_accessor = out_buffer.get_access&lt;sycl_write&gt;(cgh);</span><br><span class="line"></span><br><span class="line">              cgh.parallel_for&lt;class VecScalMul&gt;(n_items,</span><br><span class="line">                  [=](cl::sycl::id&lt;1&gt; wiID) &#123;</span><br><span class="line">                      out_accessor[wiID] = in_accessor[wiID]*2;</span><br><span class="line">                  &#125;);</span><br><span class="line">         &#125;);</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>我会把它划分为一个个片段。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;CL/sycl.hpp&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>我们做的第一件事就是包含 SYCL 头文件，它会在我们的命令中添加 SYCL 运行时库。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">const size_t array_size = 1024*512;</span><br><span class="line">std::array&lt;cl::sycl::cl_int, array_size&gt; in,out;</span><br><span class="line">std::iota(begin(in),end(in),0);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里我们构造了一个很大的整型数组并用数字 <code>0</code> 到 <code>array_size-1</code> 初始化（这就是 <code>std::iota</code> 所做的）。注意我们使用 <code>cl::sycl::cl_int</code> 确保兼容性。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    //...</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>接着我们打开一个新的作用域，其目的为二：</p><ol><li><code>device_queue</code> 将在该作用域结束时解构，它将阻塞，直到内核完成。</li><li><code>in_buffer</code> 和 <code>out_buffer</code> 也将解构，这将强制数据传输回主机并允许我们从 <code>in</code> 和 <code>out</code> 中访问数据。 <code>cl::sycl::queue device_queue;</code></li></ol><p>现在我们创建我们的命令队列。命令队列是所有工作（内核）在分发到设备之前需要入队的地方。有很多方法可以定制队列，例如说提供设备用于入队或者设置异步错误处理器，但对于这个例子默认构造器就可以了；它会查找兼容的 GPU，如果失败的话会回退到主机 CPU。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cl::sycl::range&lt;1&gt; n_items&#123;array_size&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>接下来我们创建一个范围，它描述了内核在上面执行的数据的形状。在我们简单的例子中，它是一个一维数组，因此我们使用 <code>cl::sycl::range&lt;1&gt;</code>。如果数据是二维的，我们就会使用 <code>cl::sycl::range&lt;2&gt;</code>，以此类推。除了 <code>cl::sycl::range</code>，还有 <code>cl::sycl::ndrange</code>，它允许你指定工作组大小以及越界范围，但在我们的例子中我们不需要使用它。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cl::sycl::buffer&lt;cl::sycl::cl_int, 1&gt; in_buffer(in.data(), n_items);</span><br><span class="line">cl::sycl::buffer&lt;cl::sycl::cl_int, 1&gt; out_buffer(out.data(), n_items);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>为了控制主机和设备之间的数据共享和传输，SYCL 提供了一个 <code>buffer</code> 类。我们创建了两个 SYCL 缓存用于管理我们的输入和输出数组。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">device_queue.submit([&amp;](cl::sycl::handler &amp;cgh) &#123;/*...*/&#125;);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>设置好了我们所有数据之后，我们就可以入队真正的工作。有多种方法可以做到，但设置并行执行的一个简单方法是在我们的队列中调用 <code>.submit</code> 函数。对于这个函数我们传递了一个运行时调度该任务时会被执行的“命令组伪函数”（伪函数是规范，不是我创造的）。命令组处理器设置任何内核需要的余下资源并分发它。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">constexpr auto sycl_read = cl::sycl::access::mode::read_write;</span><br><span class="line">constexpr auto sycl_write = cl::sycl::access::mode::write;</span><br><span class="line"></span><br><span class="line">auto in_accessor = in_buffer.get_access&lt;sycl_read&gt;(cgh);</span><br><span class="line">auto out_accessor = out_buffer.get_access&lt;sycl_write&gt;(cgh);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>为了控制到我们缓存的访问并告诉该运行时环境我们会如何使用数据，我们需要创建访问器。很显然，我们创建了一个访问器用于从 <code>in_buffer</code> 读入，一个访问器用于写到 <code>out_buffer</code>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cgh.parallel_for&lt;class VecScalMul&gt;(n_items,</span><br><span class="line">    [=](cl::sycl::id&lt;1&gt; wiID) &#123;</span><br><span class="line">         out_accessor[wiID] = in_accessor[wiID]*2;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>现在我们已经完成了所有设置，我们可以真正的在我们的设备上做一些计算了。这里我们根据范围 <code>n_items</code> 在命令组处理器 <code>cgh</code> 之上分发一个内核。实际内核自身是一个使用 work-item 标识符作为输入、输出我们计算结果的 lamda 表达式。在这种情况下，我们从 <code>in_accessor</code> 使用 work-item 标识符作为索引读入，将其乘以 <code>2</code>，然后将结果保存到 <code>out_accessor</code> 相应的位置。<code>&lt;class VecScalMul&gt;</code> 是一个为了在标准 C++ 范围内工作的不幸的副产品，因此我们需要给内核一个唯一的类名以便编译器能完成它的工作。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在此之后，我们现在可以访问 <code>out</code> 并期望看到正确的结果。</p><p>这里有相当多的新概念在起作用，但使用这些技术你可以看到这些能力和所展现出来的东西。当然，如果你只是想在你的 GPU 上执行一些代码而不关心定制化，那么你就可以使用 SYCL 并行 STL 实现。</p><h3 id="SYCL-并行-STL"><a href="#SYCL-并行-STL" class="headerlink" title="SYCL 并行 STL"></a>SYCL 并行 STL</h3><p>SYCL 并行 STL 是一个 TS 的并行化实现，它分发你的算法函数对象作为 SYCL 内核。在这个页面前面我们已经看过这样的例子，让我们来快速过一遍。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;vector&gt;</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line"></span><br><span class="line">#include &lt;sycl/execution_policy&gt;</span><br><span class="line">#include &lt;experimental/algorithm&gt;</span><br><span class="line">#include &lt;sycl/helpers/sycl_buffers.hpp&gt;</span><br><span class="line"></span><br><span class="line">using namespace std::experimental::parallel;</span><br><span class="line">using namespace sycl::helpers;</span><br><span class="line"></span><br><span class="line">int main() &#123;</span><br><span class="line">  constexpr size_t array_size = 1024*512;</span><br><span class="line">  std::array&lt;cl::sycl::cl_int, array_size&gt; in,out;</span><br><span class="line">  std::iota(begin(in),end(in),0);</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line">    cl::sycl::buffer&lt;int&gt; in_buffer(in.data(), cl::sycl::range&lt;1&gt;(in.size()));</span><br><span class="line">    cl::sycl::buffer&lt;int&gt; out_buffer(out.data(), cl::sycl::range&lt;1&gt;(out.size()));</span><br><span class="line">    cl::sycl::queue q;</span><br><span class="line">    sycl::sycl_execution_policy&lt;class Mul&gt; sycl_policy(q);</span><br><span class="line">    transform(sycl_policy, begin(in_buffer), end(in_buffer), begin(out_buffer),</span><br><span class="line">              [](int x) &#123; return x*2; &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">constexpr size_t array_size = 1024*512;</span><br><span class="line">std::array&lt;cl::sycl::cl_int, array_size&gt; in, out;</span><br><span class="line">std::iota(begin(in),end(in),0);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>到现在为止一切如此相似。我们再一次创建一组数组用于保存我们的输入输出数据。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cl::sycl::buffer&lt;int&gt; in_buffer(in.data(), cl::sycl::range&lt;1&gt;(in.size()));</span><br><span class="line">cl::sycl::buffer&lt;int&gt; out_buffer(out.data(), cl::sycl::range&lt;1&gt;(out.size()));</span><br><span class="line">cl::sycl::queue q;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里我们创建类似上个例子的缓存和队列。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sycl::sycl_execution_policy&lt;class Mul&gt; sycl_policy(q);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这就是有趣的部分。我们从我们的队列中创建 <code>sycl_execution_policy</code>，给它一个名称让内核使用。这个执行策略然后可以像 <code>std::execution::par</code> 或 <code>std::execution::seq</code> 那样使用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">transform(sycl_policy, begin(in_buffer), end(in_buffer), begin(out_buffer),</span><br><span class="line">          [](int x) &#123; return x*2; &#125;);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>现在我们的内核分发看起来像提供了一个执行策略的 <code>std::transform</code> 调用。我们传递的闭包会被编译并在设备上执行，而不需要我们做其它更加复杂的设置。</p><p>当然，除了 <code>transform</code> 你可以做更多。开发的时候，SYCL 并行 STL 支持以下算法：</p><ul><li><code>sort</code></li><li><code>transform</code></li><li><code>for_each</code></li><li><code>for_each_n</code></li><li><code>count_if</code></li><li><code>reduce</code></li><li><code>inner_product</code></li><li><code>transform_reduce</code></li></ul><p>这就是这篇短文需要介绍的东西。如果你想和 SYCL 的开发保持同步，那就要看 <a target="_blank" rel="noopener" href="http://sycl.tech/">sycl.tech</a>。最近重要的开发就是移植 <a target="_blank" rel="noopener" href="https://github.com/ville-k/sycl_starter">Eigen</a> 和 <a target="_blank" rel="noopener" href="http://deep-beta.co.uk/setting-up-tensorflow-with-opencl-using-sycl/">Tensorflow</a> 到 SYCL ，为 OpenCL 设备带来引入关注的人工智能编程。对我个人而言，我很高兴看到高级编程模型可以用于异构程序自动优化，以及它们是怎样支持类似 <a target="_blank" rel="noopener" href="https://github.com/STEllAR-GROUP/hpx">HPX</a> 或 <a target="_blank" rel="noopener" href="https://github.com/skelcl/skelcl">SkelCL</a> 等更高级的技术。</p><hr><p>via: <a target="_blank" rel="noopener" href="https://blog.tartanllama.xyz/c++/2017/05/19/sycl/">https://blog.tartanllama.xyz/c++/2017/05/19/sycl/</a></p><p>作者：<a target="_blank" rel="noopener" href="https://www.twitter.com/TartanLlama">TartanLlama</a> 译者：<a target="_blank" rel="noopener" href="https://github.com/ictlyh">ictlyh</a> 校对：<a target="_blank" rel="noopener" href="https://github.com/wxy">wxy</a></p><p>本文由 <a target="_blank" rel="noopener" href="https://github.com/LCTT/TranslateProject">LCTT</a> 原创编译，<a target="_blank" rel="noopener" href="https://linux.cn/">Linux中国</a> 荣誉推出</p></div></div></div><div class="footer"><p class="footer-copyright"><span>Powered by <a target="_blank" href="https://hexo.io">Hexo</a></span> <span>Theme <a target="_blank" href="https://github.com/tinkink-co/hexo-theme-terminal">Terminal</a></span><script type="text/javascript" src="https://cdn.staticfile.net/jquery/3.4.1/jquery.min.js"></script><script>getCDNinfo=function(){$.ajax({url:"/cdn-cgi/trace",success:function(a,n){let i="Antananarivo, Madagascar - (TNR);Cape Town, South Africa - (CPT);Casablanca, Morocco - (CMN);Dar Es Salaam, Tanzania - (DAR);Djibouti City, Djibouti - (JIB);Durban, South Africa - (DUR);Johannesburg, South Africa - (JNB);Kigali, Rwanda - (KGL);Lagos, Nigeria - (LOS);Luanda, Angola - (LAD);Maputo, MZ - (MPM);Mombasa, Kenya - (MBA);Port Louis, Mauritius - (MRU);Réunion, France - (RUN);Bangalore, India - (BLR);Bangkok, Thailand - (BKK);Bandar Seri Begawan, Brunei - (BWN);Cebu, Philippines - (CEB);Chengdu, China - (CTU);Chennai, India - (MAA);Chittagong, Bangladesh - (CGP);Chongqing, China - (CKG);Colombo, Sri Lanka - (CMB);Dhaka, Bangladesh - (DAC);Dongguan, China - (SZX);Foshan, China - (FUO);Fuzhou, China - (FOC);Guangzhou, China - (CAN);Hangzhou, China - (HGH);Hanoi, Vietnam - (HAN);Hengyang, China - (HNY);Ho Chi Minh City, Vietnam - (SGN);Hong Kong - (HKG);Hyderabad, India - (HYD);Islamabad, Pakistan - (ISB);Jakarta, Indonesia - (CGK);Jinan, China - (TNA);Karachi, Pakistan - (KHI);Kathmandu, Nepal - (KTM);Kolkata, India - (CCU);Kuala Lumpur, Malaysia - (KUL);Lahore, Pakistan - (LHE);Langfang, China - (NAY);Luoyang, China - (LYA);Macau - (MFM);Malé, Maldives - (MLE);Manila, Philippines - (MNL);Mumbai, India - (BOM);Nagpur, India - (NAG);Nanning, China - (NNG);New Delhi, India - (DEL);Osaka, Japan - (KIX);Phnom Penh, Cambodia - (PNH);Qingdao, China - (TAO);Seoul, South Korea - (ICN);Shanghai, China - (SHA);Shenyang, China - (SHE);Shijiazhuang, China - (SJW);Singapore, Singapore - (SIN);Suzhou, China - (SZV);Taipei - (TPE);Thimphu, Bhutan - (PBH);Tianjin, China - (TSN);Tokyo, Japan - (NRT);Ulaanbaatar, Mongolia - (ULN);Vientiane, Laos - (VTE);Wuhan, China - (WUH);Wuxi, China - (WUX);Xi'an, China - (XIY);Yerevan, Armenia - (EVN);Zhengzhou, China - (CGO);Zuzhou, China - (CSX);Amsterdam, Netherlands - (AMS);Athens, Greece - (ATH);Barcelona, Spain - (BCN);Belgrade, Serbia - (BEG);Berlin, Germany - (TXL);Brussels, Belgium - (BRU);Bucharest, Romania - (OTP);Budapest, Hungary - (BUD);Chișinău, Moldova - (KIV);Copenhagen, Denmark - (CPH);Cork, Ireland -  (ORK);Dublin, Ireland - (DUB);Düsseldorf, Germany - (DUS);Edinburgh, United Kingdom - (EDI);Frankfurt, Germany - (FRA);Geneva, Switzerland - (GVA);Gothenburg, Sweden - (GOT);Hamburg, Germany - (HAM);Helsinki, Finland - (HEL);Istanbul, Turkey - (IST);Kyiv, Ukraine - (KBP);Lisbon, Portugal - (LIS);London, United Kingdom - (LHR);Luxembourg City, Luxembourg - (LUX);Madrid, Spain - (MAD);Manchester, United Kingdom - (MAN);Marseille, France - (MRS);Milan, Italy - (MXP);Moscow, Russia - (DME);Munich, Germany - (MUC);Nicosia, Cyprus - (LCA);Oslo, Norway - (OSL);Paris, France - (CDG);Prague, Czech Republic - (PRG);Reykjavík, Iceland - (KEF);Riga, Latvia - (RIX);Rome, Italy - (FCO);Saint Petersburg, Russia - (LED);Sofia, Bulgaria - (SOF);Stockholm, Sweden - (ARN);Tallinn, Estonia - (TLL);Thessaloniki, Greece - (SKG);Vienna, Austria - (VIE);Vilnius, Lithuania - (VNO);Warsaw, Poland - (WAW);Zagreb, Croatia - (ZAG);Zürich, Switzerland - (ZRH);Arica, Chile - (ARI);Asunción, Paraguay - (ASU);Bogotá, Colombia - (BOG);Buenos Aires, Argentina - (EZE);Curitiba, Brazil - (CWB);Fortaleza, Brazil - (FOR);Guatemala City, Guatemala - (GUA);Lima, Peru - (LIM);Medellín, Colombia - (MDE);Panama City, Panama - (PTY);Porto Alegre, Brazil - (POA);Quito, Ecuador - (UIO);Rio de Janeiro, Brazil - (GIG);São Paulo, Brazil - (GRU);Santiago, Chile - (SCL);Willemstad, Curaçao - (CUR);St. George's, Grenada - (GND);Amman, Jordan - (AMM);Baghdad, Iraq - (BGW);Baku, Azerbaijan - (GYD);Beirut, Lebanon - (BEY);Doha, Qatar - (DOH);Dubai, United Arab Emirates - (DXB);Kuwait City, Kuwait - (KWI);Manama, Bahrain - (BAH);Muscat, Oman - (MCT);Ramallah - (ZDM);Riyadh, Saudi Arabia - (RUH);Tel Aviv, Israel - (TLV);Ashburn, VA, United States - (IAD);Atlanta, GA, United States - (ATL);Boston, MA, United States - (BOS);Buffalo, NY, United States - (BUF);Calgary, AB, Canada - (YYC);Charlotte, NC, United States - (CLT);Chicago, IL, United States - (ORD);Columbus, OH, United States - (CMH);Dallas, TX, United States - (DFW);Denver, CO, United States - (DEN);Detroit, MI, United States - (DTW);Honolulu, HI, United States - (HNL);Houston, TX, United States - (IAH);Indianapolis, IN, United States - (IND);Jacksonville, FL, United States - (JAX);Kansas City, MO, United States - (MCI);Las Vegas, NV, United States - (LAS);Los Angeles, CA, United States - (LAX);McAllen, TX, United States - (MFE);Memphis, TN, United States - (MEM);Mexico City, Mexico - (MEX);Miami, FL, United States - (MIA);Minneapolis, MN, United States - (MSP);Montgomery, AL, United States - (MGM);Montréal, QC, Canada - (YUL);Nashville, TN, United States - (BNA);Newark, NJ, United States - (EWR);Norfolk, VA, United States - (ORF);Omaha, NE, United States - (OMA);Philadelphia, United States - (PHL);Phoenix, AZ, United States - (PHX);Pittsburgh, PA, United States - (PIT);Port-Au-Prince, Haiti - (PAP);Portland, OR, United States - (PDX);Queretaro, MX, Mexico - (QRO);Richmond, Virginia - (RIC);Sacramento, CA, United States - (SMF);Salt Lake City, UT, United States - (SLC);San Diego, CA, United States - (SAN);San Jose, CA, United States - (SJC);Saskatoon, SK, Canada - (YXE);Seattle, WA, United States - (SEA);St. Louis, MO, United States - (STL);Tampa, FL, United States - (TPA);Toronto, ON, Canada - (YYZ);Vancouver, BC, Canada - (YVR);Tallahassee, FL, United States - (TLH);Winnipeg, MB, Canada - (YWG);Adelaide, SA, Australia - (ADL);Auckland, New Zealand - (AKL);Brisbane, QLD, Australia - (BNE);Melbourne, VIC, Australia - (MEL);Noumea, New caledonia - (NOU);Perth, WA, Australia - (PER);Sydney, NSW, Australia - (SYD)".split(";"),e=a.split("colo=")[1].split("\n")[0],t=(a.split("colo=")[1].split("\n")[0],a.split("tls=")[1].split("\n")[0]),o=a.split("http=")[1].split("\n")[0],s=a.split("sni=")[1].split("\n")[0],r=a.split("ip=")[1].split("\n")[0],l=a.split("uag=")[1].split("\n")[0];for(var d=0;d<i.length;d++)if(-1!=i[d].indexOf(e)){document.getElementById("cdn").innerHTML=i[d];break}document.getElementById("tls").innerHTML=t,document.getElementById("http").innerHTML=o,document.getElementById("sni").innerHTML=s,document.getElementById("ip").innerHTML=r,document.getElementById("useragent").innerHTML=l}})},$(document).ready((function(){getCDNinfo()}))</script></p><p style="text-align:center">感谢陪伴与布道，开源之火不灭。​</p><p style="text-align:center"><script>document.write("本次加载耗时: "+(performance.getEntriesByType("navigation").reduce((e,r)=>e+r.responseEnd-r.startTime,0)+performance.getEntriesByType("resource").reduce((e,r)=>e+r.responseEnd-r.startTime,0)).toFixed(0)+"ms")</script></p><p style="text-align:center">当前 SNI 状态： <span id="sni">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 TLS 版本： <span id="tls">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前 HTTP 版本： <span id="http">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前您的客户端 IP 是： <span id="ip">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">当前分配的 CDN 节点是: <span id="cdn">正在统计！或可能被浏览器防追踪拦截！</span></p><p style="text-align:center">您的 UserAgent 信息是: <span id="useragent">正在统计！或可能被浏览器防追踪拦截！</span></p><p></p></div></div></body></html>